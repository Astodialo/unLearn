import { ConstValue } from "../UPLCTerms/UPLCConst/ConstValue/index.js";
import { UPLCTerm } from "../UPLCTerm/UPLCTerm.js";
import { UPLCProgram } from "../UPLCProgram/UPLCProgram.js";
import { UPLCVersion } from "../UPLCProgram/UPLCVersion.js";
import { Application } from "../UPLCTerms/Application.js";
import { Builtin } from "../UPLCTerms/Builtin/Builtin.js";
import { UPLCConst } from "../UPLCTerms/UPLCConst/UPLCConst.js";
import { Delay } from "../UPLCTerms/Delay.js";
import { ErrorUPLC } from "../UPLCTerms/ErrorUPLC.js";
import { Force } from "../UPLCTerms/Force.js";
import { Lambda } from "../UPLCTerms/Lambda.js";
import { UPLCVar } from "../UPLCTerms/UPLCVar/index.js";
import { BitStream } from "@harmoniclabs/bitstream";
import { ByteString } from "@harmoniclabs/bytestring";
import { Data } from "@harmoniclabs/plutus-data";
import { Constr } from "../UPLCTerms/Constr.js";
import { Case } from "../UPLCTerms/Case.js";
/**
 * exported for testing purposes
 */
export declare function serializeBuiltin(bn: Builtin): BitStream;
export declare class UPLCEncoder {
    private _ctx;
    constructor();
    compile(program: UPLCProgram): BitStream;
    static get compile(): (program: UPLCProgram) => BitStream;
    /** always byte-alligned */
    encodeVersion(version: UPLCVersion): BitStream;
    /** might modify version if necessary */
    encodeTerm(term: UPLCTerm): BitStream;
    encodeUPLCVar(uplcVar: UPLCVar): BitStream;
    encodeDelayTerm(delayed: Delay): BitStream;
    encodeLambdaTerm(lam: Lambda): BitStream;
    encodeApplicationTerm(app: Application): BitStream;
    encodeConstTerm(uplcConst: UPLCConst): BitStream;
    encodeConstValue(value: ConstValue): BitStream;
    /**
     * ### Section D.3.5
     * The ```data``` type
     *
     * The ğšğšŠğšğšŠ type is encoded by converting to a bytestring using the CBOR encoding described in Note 1 of
     * Appendix B.2 and then using ğ–¤ ğ•Œ âˆ— . The decoding process is the opposite of this: a bytestring is obtained
     * using ğ–£ ğ•Œ âˆ— and this is then decoded from CBOR to obtain a ğšğšŠğšğšŠ object.
     *
     * ### Section B.2
     *
     * **Note 1.** Serialising ğšğšŠğšğšŠ objects. The ```serialiseData``` function takes a ğšğšŠğšğšŠ object and converts it
     * into a CBOR (Bormann and Hoffman [2020]) object. The encoding is based on the Haskell Data type
     * described in Section A.1. A detailed description of the encoding will appear here at a later date, but for
     * the time being see the Haskell code in
     * [plutus-core/plutus-core/src/PlutusCore/Data.hs](https://github.com/input-output-hk/plutus/blob/master/plutus-core/plutus-core/src/PlutusCore/Data.hs)
     * ([```encodeData``` line](https://github.com/input-output-hk/plutus/blob/9ef6a65067893b4f9099215ff7947da00c5cd7ac/plutus-core/plutus-core/src/PlutusCore/Data.hs#L139))
     * in the Plutus GitHub repository IOHK [2019] for a definitive implementation.
     *
     * from the `encodeData` source:
     *
     * {- Note [The 64-byte limit]
     *    We impose a 64-byte *on-the-wire* limit on the leaves of a serialized 'Data'. This prevents people from inserting
     *    Mickey Mouse entire.
     *
     *    The simplest way of doing this is to check during deserialization that we never deserialize something that uses
     *    more than 64-bytes, and this is largely what we do. Then it's the user's problem to not produce something too big.
     *
     *    But this is quite inconvenient, so see Note [Evading the 64-byte limit] for how we get around this.
     * -}
     * {- Note [Evading the 64-byte limit]
     *  Implementing Note [The 64-byte limit] naively would be quite annoying:
     *  - Users would be responsible for not creating Data values with leaves that were too big.
     *  - If a script *required* such a thing (e.g. a counter that somehow got above 64 bytes), then the user is totally
     *  stuck: the script demands something they cannot represent.
     *
     *  This is unpleasant and introduces limits. Probably limits that nobody will hit, but it's nicer to just not have them.
     *  And it turns out that we can evade the problem with some clever encoding.
     *
     *  The fundamental
     *  trick is that an *indefinite-length* CBOR bytestring is just as obfuscated as a list of bytestrings,
     *  since it consists of a list of definite-length chunks, and each definite-length chunk must be *tagged* (at least with the size).
     *  So we get a sequence like:
     *
     *  <list start>
     *  <chunk length metadata>
     *  <chunk>
     *  <chunk length metadata>
     *  ...
     *  <list end>
     *
     *  The chunk length metadata has a prescribed format, such that it's difficult to manipulate it so that it
     *  matches your "desired" data.
     *  So this effectively breaks up the bytestring in much the same way as a list of <64 byte bytestrings.
     *
     *  So that solves the problem for bytestrings on the encoding side:
     *  - if they are <=64 bytes, we can just encode them as a normal bytestring
     *  - if they are >64 bytes, we encode them as indefinite-length bytestrings with 64-byte chunks
     *
     *  On the decoding side, we need to check when we decode that we never decode a definite-length
     *  bytestring of >64 bytes. That covers our two cases:
     *  - Short definite-length bytestrings are fine
     *  - Long indefinite-length bytestrings are just made of short definite-length bytestings.
     *
     *   *  Unfortunately this all means that we have to write our own encoders/decoders so we can produce
     *   *  chunks of the right size and check the sizes when we decode, but that's okay. Users need to do the same
     *   *  thing: anyone encoding `Data` with their own encoders who doesn't split up big bytestrings in this way
     *   *  will get failures when we decode them.
     *
     *  For integers, we have two cases. Small integers (<=64bits) can be encoded normally. Big integers are already
     *  encoded *with a byte string*. The spec allows this to be an indefinite-length bytestring (although cborg doesn't
     *  like it), so we can reuse our trick. Again, we need to write some manual encoders/decoders.
     *  -}
     */
    encodeConstValueData(data: Data): BitStream;
    /**
     * latest specification (**_section D.2.5 Bytestrings; page 27_**)
     * specifies how bytestrings are byte-alligned before and the first byte indicates the length
     *
     * **this function takes care of the length AND padding**
     *
     */
    encodeConstValueByteString(bs: ByteString): BitStream;
    encodeForceTerm(force: Force): BitStream;
    encodeUPLCError(_term: ErrorUPLC): BitStream;
    encodeBuiltin(bn: Builtin): BitStream;
    encodeConstr(constr: Constr): BitStream;
    encodeCase(caseTerm: Case): BitStream;
    encodeTermList(list: UPLCTerm[]): BitStream;
}
export declare function compileUPLC(program: UPLCProgram): BitStream;
/**
 * alias for `compileUPLC`
 */
export declare const encodeUPLC: typeof compileUPLC;
