"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.ListFromSelf = exports.List = exports.LessThanSchemaId = exports.LessThanOrEqualToSchemaId = exports.LessThanOrEqualToDurationSchemaId = exports.LessThanOrEqualToDateSchemaId = exports.LessThanOrEqualToBigIntSchemaId = exports.LessThanOrEqualToBigDecimalSchemaId = exports.LessThanDurationSchemaId = exports.LessThanDateSchemaId = exports.LessThanBigIntSchemaId = exports.LessThanBigDecimalSchemaId = exports.LengthSchemaId = exports.JsonNumberSchemaId = exports.JsonNumber = exports.ItemsCountSchemaId = exports.IntSchemaId = exports.Int = exports.InstanceOfSchemaId = exports.IncludesSchemaId = exports.HashSetFromSelf = exports.HashSet = exports.HashMapFromSelf = exports.HashMap = exports.GreaterThanSchemaId = exports.GreaterThanOrEqualToSchemaId = exports.GreaterThanOrEqualToDurationSchemaId = exports.GreaterThanOrEqualToDateSchemaId = exports.GreaterThanOrEqualToBigIntSchemaId = exports.GreaterThanOrEqualToBigDecimalSchemaId = exports.GreaterThanDurationSchemaId = exports.GreaterThanDateSchemaId = exports.GreaterThanBigIntSchemaId = exports.GreaterThanBigDecimalSchemaId = exports.FromPropertySignature = exports.FiniteSchemaId = exports.Finite = exports.FiberIdFromSelf = exports.FiberId = exports.ExitFromSelf = exports.Exit = exports.Enums = exports.EndsWithSchemaId = exports.EitherFromUnion = exports.EitherFromSelf = exports.Either = exports.DurationFromSelf = exports.DurationFromNanos = exports.DurationFromMillis = exports.Duration = exports.Defect = exports.DateTimeZonedFromSelf = exports.DateTimeZoned = exports.DateTimeUtcFromSelf = exports.DateTimeUtcFromNumber = exports.DateTimeUtc = exports.DateFromString = exports.DateFromSelf = exports.DateFromNumber = exports.Date = exports.DataFromSelf = exports.Data = exports.Config = exports.Class = exports.ChunkFromSelf = exports.Chunk = exports.Char = exports.CauseFromSelf = exports.Cause = exports.CapitalizedSchemaId = exports.Capitalized = exports.Capitalize = exports.BrandSchemaId = exports.BooleanFromUnknown = exports.Boolean = exports.BigIntFromSelf = exports.BigIntFromNumber = exports.BigInt = exports.BigDecimalFromSelf = exports.BigDecimalFromNumber = exports.BigDecimal = exports.BetweenSchemaId = exports.BetweenDurationSchemaId = exports.BetweenDateSchemaId = exports.BetweenBigIntSchemaId = exports.BetweenBigDecimalSchemaId = exports.ArrayEnsure = exports.Array = exports.Any = void 0;
exports.Literal = Literal;
exports.MinLengthSchemaId = exports.MinItemsSchemaId = exports.MaxLengthSchemaId = exports.MaxItemsSchemaId = exports.MapFromSelf = exports.MapFromRecord = exports.Map = exports.LowercasedSchemaId = exports.Lowercased = exports.Lowercase = void 0;
exports.StringFromHex = exports.StringFromBase64Url = exports.StringFromBase64 = exports.String = exports.StartsWithSchemaId = exports.SortedSetFromSelf = exports.SortedSet = exports.SetFromSelf = exports.Set = exports.RefineSchemaId = exports.RedactedFromSelf = exports.Redacted = exports.Record = exports.ReadonlySetFromSelf = exports.ReadonlySet = exports.ReadonlyMapFromSelf = exports.ReadonlyMapFromRecord = exports.ReadonlyMap = exports.PropertySignatureTypeId = exports.PropertySignatureTransformation = exports.PropertySignatureDeclaration = exports.PositiveBigIntFromSelf = exports.PositiveBigInt = exports.PositiveBigDecimalSchemaId = exports.PositiveBigDecimalFromSelf = exports.Positive = exports.PatternSchemaId = exports.OptionFromUndefinedOr = exports.OptionFromSelf = exports.OptionFromNullishOr = exports.OptionFromNullOr = exports.OptionFromNonEmptyTrimmedString = exports.Option = exports.Object = exports.NumberFromString = exports.Number = exports.NullishOr = exports.NullOr = exports.Null = exports.Not = exports.NonPositiveBigIntFromSelf = exports.NonPositiveBigInt = exports.NonPositiveBigDecimalSchemaId = exports.NonPositiveBigDecimalFromSelf = exports.NonPositive = exports.NonNegativeBigIntFromSelf = exports.NonNegativeBigInt = exports.NonNegativeBigDecimalSchemaId = exports.NonNegativeBigDecimalFromSelf = exports.NonNegative = exports.NonNaNSchemaId = exports.NonNaN = exports.NonEmptyTrimmedString = exports.NonEmptyString = exports.NonEmptyChunkFromSelf = exports.NonEmptyChunk = exports.NonEmptyArrayEnsure = exports.NonEmptyArray = exports.Never = exports.NegativeBigIntFromSelf = exports.NegativeBigInt = exports.NegativeBigDecimalSchemaId = exports.NegativeBigDecimalFromSelf = exports.Negative = exports.MultipleOfSchemaId = void 0;
exports.Struct = Struct;
exports.TrimmedSchemaId = exports.Trimmed = exports.Trim = exports.ToPropertySignature = exports.TimeZoneOffsetFromSelf = exports.TimeZoneOffset = exports.TimeZoneNamedFromSelf = exports.TimeZoneNamed = exports.TimeZoneFromSelf = exports.TimeZone = exports.TemplateLiteralParser = exports.TemplateLiteral = exports.TaggedStruct = exports.TaggedRequest = exports.TaggedError = exports.TaggedClass = exports.SymbolFromSelf = exports.Symbol = void 0;
exports.Tuple = Tuple;
exports.UndefinedOr = exports.Undefined = exports.UncapitalizedSchemaId = exports.Uncapitalized = exports.Uncapitalize = exports.Uint8ArrayFromSelf = exports.Uint8ArrayFromHex = exports.Uint8ArrayFromBase64Url = exports.Uint8ArrayFromBase64 = exports.Uint8Array = exports.UUIDSchemaId = exports.UUID = exports.ULIDSchemaId = exports.ULID = exports.TypeId = void 0;
exports.Union = Union;
exports.asWithResult = exports.asSerializableWithResult = exports.asSerializable = exports.asSchema = exports.annotations = exports.Void = exports.ValidDateSchemaId = exports.ValidDateFromSelf = exports.UppercasedSchemaId = exports.Uppercased = exports.Uppercase = exports.Unknown = exports.UniqueSymbolFromSelf = void 0;
Object.defineProperty(exports, "asserts", {
  enumerable: true,
  get: function () {
    return ParseResult.asserts;
  }
});
exports.decodeEither = exports.decode = exports.declare = exports.compose = exports.clampDuration = exports.clampBigInt = exports.clampBigDecimal = exports.clamp = exports.capitalized = exports.brand = exports.betweenDuration = exports.betweenDate = exports.betweenBigInt = exports.betweenBigDecimal = exports.between = exports.attachPropertySignature = void 0;
Object.defineProperty(exports, "decodeOption", {
  enumerable: true,
  get: function () {
    return ParseResult.decodeOption;
  }
});
exports.decodePromise = void 0;
Object.defineProperty(exports, "decodeSync", {
  enumerable: true,
  get: function () {
    return ParseResult.decodeSync;
  }
});
exports.decodeUnknownEither = exports.decodeUnknown = void 0;
Object.defineProperty(exports, "decodeUnknownOption", {
  enumerable: true,
  get: function () {
    return ParseResult.decodeUnknownOption;
  }
});
exports.decodeUnknownPromise = void 0;
Object.defineProperty(exports, "decodeUnknownSync", {
  enumerable: true,
  get: function () {
    return ParseResult.decodeUnknownSync;
  }
});
exports.encodeEither = exports.encode = exports.element = exports.deserializeSuccess = exports.deserializeFailure = exports.deserializeExit = exports.deserialize = void 0;
Object.defineProperty(exports, "encodeOption", {
  enumerable: true,
  get: function () {
    return ParseResult.encodeOption;
  }
});
exports.encodePromise = void 0;
Object.defineProperty(exports, "encodeSync", {
  enumerable: true,
  get: function () {
    return ParseResult.encodeSync;
  }
});
exports.encodeUnknownEither = exports.encodeUnknown = void 0;
Object.defineProperty(exports, "encodeUnknownOption", {
  enumerable: true,
  get: function () {
    return ParseResult.encodeUnknownOption;
  }
});
exports.encodeUnknownPromise = void 0;
Object.defineProperty(exports, "encodeUnknownSync", {
  enumerable: true,
  get: function () {
    return ParseResult.encodeUnknownSync;
  }
});
exports.failureSchema = exports.extend = exports.exitSchema = exports.equivalence = exports.endsWith = exports.encodedSchema = exports.encodedBoundSchema = void 0;
exports.filter = filter;
exports.int = exports.instanceOf = exports.includes = exports.headOrElse = exports.head = exports.greaterThanOrEqualToDuration = exports.greaterThanOrEqualToDate = exports.greaterThanOrEqualToBigInt = exports.greaterThanOrEqualToBigDecimal = exports.greaterThanOrEqualTo = exports.greaterThanDuration = exports.greaterThanDate = exports.greaterThanBigInt = exports.greaterThanBigDecimal = exports.greaterThan = exports.getNumberIndexedAccess = exports.getClassTag = exports.fromKey = exports.fromBrand = exports.format = exports.finite = exports.filterEffect = void 0;
Object.defineProperty(exports, "is", {
  enumerable: true,
  get: function () {
    return ParseResult.is;
  }
});
exports.lessThanOrEqualToDuration = exports.lessThanOrEqualToDate = exports.lessThanOrEqualToBigInt = exports.lessThanOrEqualToBigDecimal = exports.lessThanOrEqualTo = exports.lessThanDuration = exports.lessThanDate = exports.lessThanBigInt = exports.lessThanBigDecimal = exports.lessThan = exports.length = exports.keyof = exports.itemsCount = exports.isSchema = exports.isPropertySignature = void 0;
exports.transformLiteral = exports.transform = exports.tag = exports.symbolWithResult = exports.symbolSerializable = exports.suspend = exports.successSchema = exports.startsWith = exports.split = exports.serializeSuccess = exports.serializeFailure = exports.serializeExit = exports.serialize = exports.serializableSchema = exports.requiredToOptional = exports.required = exports.rename = exports.propertySignature = exports.positiveBigInt = exports.positiveBigDecimal = exports.positive = exports.pluck = exports.pickLiteral = exports.pick = exports.pattern = exports.partialWith = exports.partial = exports.parseNumber = exports.parseJson = exports.optionalWith = exports.optionalToRequired = exports.optionalToOptional = exports.optionalElement = exports.optional = exports.omit = exports.nonPositiveBigInt = exports.nonPositiveBigDecimal = exports.nonPositive = exports.nonNegativeBigInt = exports.nonNegativeBigDecimal = exports.nonNegative = exports.nonNaN = exports.nonEmptyString = exports.negativeBigInt = exports.negativeBigDecimal = exports.negative = exports.mutable = exports.multipleOf = exports.minLength = exports.minItems = exports.maxLength = exports.maxItems = exports.makePropertySignature = exports.make = exports.lowercased = void 0;
exports.transformLiterals = transformLiterals;
exports.validateEither = exports.validate = exports.validDate = exports.uppercased = exports.uncapitalized = exports.typeSchema = exports.trimmed = exports.transformOrFail = void 0;
Object.defineProperty(exports, "validateOption", {
  enumerable: true,
  get: function () {
    return ParseResult.validateOption;
  }
});
exports.validatePromise = void 0;
Object.defineProperty(exports, "validateSync", {
  enumerable: true,
  get: function () {
    return ParseResult.validateSync;
  }
});
exports.withDefaults = exports.withDecodingDefault = exports.withConstructorDefault = void 0;
var array_ = _interopRequireWildcard(require("./Array.js"));
var bigDecimal_ = _interopRequireWildcard(require("./BigDecimal.js"));
var bigInt_ = _interopRequireWildcard(require("./BigInt.js"));
var boolean_ = _interopRequireWildcard(require("./Boolean.js"));
var cause_ = _interopRequireWildcard(require("./Cause.js"));
var chunk_ = _interopRequireWildcard(require("./Chunk.js"));
var config_ = _interopRequireWildcard(require("./Config.js"));
var configError_ = _interopRequireWildcard(require("./ConfigError.js"));
var data_ = _interopRequireWildcard(require("./Data.js"));
var dateTime = _interopRequireWildcard(require("./DateTime.js"));
var duration_ = _interopRequireWildcard(require("./Duration.js"));
var Effect = _interopRequireWildcard(require("./Effect.js"));
var either_ = _interopRequireWildcard(require("./Either.js"));
var Encoding = _interopRequireWildcard(require("./Encoding.js"));
var Equal = _interopRequireWildcard(require("./Equal.js"));
var Equivalence = _interopRequireWildcard(require("./Equivalence.js"));
var exit_ = _interopRequireWildcard(require("./Exit.js"));
var fastCheck_ = _interopRequireWildcard(require("./FastCheck.js"));
var fiberId_ = _interopRequireWildcard(require("./FiberId.js"));
var _Function = require("./Function.js");
var _GlobalValue = require("./GlobalValue.js");
var hashMap_ = _interopRequireWildcard(require("./HashMap.js"));
var hashSet_ = _interopRequireWildcard(require("./HashSet.js"));
var errors_ = _interopRequireWildcard(require("./internal/schema/errors.js"));
var filters_ = _interopRequireWildcard(require("./internal/schema/filters.js"));
var util_ = _interopRequireWildcard(require("./internal/schema/util.js"));
var list_ = _interopRequireWildcard(require("./List.js"));
var number_ = _interopRequireWildcard(require("./Number.js"));
var option_ = _interopRequireWildcard(require("./Option.js"));
var ParseResult = _interopRequireWildcard(require("./ParseResult.js"));
var _Pipeable = require("./Pipeable.js");
var Predicate = _interopRequireWildcard(require("./Predicate.js"));
var record_ = _interopRequireWildcard(require("./Record.js"));
var redacted_ = _interopRequireWildcard(require("./Redacted.js"));
var Request = _interopRequireWildcard(require("./Request.js"));
var AST = _interopRequireWildcard(require("./SchemaAST.js"));
var sortedSet_ = _interopRequireWildcard(require("./SortedSet.js"));
var string_ = _interopRequireWildcard(require("./String.js"));
var struct_ = _interopRequireWildcard(require("./Struct.js"));
function _getRequireWildcardCache(e) { if ("function" != typeof WeakMap) return null; var r = new WeakMap(), t = new WeakMap(); return (_getRequireWildcardCache = function (e) { return e ? t : r; })(e); }
function _interopRequireWildcard(e, r) { if (!r && e && e.__esModule) return e; if (null === e || "object" != typeof e && "function" != typeof e) return { default: e }; var t = _getRequireWildcardCache(r); if (t && t.has(e)) return t.get(e); var n = { __proto__: null }, a = Object.defineProperty && Object.getOwnPropertyDescriptor; for (var u in e) if ("default" !== u && {}.hasOwnProperty.call(e, u)) { var i = a ? Object.getOwnPropertyDescriptor(e, u) : null; i && (i.get || i.set) ? Object.defineProperty(n, u, i) : n[u] = e[u]; } return n.default = e, t && t.set(e, n), n; }
/**
 * @since 3.10.0
 */

/**
 * @since 3.10.0
 * @category symbol
 */
const TypeId = exports.TypeId = /*#__PURE__*/Symbol.for("effect/Schema");
/**
 * @category constructors
 * @since 3.10.0
 */
const make = ast => class SchemaClass {
  [TypeId] = variance;
  static Type;
  static Encoded;
  static Context;
  static [TypeId] = variance;
  static ast = ast;
  static annotations(annotations) {
    return make(mergeSchemaAnnotations(this.ast, annotations));
  }
  static pipe() {
    return (0, _Pipeable.pipeArguments)(this, arguments);
  }
  static toString() {
    return String(ast);
  }
};
exports.make = make;
const variance = {
  /* c8 ignore next */
  _A: _ => _,
  /* c8 ignore next */
  _I: _ => _,
  /* c8 ignore next */
  _R: _ => _
};
const builtInAnnotations = {
  schemaId: AST.SchemaIdAnnotationId,
  message: AST.MessageAnnotationId,
  missingMessage: AST.MissingMessageAnnotationId,
  identifier: AST.IdentifierAnnotationId,
  title: AST.TitleAnnotationId,
  description: AST.DescriptionAnnotationId,
  examples: AST.ExamplesAnnotationId,
  default: AST.DefaultAnnotationId,
  documentation: AST.DocumentationAnnotationId,
  jsonSchema: AST.JSONSchemaAnnotationId,
  arbitrary: AST.ArbitraryAnnotationId,
  pretty: AST.PrettyAnnotationId,
  equivalence: AST.EquivalenceAnnotationId,
  concurrency: AST.ConcurrencyAnnotationId,
  batching: AST.BatchingAnnotationId,
  parseIssueTitle: AST.ParseIssueTitleAnnotationId,
  parseOptions: AST.ParseOptionsAnnotationId,
  decodingFallback: AST.DecodingFallbackAnnotationId
};
const toASTAnnotations = annotations => {
  if (!annotations) {
    return {};
  }
  const out = {
    ...annotations
  };
  for (const key in builtInAnnotations) {
    if (key in annotations) {
      const id = builtInAnnotations[key];
      out[id] = annotations[key];
      delete out[key];
    }
  }
  return out;
};
const mergeSchemaAnnotations = (ast, annotations) => AST.annotations(ast, toASTAnnotations(annotations));
/**
 * @since 3.10.0
 */
const asSchema = schema => schema;
/**
 * @category formatting
 * @since 3.10.0
 */
exports.asSchema = asSchema;
const format = schema => String(schema.ast);
/**
 * The `encodedSchema` function allows you to extract the `Encoded` portion of a
 * schema, creating a new schema that conforms to the properties defined in the
 * original schema without retaining any refinements or transformations that
 * were applied previously.
 *
 * @since 3.10.0
 */
exports.format = format;
const encodedSchema = schema => make(AST.encodedAST(schema.ast));
/**
 * The `encodedBoundSchema` function is similar to `encodedSchema` but preserves
 * the refinements up to the first transformation point in the original schema.
 *
 * @since 3.10.0
 */
exports.encodedSchema = encodedSchema;
const encodedBoundSchema = schema => make(AST.encodedBoundAST(schema.ast));
/**
 * The `typeSchema` function allows you to extract the `Type` portion of a
 * schema, creating a new schema that conforms to the properties defined in the
 * original schema without considering the initial encoding or transformation
 * processes.
 *
 * @since 3.10.0
 */
exports.encodedBoundSchema = encodedBoundSchema;
const typeSchema = schema => make(AST.typeAST(schema.ast));
/* c8 ignore start */
exports.typeSchema = typeSchema;
/* c8 ignore end */
/**
 * @category encoding
 * @since 3.10.0
 */
const encodeUnknown = (schema, options) => {
  const encodeUnknown = ParseResult.encodeUnknown(schema, options);
  return (u, overrideOptions) => ParseResult.mapError(encodeUnknown(u, overrideOptions), ParseResult.parseError);
};
/**
 * @category encoding
 * @since 3.10.0
 */
exports.encodeUnknown = encodeUnknown;
const encodeUnknownEither = (schema, options) => {
  const encodeUnknownEither = ParseResult.encodeUnknownEither(schema, options);
  return (u, overrideOptions) => either_.mapLeft(encodeUnknownEither(u, overrideOptions), ParseResult.parseError);
};
/**
 * @category encoding
 * @since 3.10.0
 */
exports.encodeUnknownEither = encodeUnknownEither;
const encodeUnknownPromise = (schema, options) => {
  const parser = encodeUnknown(schema, options);
  return (u, overrideOptions) => Effect.runPromise(parser(u, overrideOptions));
};
/**
 * @category encoding
 * @since 3.10.0
 */
exports.encodeUnknownPromise = encodeUnknownPromise;
const encode = exports.encode = encodeUnknown;
/**
 * @category encoding
 * @since 3.10.0
 */
const encodeEither = exports.encodeEither = encodeUnknownEither;
/**
 * @category encoding
 * @since 3.10.0
 */
const encodePromise = exports.encodePromise = encodeUnknownPromise;
/**
 * @category decoding
 * @since 3.10.0
 */
const decodeUnknown = (schema, options) => {
  const decodeUnknown = ParseResult.decodeUnknown(schema, options);
  return (u, overrideOptions) => ParseResult.mapError(decodeUnknown(u, overrideOptions), ParseResult.parseError);
};
/**
 * @category decoding
 * @since 3.10.0
 */
exports.decodeUnknown = decodeUnknown;
const decodeUnknownEither = (schema, options) => {
  const decodeUnknownEither = ParseResult.decodeUnknownEither(schema, options);
  return (u, overrideOptions) => either_.mapLeft(decodeUnknownEither(u, overrideOptions), ParseResult.parseError);
};
/**
 * @category decoding
 * @since 3.10.0
 */
exports.decodeUnknownEither = decodeUnknownEither;
const decodeUnknownPromise = (schema, options) => {
  const parser = decodeUnknown(schema, options);
  return (u, overrideOptions) => Effect.runPromise(parser(u, overrideOptions));
};
/**
 * @category decoding
 * @since 3.10.0
 */
exports.decodeUnknownPromise = decodeUnknownPromise;
const decode = exports.decode = decodeUnknown;
/**
 * @category decoding
 * @since 3.10.0
 */
const decodeEither = exports.decodeEither = decodeUnknownEither;
/**
 * @category decoding
 * @since 3.10.0
 */
const decodePromise = exports.decodePromise = decodeUnknownPromise;
/**
 * @category validation
 * @since 3.10.0
 */
const validate = (schema, options) => {
  const validate = ParseResult.validate(schema, options);
  return (u, overrideOptions) => ParseResult.mapError(validate(u, overrideOptions), ParseResult.parseError);
};
/**
 * @category validation
 * @since 3.10.0
 */
exports.validate = validate;
const validateEither = (schema, options) => {
  const validateEither = ParseResult.validateEither(schema, options);
  return (u, overrideOptions) => either_.mapLeft(validateEither(u, overrideOptions), ParseResult.parseError);
};
/**
 * @category validation
 * @since 3.10.0
 */
exports.validateEither = validateEither;
const validatePromise = (schema, options) => {
  const parser = validate(schema, options);
  return (u, overrideOptions) => Effect.runPromise(parser(u, overrideOptions));
};
/**
 * Tests if a value is a `Schema`.
 *
 * @category guards
 * @since 3.10.0
 */
exports.validatePromise = validatePromise;
const isSchema = u => Predicate.hasProperty(u, TypeId) && Predicate.isObject(u[TypeId]);
exports.isSchema = isSchema;
const getDefaultLiteralAST = literals => AST.isMembers(literals) ? AST.Union.make(AST.mapMembers(literals, literal => new AST.Literal(literal))) : new AST.Literal(literals[0]);
const makeLiteralClass = (literals, ast = getDefaultLiteralAST(literals)) => class LiteralClass extends make(ast) {
  static annotations(annotations) {
    return makeLiteralClass(this.literals, mergeSchemaAnnotations(this.ast, annotations));
  }
  static literals = [...literals];
};
function Literal(...literals) {
  return array_.isNonEmptyReadonlyArray(literals) ? makeLiteralClass(literals) : Never;
}
/**
 * Creates a new `Schema` from a literal schema.
 *
 * @example
 * import * as Schema from "effect/Schema"
 * import { Either } from "effect"
 *
 * const schema = Schema.Literal("a", "b", "c").pipe(Schema.pickLiteral("a", "b"))
 *
 * assert.deepStrictEqual(Schema.decodeSync(schema)("a"), "a")
 * assert.deepStrictEqual(Schema.decodeSync(schema)("b"), "b")
 * assert.strictEqual(Either.isLeft(Schema.decodeUnknownEither(schema)("c")), true)
 *
 * @category constructors
 * @since 3.10.0
 */
const pickLiteral = (...literals) => _schema => Literal(...literals);
/**
 * @category constructors
 * @since 3.10.0
 */
exports.pickLiteral = pickLiteral;
const UniqueSymbolFromSelf = symbol => make(new AST.UniqueSymbol(symbol));
exports.UniqueSymbolFromSelf = UniqueSymbolFromSelf;
const getDefaultEnumsAST = enums => new AST.Enums(Object.keys(enums).filter(key => typeof enums[enums[key]] !== "number").map(key => [key, enums[key]]));
const makeEnumsClass = (enums, ast = getDefaultEnumsAST(enums)) => class EnumsClass extends make(ast) {
  static annotations(annotations) {
    return makeEnumsClass(this.enums, mergeSchemaAnnotations(this.ast, annotations));
  }
  static enums = {
    ...enums
  };
};
/**
 * @category constructors
 * @since 3.10.0
 */
const Enums = enums => makeEnumsClass(enums);
/**
 * @category template literal
 * @since 3.10.0
 */
exports.Enums = Enums;
const TemplateLiteral = (...[head, ...tail]) => {
  let astOrs = getTemplateLiterals(getTemplateLiteralParameterAST(head));
  for (const span of tail) {
    astOrs = array_.flatMap(astOrs, a => getTemplateLiterals(getTemplateLiteralParameterAST(span)).map(b => combineTemplateLiterals(a, b)));
  }
  return make(AST.Union.make(astOrs.map(astOr => Predicate.isString(astOr) ? new AST.Literal(astOr) : astOr)));
};
exports.TemplateLiteral = TemplateLiteral;
const getTemplateLiteralParameterAST = span => isSchema(span) ? span.ast : new AST.Literal(String(span));
const combineTemplateLiterals = (a, b) => {
  if (Predicate.isString(a)) {
    return Predicate.isString(b) ? a + b : new AST.TemplateLiteral(a + b.head, b.spans);
  }
  if (Predicate.isString(b)) {
    return new AST.TemplateLiteral(a.head, array_.modifyNonEmptyLast(a.spans, span => new AST.TemplateLiteralSpan(span.type, span.literal + b)));
  }
  return new AST.TemplateLiteral(a.head, array_.appendAll(array_.modifyNonEmptyLast(a.spans, span => new AST.TemplateLiteralSpan(span.type, span.literal + String(b.head))), b.spans));
};
const getTemplateLiterals = ast => {
  switch (ast._tag) {
    case "Literal":
      return [String(ast.literal)];
    case "NumberKeyword":
    case "StringKeyword":
      return [new AST.TemplateLiteral("", [new AST.TemplateLiteralSpan(ast, "")])];
    case "Union":
      return array_.flatMap(ast.types, getTemplateLiterals);
  }
  throw new Error(errors_.getSchemaUnsupportedLiteralSpanErrorMessage(ast));
};
/**
 * @category template literal
 * @since 3.10.0
 */
const TemplateLiteralParser = (...params) => {
  const encodedSchemas = [];
  const typeSchemas = [];
  const numbers = [];
  for (let i = 0; i < params.length; i++) {
    const p = params[i];
    if (isSchema(p)) {
      const encoded = encodedSchema(p);
      if (AST.isNumberKeyword(encoded.ast)) {
        numbers.push(i);
      }
      encodedSchemas.push(encoded);
      typeSchemas.push(p);
    } else {
      const literal = Literal(p);
      encodedSchemas.push(literal);
      typeSchemas.push(literal);
    }
  }
  const from = TemplateLiteral(...encodedSchemas);
  const re = AST.getTemplateLiteralCapturingRegExp(from.ast);
  return class TemplateLiteralParserClass extends transform(from, Tuple(...typeSchemas), {
    strict: false,
    decode: s => {
      const out = re.exec(s).slice(1, params.length + 1);
      for (let i = 0; i < numbers.length; i++) {
        const index = numbers[i];
        out[index] = Number(out[index]);
      }
      return out;
    },
    encode: tuple => tuple.join("")
  }) {
    static params = params.slice();
  };
};
exports.TemplateLiteralParser = TemplateLiteralParser;
const declareConstructor = (typeParameters, options, annotations) => make(new AST.Declaration(typeParameters.map(tp => tp.ast), (...typeParameters) => options.decode(...typeParameters.map(make)), (...typeParameters) => options.encode(...typeParameters.map(make)), toASTAnnotations(annotations)));
const declarePrimitive = (is, annotations) => {
  const decodeUnknown = () => (input, _, ast) => is(input) ? ParseResult.succeed(input) : ParseResult.fail(new ParseResult.Type(ast, input));
  const encodeUnknown = decodeUnknown;
  return make(new AST.Declaration([], decodeUnknown, encodeUnknown, toASTAnnotations(annotations)));
};
/**
 * The constraint `R extends Schema.Context<P[number]>` enforces dependencies solely from `typeParameters`.
 * This ensures that when you call `Schema.to` or `Schema.from`, you receive a schema with a `never` context.
 *
 * @category constructors
 * @since 3.10.0
 */
const declare = function () {
  if (Array.isArray(arguments[0])) {
    const typeParameters = arguments[0];
    const options = arguments[1];
    const annotations = arguments[2];
    return declareConstructor(typeParameters, options, annotations);
  }
  const is = arguments[0];
  const annotations = arguments[1];
  return declarePrimitive(is, annotations);
};
/**
 * @category schema id
 * @since 3.10.0
 */
exports.declare = declare;
const BrandSchemaId = exports.BrandSchemaId = /*#__PURE__*/Symbol.for("effect/SchemaId/Brand");
/**
 * @category constructors
 * @since 3.10.0
 */
const fromBrand = (constructor, annotations) => self => makeBrandClass(new AST.Refinement(self.ast, function predicate(a, _, ast) {
  const either = constructor.either(a);
  return either_.isLeft(either) ? option_.some(new ParseResult.Type(ast, a, either.left.map(v => v.message).join(", "))) : option_.none();
}, toASTAnnotations({
  schemaId: BrandSchemaId,
  [BrandSchemaId]: {
    constructor
  },
  ...annotations
})));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.fromBrand = fromBrand;
const InstanceOfSchemaId = exports.InstanceOfSchemaId = /*#__PURE__*/Symbol.for("effect/SchemaId/InstanceOf");
/**
 * @category constructors
 * @since 3.10.0
 */
const instanceOf = (constructor, annotations) => declare(u => u instanceof constructor, {
  title: constructor.name,
  description: `an instance of ${constructor.name}`,
  pretty: () => String,
  schemaId: InstanceOfSchemaId,
  [InstanceOfSchemaId]: {
    constructor
  },
  ...annotations
});
/**
 * @category primitives
 * @since 3.10.0
 */
exports.instanceOf = instanceOf;
class Undefined extends /*#__PURE__*/make(AST.undefinedKeyword) {}
/**
 * @category primitives
 * @since 3.10.0
 */
exports.Undefined = Undefined;
class Void extends /*#__PURE__*/make(AST.voidKeyword) {}
/**
 * @category primitives
 * @since 3.10.0
 */
exports.Void = Void;
class Null extends /*#__PURE__*/make(AST.null) {}
/**
 * @category primitives
 * @since 3.10.0
 */
exports.Null = Null;
class Never extends /*#__PURE__*/make(AST.neverKeyword) {}
/**
 * @category primitives
 * @since 3.10.0
 */
exports.Never = Never;
class Unknown extends /*#__PURE__*/make(AST.unknownKeyword) {}
/**
 * @category primitives
 * @since 3.10.0
 */
exports.Unknown = Unknown;
class Any extends /*#__PURE__*/make(AST.anyKeyword) {}
/**
 * @category primitives
 * @since 3.10.0
 */
exports.Any = Any;
class BigIntFromSelf extends /*#__PURE__*/make(AST.bigIntKeyword) {}
/**
 * @category primitives
 * @since 3.10.0
 */
exports.BigIntFromSelf = BigIntFromSelf;
class SymbolFromSelf extends /*#__PURE__*/make(AST.symbolKeyword) {}
/** @ignore */
exports.SymbolFromSelf = SymbolFromSelf;
class String$ extends /*#__PURE__*/make(AST.stringKeyword) {}
/** @ignore */
exports.String = String$;
class Number$ extends /*#__PURE__*/make(AST.numberKeyword) {}
/** @ignore */
exports.Number = Number$;
class Boolean$ extends /*#__PURE__*/make(AST.booleanKeyword) {}
/** @ignore */
exports.Boolean = Boolean$;
class Object$ extends /*#__PURE__*/make(AST.objectKeyword) {}
exports.Object = Object$;
const getDefaultUnionAST = members => AST.Union.make(members.map(m => m.ast));
const makeUnionClass = (members, ast = getDefaultUnionAST(members)) => class UnionClass extends make(ast) {
  static annotations(annotations) {
    return makeUnionClass(this.members, mergeSchemaAnnotations(this.ast, annotations));
  }
  static members = [...members];
};
function Union(...members) {
  return AST.isMembers(members) ? makeUnionClass(members) : array_.isNonEmptyReadonlyArray(members) ? members[0] : Never;
}
/**
 * @category combinators
 * @since 3.10.0
 */
const NullOr = self => Union(self, Null);
/**
 * @category combinators
 * @since 3.10.0
 */
exports.NullOr = NullOr;
const UndefinedOr = self => Union(self, Undefined);
/**
 * @category combinators
 * @since 3.10.0
 */
exports.UndefinedOr = UndefinedOr;
const NullishOr = self => Union(self, Null, Undefined);
/**
 * @category combinators
 * @since 3.10.0
 */
exports.NullishOr = NullishOr;
const keyof = self => make(AST.keyof(self.ast));
/**
 * @since 3.10.0
 */
exports.keyof = keyof;
const element = self => new ElementImpl(new AST.OptionalType(self.ast, false), self);
/**
 * @since 3.10.0
 */
exports.element = element;
const optionalElement = self => new ElementImpl(new AST.OptionalType(self.ast, true), self);
exports.optionalElement = optionalElement;
class ElementImpl {
  ast;
  from;
  [TypeId];
  _Token;
  constructor(ast, from) {
    this.ast = ast;
    this.from = from;
  }
  annotations(annotations) {
    return new ElementImpl(new AST.OptionalType(this.ast.type, this.ast.isOptional, {
      ...this.ast.annotations,
      ...toASTAnnotations(annotations)
    }), this.from);
  }
  toString() {
    return `${this.ast.type}${this.ast.isOptional ? "?" : ""}`;
  }
}
const getDefaultTupleTypeAST = (elements, rest) => new AST.TupleType(elements.map(el => isSchema(el) ? new AST.OptionalType(el.ast, false) : el.ast), rest.map(el => isSchema(el) ? new AST.Type(el.ast) : el.ast), true);
const makeTupleTypeClass = (elements, rest, ast = getDefaultTupleTypeAST(elements, rest)) => class TupleTypeClass extends make(ast) {
  static annotations(annotations) {
    return makeTupleTypeClass(this.elements, this.rest, mergeSchemaAnnotations(this.ast, annotations));
  }
  static elements = [...elements];
  static rest = [...rest];
};
function Tuple(...args) {
  return Array.isArray(args[0]) ? makeTupleTypeClass(args[0], args.slice(1)) : makeTupleTypeClass(args, []);
}
const makeArrayClass = (value, ast) => class ArrayClass extends makeTupleTypeClass([], [value], ast) {
  static annotations(annotations) {
    return makeArrayClass(this.value, mergeSchemaAnnotations(this.ast, annotations));
  }
  static value = value;
};
const Array$ = value => makeArrayClass(value);
exports.Array = Array$;
const makeNonEmptyArrayClass = (value, ast) => class NonEmptyArrayClass extends makeTupleTypeClass([value], [value], ast) {
  static annotations(annotations) {
    return makeNonEmptyArrayClass(this.value, mergeSchemaAnnotations(this.ast, annotations));
  }
  static value = value;
};
/**
 * @category constructors
 * @since 3.10.0
 */
const NonEmptyArray = value => makeNonEmptyArrayClass(value);
/**
 * @category constructors
 * @since 3.10.0
 */
exports.NonEmptyArray = NonEmptyArray;
const ArrayEnsure = value => {
  const value_ = asSchema(value);
  return class ArrayEnsureClass extends transform(Union(value_, Array$(value_)), Array$(typeSchema(value_)), {
    strict: true,
    decode: array_.ensure,
    encode: arr => arr.length === 1 ? arr[0] : arr
  }) {};
};
/**
 * @category constructors
 * @since 3.10.0
 */
exports.ArrayEnsure = ArrayEnsure;
const NonEmptyArrayEnsure = value => {
  const value_ = asSchema(value);
  return class NonEmptyArrayEnsureClass extends transform(Union(value_, NonEmptyArray(value_)), NonEmptyArray(typeSchema(value_)), {
    strict: true,
    decode: array_.ensure,
    encode: arr => arr.length === 1 ? arr[0] : arr
  }) {};
};
exports.NonEmptyArrayEnsure = NonEmptyArrayEnsure;
const formatPropertySignatureToken = isOptional => isOptional ? "\"?:\"" : "\":\"";
/**
 * @category PropertySignature
 * @since 3.10.0
 */
class PropertySignatureDeclaration extends AST.OptionalType {
  isReadonly;
  defaultValue;
  /**
   * @since 3.10.0
   */
  _tag = "PropertySignatureDeclaration";
  constructor(type, isOptional, isReadonly, annotations, defaultValue) {
    super(type, isOptional, annotations);
    this.isReadonly = isReadonly;
    this.defaultValue = defaultValue;
  }
  /**
   * @since 3.10.0
   */
  toString() {
    const token = formatPropertySignatureToken(this.isOptional);
    const type = String(this.type);
    return `PropertySignature<${token}, ${type}, never, ${token}, ${type}>`;
  }
}
/**
 * @category PropertySignature
 * @since 3.10.0
 */
exports.PropertySignatureDeclaration = PropertySignatureDeclaration;
class FromPropertySignature extends AST.OptionalType {
  isReadonly;
  fromKey;
  constructor(type, isOptional, isReadonly, annotations, fromKey) {
    super(type, isOptional, annotations);
    this.isReadonly = isReadonly;
    this.fromKey = fromKey;
  }
}
/**
 * @category PropertySignature
 * @since 3.10.0
 */
exports.FromPropertySignature = FromPropertySignature;
class ToPropertySignature extends AST.OptionalType {
  isReadonly;
  defaultValue;
  constructor(type, isOptional, isReadonly, annotations, defaultValue) {
    super(type, isOptional, annotations);
    this.isReadonly = isReadonly;
    this.defaultValue = defaultValue;
  }
}
exports.ToPropertySignature = ToPropertySignature;
const formatPropertyKey = p => {
  if (p === undefined) {
    return "never";
  }
  if (Predicate.isString(p)) {
    return JSON.stringify(p);
  }
  return String(p);
};
/**
 * @category PropertySignature
 * @since 3.10.0
 */
class PropertySignatureTransformation {
  from;
  to;
  decode;
  encode;
  /**
   * @since 3.10.0
   */
  _tag = "PropertySignatureTransformation";
  constructor(from, to, decode, encode) {
    this.from = from;
    this.to = to;
    this.decode = decode;
    this.encode = encode;
  }
  /**
   * @since 3.10.0
   */
  toString() {
    return `PropertySignature<${formatPropertySignatureToken(this.to.isOptional)}, ${this.to.type}, ${formatPropertyKey(this.from.fromKey)}, ${formatPropertySignatureToken(this.from.isOptional)}, ${this.from.type}>`;
  }
}
exports.PropertySignatureTransformation = PropertySignatureTransformation;
const mergeSignatureAnnotations = (ast, annotations) => {
  switch (ast._tag) {
    case "PropertySignatureDeclaration":
      {
        return new PropertySignatureDeclaration(ast.type, ast.isOptional, ast.isReadonly, {
          ...ast.annotations,
          ...annotations
        }, ast.defaultValue);
      }
    case "PropertySignatureTransformation":
      {
        return new PropertySignatureTransformation(new FromPropertySignature(ast.from.type, ast.from.isOptional, ast.from.isReadonly, ast.from.annotations), new ToPropertySignature(ast.to.type, ast.to.isOptional, ast.to.isReadonly, {
          ...ast.to.annotations,
          ...annotations
        }, ast.to.defaultValue), ast.decode, ast.encode);
      }
  }
};
/**
 * @since 3.10.0
 * @category symbol
 */
const PropertySignatureTypeId = exports.PropertySignatureTypeId = /*#__PURE__*/Symbol.for("effect/PropertySignature");
/**
 * @since 3.10.0
 * @category guards
 */
const isPropertySignature = u => Predicate.hasProperty(u, PropertySignatureTypeId);
exports.isPropertySignature = isPropertySignature;
class PropertySignatureImpl {
  ast;
  [TypeId];
  [PropertySignatureTypeId] = null;
  _TypeToken;
  _Key;
  _EncodedToken;
  _HasDefault;
  constructor(ast) {
    this.ast = ast;
  }
  pipe() {
    return (0, _Pipeable.pipeArguments)(this, arguments);
  }
  annotations(annotations) {
    return new PropertySignatureImpl(mergeSignatureAnnotations(this.ast, toASTAnnotations(annotations)));
  }
  toString() {
    return String(this.ast);
  }
}
/**
 * @category PropertySignature
 * @since 3.10.0
 */
const makePropertySignature = ast => new PropertySignatureImpl(ast);
exports.makePropertySignature = makePropertySignature;
class PropertySignatureWithFromImpl extends PropertySignatureImpl {
  from;
  constructor(ast, from) {
    super(ast);
    this.from = from;
  }
  annotations(annotations) {
    return new PropertySignatureWithFromImpl(mergeSignatureAnnotations(this.ast, toASTAnnotations(annotations)), this.from);
  }
}
/**
 * Lifts a `Schema` into a `PropertySignature`.
 *
 * @category PropertySignature
 * @since 3.10.0
 */
const propertySignature = self => new PropertySignatureWithFromImpl(new PropertySignatureDeclaration(self.ast, false, true, {}, undefined), self);
/**
 * Enhances a property signature with a default constructor value.
 *
 * @category PropertySignature
 * @since 3.10.0
 */
exports.propertySignature = propertySignature;
const withConstructorDefault = exports.withConstructorDefault = /*#__PURE__*/(0, _Function.dual)(2, (self, defaultValue) => {
  const ast = self.ast;
  switch (ast._tag) {
    case "PropertySignatureDeclaration":
      return makePropertySignature(new PropertySignatureDeclaration(ast.type, ast.isOptional, ast.isReadonly, ast.annotations, defaultValue));
    case "PropertySignatureTransformation":
      return makePropertySignature(new PropertySignatureTransformation(ast.from, new ToPropertySignature(ast.to.type, ast.to.isOptional, ast.to.isReadonly, ast.to.annotations, defaultValue), ast.decode, ast.encode));
  }
});
const applyDefaultValue = (o, defaultValue) => option_.match(o, {
  onNone: () => option_.some(defaultValue()),
  onSome: value => option_.some(value === undefined ? defaultValue() : value)
});
/**
 * Enhances a property signature with a default decoding value.
 *
 * @category PropertySignature
 * @since 3.10.0
 */
const withDecodingDefault = exports.withDecodingDefault = /*#__PURE__*/(0, _Function.dual)(2, (self, defaultValue) => {
  const ast = self.ast;
  switch (ast._tag) {
    case "PropertySignatureDeclaration":
      return makePropertySignature(new PropertySignatureTransformation(ast, new ToPropertySignature(AST.typeAST(ast.type), false, true, {}, undefined), o => applyDefaultValue(o, defaultValue), _Function.identity));
    case "PropertySignatureTransformation":
      return makePropertySignature(new PropertySignatureTransformation(ast.from, new ToPropertySignature(ast.to.type, false, ast.to.isReadonly, ast.to.annotations, ast.to.defaultValue), o => applyDefaultValue(ast.decode(o), defaultValue), ast.encode));
  }
});
/**
 * Enhances a property signature with a default decoding value and a default constructor value.
 *
 * @category PropertySignature
 * @since 3.10.0
 */
const withDefaults = exports.withDefaults = /*#__PURE__*/(0, _Function.dual)(2, (self, defaults) => self.pipe(withDecodingDefault(defaults.decoding), withConstructorDefault(defaults.constructor)));
/**
 * Enhances a property signature by specifying a different key for it in the Encoded type.
 *
 * @category PropertySignature
 * @since 3.10.0
 */
const fromKey = exports.fromKey = /*#__PURE__*/(0, _Function.dual)(2, (self, key) => {
  const ast = self.ast;
  switch (ast._tag) {
    case "PropertySignatureDeclaration":
      {
        return makePropertySignature(new PropertySignatureTransformation(new FromPropertySignature(ast.type, ast.isOptional, ast.isReadonly, ast.annotations, key), new ToPropertySignature(AST.typeAST(ast.type), ast.isOptional, ast.isReadonly, {}, ast.defaultValue), _Function.identity, _Function.identity));
      }
    case "PropertySignatureTransformation":
      return makePropertySignature(new PropertySignatureTransformation(new FromPropertySignature(ast.from.type, ast.from.isOptional, ast.from.isReadonly, ast.from.annotations, key), ast.to, ast.decode, ast.encode));
  }
});
/**
 * Converts an optional property to a required one through a transformation `Option -> Type`.
 *
 * - `decode`: `none` as argument means the value is missing in the input.
 * - `encode`: `none` as return value means the value will be missing in the output.
 *
 * @category PropertySignature
 * @since 3.10.0
 */
const optionalToRequired = (from, to, options) => makePropertySignature(new PropertySignatureTransformation(new FromPropertySignature(from.ast, true, true, {}, undefined), new ToPropertySignature(to.ast, false, true, {}, undefined), o => option_.some(options.decode(o)), option_.flatMap(options.encode)));
/**
 * Converts an optional property to a required one through a transformation `Type -> Option`.
 *
 * - `decode`: `none` as return value means the value will be missing in the output.
 * - `encode`: `none` as argument means the value is missing in the input.
 *
 * @category PropertySignature
 * @since 3.10.0
 */
exports.optionalToRequired = optionalToRequired;
const requiredToOptional = (from, to, options) => makePropertySignature(new PropertySignatureTransformation(new FromPropertySignature(from.ast, false, true, {}, undefined), new ToPropertySignature(to.ast, true, true, {}, undefined), option_.flatMap(options.decode), o => option_.some(options.encode(o))));
/**
 * Converts an optional property to another optional property through a transformation `Option -> Option`.
 *
 * - `decode`:
 *   - `none` as argument means the value is missing in the input.
 *   - `none` as return value means the value will be missing in the output.
 * - `encode`:
 *   - `none` as argument means the value is missing in the input.
 *   - `none` as return value means the value will be missing in the output.
 *
 * @category PropertySignature
 * @since 3.10.0
 */
exports.requiredToOptional = requiredToOptional;
const optionalToOptional = (from, to, options) => makePropertySignature(new PropertySignatureTransformation(new FromPropertySignature(from.ast, true, true, {}, undefined), new ToPropertySignature(to.ast, true, true, {}, undefined), options.decode, options.encode));
exports.optionalToOptional = optionalToOptional;
const optionalPropertySignatureAST = (self, options) => {
  const isExact = options?.exact;
  const defaultValue = options?.default;
  const isNullable = options?.nullable;
  const asOption = options?.as == "Option";
  const asOptionEncode = options?.onNoneEncoding ? option_.orElse(options.onNoneEncoding) : _Function.identity;
  if (isExact) {
    if (defaultValue) {
      if (isNullable) {
        return withConstructorDefault(optionalToRequired(NullOr(self), typeSchema(self), {
          decode: option_.match({
            onNone: defaultValue,
            onSome: a => a === null ? defaultValue() : a
          }),
          encode: option_.some
        }), defaultValue).ast;
      } else {
        return withConstructorDefault(optionalToRequired(self, typeSchema(self), {
          decode: option_.match({
            onNone: defaultValue,
            onSome: _Function.identity
          }),
          encode: option_.some
        }), defaultValue).ast;
      }
    } else if (asOption) {
      if (isNullable) {
        return optionalToRequired(NullOr(self), OptionFromSelf(typeSchema(self)), {
          decode: option_.filter(Predicate.isNotNull),
          encode: asOptionEncode
        }).ast;
      } else {
        return optionalToRequired(self, OptionFromSelf(typeSchema(self)), {
          decode: _Function.identity,
          encode: _Function.identity
        }).ast;
      }
    } else {
      if (isNullable) {
        return optionalToOptional(NullOr(self), typeSchema(self), {
          decode: option_.filter(Predicate.isNotNull),
          encode: _Function.identity
        }).ast;
      } else {
        return new PropertySignatureDeclaration(self.ast, true, true, {}, undefined);
      }
    }
  } else {
    if (defaultValue) {
      if (isNullable) {
        return withConstructorDefault(optionalToRequired(NullishOr(self), typeSchema(self), {
          decode: option_.match({
            onNone: defaultValue,
            onSome: a => a == null ? defaultValue() : a
          }),
          encode: option_.some
        }), defaultValue).ast;
      } else {
        return withConstructorDefault(optionalToRequired(UndefinedOr(self), typeSchema(self), {
          decode: option_.match({
            onNone: defaultValue,
            onSome: a => a === undefined ? defaultValue() : a
          }),
          encode: option_.some
        }), defaultValue).ast;
      }
    } else if (asOption) {
      if (isNullable) {
        return optionalToRequired(NullishOr(self), OptionFromSelf(typeSchema(self)), {
          decode: option_.filter(a => a != null),
          encode: asOptionEncode
        }).ast;
      } else {
        return optionalToRequired(UndefinedOr(self), OptionFromSelf(typeSchema(self)), {
          decode: option_.filter(Predicate.isNotUndefined),
          encode: asOptionEncode
        }).ast;
      }
    } else {
      if (isNullable) {
        return optionalToOptional(NullishOr(self), UndefinedOr(typeSchema(self)), {
          decode: option_.filter(Predicate.isNotNull),
          encode: _Function.identity
        }).ast;
      } else {
        return new PropertySignatureDeclaration(UndefinedOr(self).ast, true, true, {}, undefined);
      }
    }
  }
};
/**
 * @category PropertySignature
 * @since 3.10.0
 */
const optional = self => {
  const ast = self.ast === AST.undefinedKeyword || self.ast === AST.neverKeyword ? AST.undefinedKeyword : UndefinedOr(self).ast;
  return new PropertySignatureWithFromImpl(new PropertySignatureDeclaration(ast, true, true, {}, undefined), self);
};
/**
 * @category PropertySignature
 * @since 3.10.0
 */
exports.optional = optional;
const optionalWith = exports.optionalWith = /*#__PURE__*/(0, _Function.dual)(args => isSchema(args[0]), (self, options) => {
  return new PropertySignatureWithFromImpl(optionalPropertySignatureAST(self, options), self);
});
const getDefaultTypeLiteralAST = (fields, records) => {
  const ownKeys = util_.ownKeys(fields);
  const pss = [];
  if (ownKeys.length > 0) {
    const from = [];
    const to = [];
    const transformations = [];
    for (let i = 0; i < ownKeys.length; i++) {
      const key = ownKeys[i];
      const field = fields[key];
      if (isPropertySignature(field)) {
        const ast = field.ast;
        switch (ast._tag) {
          case "PropertySignatureDeclaration":
            {
              const type = ast.type;
              const isOptional = ast.isOptional;
              const toAnnotations = ast.annotations;
              from.push(new AST.PropertySignature(key, type, isOptional, true));
              to.push(new AST.PropertySignature(key, AST.typeAST(type), isOptional, true, toAnnotations));
              pss.push(new AST.PropertySignature(key, type, isOptional, true, toAnnotations));
              break;
            }
          case "PropertySignatureTransformation":
            {
              const fromKey = ast.from.fromKey ?? key;
              from.push(new AST.PropertySignature(fromKey, ast.from.type, ast.from.isOptional, true, ast.from.annotations));
              to.push(new AST.PropertySignature(key, ast.to.type, ast.to.isOptional, true, ast.to.annotations));
              transformations.push(new AST.PropertySignatureTransformation(fromKey, key, ast.decode, ast.encode));
              break;
            }
        }
      } else {
        from.push(new AST.PropertySignature(key, field.ast, false, true));
        to.push(new AST.PropertySignature(key, AST.typeAST(field.ast), false, true));
        pss.push(new AST.PropertySignature(key, field.ast, false, true));
      }
    }
    if (array_.isNonEmptyReadonlyArray(transformations)) {
      const issFrom = [];
      const issTo = [];
      for (const r of records) {
        const {
          indexSignatures,
          propertySignatures
        } = AST.record(r.key.ast, r.value.ast);
        propertySignatures.forEach(ps => {
          from.push(ps);
          to.push(new AST.PropertySignature(ps.name, AST.typeAST(ps.type), ps.isOptional, ps.isReadonly, ps.annotations));
        });
        indexSignatures.forEach(is => {
          issFrom.push(is);
          issTo.push(new AST.IndexSignature(is.parameter, AST.typeAST(is.type), is.isReadonly));
        });
      }
      return new AST.Transformation(new AST.TypeLiteral(from, issFrom, {
        [AST.TitleAnnotationId]: "Struct (Encoded side)"
      }), new AST.TypeLiteral(to, issTo, {
        [AST.TitleAnnotationId]: "Struct (Type side)"
      }), new AST.TypeLiteralTransformation(transformations));
    }
  }
  const iss = [];
  for (const r of records) {
    const {
      indexSignatures,
      propertySignatures
    } = AST.record(r.key.ast, r.value.ast);
    propertySignatures.forEach(ps => pss.push(ps));
    indexSignatures.forEach(is => iss.push(is));
  }
  return new AST.TypeLiteral(pss, iss);
};
const lazilyMergeDefaults = (fields, out) => {
  const ownKeys = util_.ownKeys(fields);
  for (const key of ownKeys) {
    const field = fields[key];
    if (out[key] === undefined && isPropertySignature(field)) {
      const ast = field.ast;
      const defaultValue = ast._tag === "PropertySignatureDeclaration" ? ast.defaultValue : ast.to.defaultValue;
      if (defaultValue !== undefined) {
        out[key] = defaultValue();
      }
    }
  }
  return out;
};
const makeTypeLiteralClass = (fields, records, ast = getDefaultTypeLiteralAST(fields, records)) => {
  return class TypeLiteralClass extends make(ast) {
    static annotations(annotations) {
      return makeTypeLiteralClass(this.fields, this.records, mergeSchemaAnnotations(this.ast, annotations));
    }
    static fields = {
      ...fields
    };
    static records = [...records];
    static make = (props, options) => {
      const propsWithDefaults = lazilyMergeDefaults(fields, {
        ...props
      });
      return getDisableValidationMakeOption(options) ? propsWithDefaults : ParseResult.validateSync(this)(propsWithDefaults);
    };
    static pick(...keys) {
      return Struct(struct_.pick(fields, ...keys));
    }
    static omit(...keys) {
      return Struct(struct_.omit(fields, ...keys));
    }
  };
};
function Struct(fields, ...records) {
  return makeTypeLiteralClass(fields, records);
}
/**
 * Returns a property signature that represents a tag.
 * A tag is a literal value that is used to distinguish between different types of objects.
 * The tag is optional when using the `make` method.
 *
 * @see {@link TaggedStruct}
 *
 * @example
 * import { Schema } from "effect"
 *
 * const User = Schema.Struct({
 *   _tag: Schema.tag("User"),
 *   name: Schema.String,
 *   age: Schema.Number
 * })
 *
 * assert.deepStrictEqual(User.make({ name: "John", age: 44 }), { _tag: "User", name: "John", age: 44 })
 *
 * @since 3.10.0
 */
const tag = tag => Literal(tag).pipe(propertySignature, withConstructorDefault(() => tag));
/**
 * A tagged struct is a struct that has a tag property that is used to distinguish between different types of objects.
 *
 * The tag is optional when using the `make` method.
 *
 * @example
 * import { Schema } from "effect"
 *
 * const User = Schema.TaggedStruct("User", {
 *   name: Schema.String,
 *   age: Schema.Number
 * })
 *
 * assert.deepStrictEqual(User.make({ name: "John", age: 44 }), { _tag: "User", name: "John", age: 44 })
 *
 * @category constructors
 * @since 3.10.0
 */
exports.tag = tag;
const TaggedStruct = (value, fields) => Struct({
  _tag: tag(value),
  ...fields
});
exports.TaggedStruct = TaggedStruct;
const makeRecordClass = (key, value, ast) => class RecordClass extends makeTypeLiteralClass({}, [{
  key,
  value
}], ast) {
  static annotations(annotations) {
    return makeRecordClass(key, value, mergeSchemaAnnotations(this.ast, annotations));
  }
  static key = key;
  static value = value;
};
/**
 * @category constructors
 * @since 3.10.0
 */
const Record = options => makeRecordClass(options.key, options.value);
/**
 * @category struct transformations
 * @since 3.10.0
 */
exports.Record = Record;
const pick = (...keys) => self => make(AST.pick(self.ast, keys));
/**
 * @category struct transformations
 * @since 3.10.0
 */
exports.pick = pick;
const omit = (...keys) => self => make(AST.omit(self.ast, keys));
/**
 * Given a schema `Schema<A, I, R>` and a key `key: K`, this function extracts a specific field from the `A` type,
 * producing a new schema that represents a transformation from the `{ readonly [key]: I[K] }` type to `A[K]`.
 *
 * @example
 * import * as Schema from "effect/Schema"
 *
 * // ---------------------------------------------
 * // use case: pull out a single field from a
 * // struct through a transformation
 * // ---------------------------------------------
 *
 * const mytable = Schema.Struct({
 *   column1: Schema.NumberFromString,
 *   column2: Schema.Number
 * })
 *
 * // const pullOutColumn: S.Schema<number, {
 * //     readonly column1: string;
 * // }, never>
 * const pullOutColumn = mytable.pipe(Schema.pluck("column1"))
 *
 * console.log(Schema.decodeUnknownEither(Schema.Array(pullOutColumn))([{ column1: "1", column2: 100 }, { column1: "2", column2: 300 }]))
 * // Output: { _id: 'Either', _tag: 'Right', right: [ 1, 2 ] }
 *
 * @category struct transformations
 * @since 3.10.0
 */
exports.omit = omit;
const pluck = exports.pluck = /*#__PURE__*/(0, _Function.dual)(2, (schema, key) => {
  const ps = AST.getPropertyKeyIndexedAccess(AST.typeAST(schema.ast), key);
  const value = make(ps.isOptional ? AST.orUndefined(ps.type) : ps.type);
  return transform(schema.pipe(pick(key)), value, {
    strict: true,
    decode: a => a[key],
    encode: ak => ps.isOptional && ak === undefined ? {} : {
      [key]: ak
    }
  });
});
const makeBrandClass = ast => class BrandClass extends make(ast) {
  static annotations(annotations) {
    return makeBrandClass(mergeSchemaAnnotations(this.ast, annotations));
  }
  static make = (a, options) => {
    return getDisableValidationMakeOption(options) ? a : ParseResult.validateSync(this)(a);
  };
};
/**
 * Returns a nominal branded schema by applying a brand to a given schema.
 *
 * ```
 * Schema<A> + B -> Schema<A & Brand<B>>
 * ```
 *
 * @param self - The input schema to be combined with the brand.
 * @param brand - The brand to apply.
 *
 * @example
 * import * as Schema from "effect/Schema"
 *
 * const Int = Schema.Number.pipe(Schema.int(), Schema.brand("Int"))
 * type Int = Schema.Schema.Type<typeof Int> // number & Brand<"Int">
 *
 * @category branding
 * @since 3.10.0
 */
const brand = (brand, annotations) => self => {
  const annotation = option_.match(AST.getBrandAnnotation(self.ast), {
    onNone: () => [brand],
    onSome: brands => [...brands, brand]
  });
  const ast = AST.annotations(self.ast, toASTAnnotations({
    // add a default title annotation containing the brand
    title: String(self.ast) + ` & Brand<${util_.formatUnknown(brand)}>`,
    ...annotations,
    [AST.BrandAnnotationId]: annotation
  }));
  return makeBrandClass(ast);
};
/**
 * @category combinators
 * @since 3.10.0
 */
exports.brand = brand;
const partial = self => make(AST.partial(self.ast));
/**
 * @category combinators
 * @since 3.10.0
 */
exports.partial = partial;
const partialWith = exports.partialWith = /*#__PURE__*/(0, _Function.dual)(args => isSchema(args[0]), (self, options) => make(AST.partial(self.ast, options)));
/**
 * @category combinators
 * @since 3.10.0
 */
const required = self => make(AST.required(self.ast));
/**
 * Creates a new schema with shallow mutability applied to its properties.
 *
 * @param schema - The original schema to make properties mutable (shallowly).
 *
 * @category combinators
 * @since 3.10.0
 */
exports.required = required;
const mutable = schema => make(AST.mutable(schema.ast));
exports.mutable = mutable;
const intersectTypeLiterals = (x, y, path) => {
  if (AST.isTypeLiteral(x) && AST.isTypeLiteral(y)) {
    const propertySignatures = [...x.propertySignatures];
    for (const ps of y.propertySignatures) {
      const name = ps.name;
      const i = propertySignatures.findIndex(ps => ps.name === name);
      if (i === -1) {
        propertySignatures.push(ps);
      } else {
        const {
          isOptional,
          type
        } = propertySignatures[i];
        propertySignatures[i] = new AST.PropertySignature(name, extendAST(type, ps.type, path.concat(name)), isOptional, true);
      }
    }
    return new AST.TypeLiteral(propertySignatures, x.indexSignatures.concat(y.indexSignatures));
  }
  throw new Error(errors_.getSchemaExtendErrorMessage(x, y, path));
};
const preserveRefinementAnnotations = /*#__PURE__*/AST.blackListAnnotations([AST.IdentifierAnnotationId]);
const addRefinementToMembers = (refinement, asts) => asts.map(ast => new AST.Refinement(ast, refinement.filter, preserveRefinementAnnotations(refinement)));
const extendAST = (x, y, path) => AST.Union.make(intersectUnionMembers([x], [y], path));
const getTypes = ast => AST.isUnion(ast) ? ast.types : [ast];
const intersectUnionMembers = (xs, ys, path) => array_.flatMap(xs, x => array_.flatMap(ys, y => {
  switch (y._tag) {
    case "Literal":
      {
        if (Predicate.isString(y.literal) && AST.isStringKeyword(x) || Predicate.isNumber(y.literal) && AST.isNumberKeyword(x) || Predicate.isBoolean(y.literal) && AST.isBooleanKeyword(x)) {
          return [y];
        }
        break;
      }
    case "StringKeyword":
      {
        if (y === AST.stringKeyword) {
          if (AST.isStringKeyword(x) || AST.isLiteral(x) && Predicate.isString(x.literal)) {
            return [x];
          } else if (AST.isRefinement(x)) {
            return addRefinementToMembers(x, intersectUnionMembers(getTypes(x.from), [y], path));
          }
        } else if (x === AST.stringKeyword) {
          return [y];
        }
        break;
      }
    case "NumberKeyword":
      {
        if (y === AST.numberKeyword) {
          if (AST.isNumberKeyword(x) || AST.isLiteral(x) && Predicate.isNumber(x.literal)) {
            return [x];
          } else if (AST.isRefinement(x)) {
            return addRefinementToMembers(x, intersectUnionMembers(getTypes(x.from), [y], path));
          }
        } else if (x === AST.numberKeyword) {
          return [y];
        }
        break;
      }
    case "BooleanKeyword":
      {
        if (y === AST.booleanKeyword) {
          if (AST.isBooleanKeyword(x) || AST.isLiteral(x) && Predicate.isBoolean(x.literal)) {
            return [x];
          } else if (AST.isRefinement(x)) {
            return addRefinementToMembers(x, intersectUnionMembers(getTypes(x.from), [y], path));
          }
        } else if (x === AST.booleanKeyword) {
          return [y];
        }
        break;
      }
    case "Union":
      return intersectUnionMembers(getTypes(x), y.types, path);
    case "Suspend":
      return [new AST.Suspend(() => extendAST(x, y.f(), path))];
    case "Refinement":
      return addRefinementToMembers(y, intersectUnionMembers(getTypes(x), getTypes(y.from), path));
    case "TypeLiteral":
      {
        switch (x._tag) {
          case "Union":
            return intersectUnionMembers(x.types, [y], path);
          case "Suspend":
            return [new AST.Suspend(() => extendAST(x.f(), y, path))];
          case "Refinement":
            return addRefinementToMembers(x, intersectUnionMembers(getTypes(x.from), [y], path));
          case "TypeLiteral":
            return [intersectTypeLiterals(x, y, path)];
          case "Transformation":
            {
              if (AST.isTypeLiteralTransformation(x.transformation)) {
                return [new AST.Transformation(intersectTypeLiterals(x.from, y, path), intersectTypeLiterals(x.to, AST.typeAST(y), path), new AST.TypeLiteralTransformation(x.transformation.propertySignatureTransformations))];
              }
              break;
            }
        }
        break;
      }
    case "Transformation":
      {
        if (AST.isTypeLiteralTransformation(y.transformation)) {
          switch (x._tag) {
            case "Union":
              return intersectUnionMembers(x.types, [y], path);
            case "Suspend":
              return [new AST.Suspend(() => extendAST(x.f(), y, path))];
            case "Refinement":
              return addRefinementToMembers(x, intersectUnionMembers(getTypes(x.from), [y], path));
            case "TypeLiteral":
              return [new AST.Transformation(intersectTypeLiterals(x, y.from, path), intersectTypeLiterals(AST.typeAST(x), y.to, path), new AST.TypeLiteralTransformation(y.transformation.propertySignatureTransformations))];
            case "Transformation":
              {
                if (AST.isTypeLiteralTransformation(x.transformation)) {
                  return [new AST.Transformation(intersectTypeLiterals(x.from, y.from, path), intersectTypeLiterals(x.to, y.to, path), new AST.TypeLiteralTransformation(y.transformation.propertySignatureTransformations.concat(x.transformation.propertySignatureTransformations)))];
                }
              }
              break;
          }
        }
        break;
      }
  }
  throw new Error(errors_.getSchemaExtendErrorMessage(x, y, path));
}));
/**
 * Extends a schema with another schema.
 *
 * Not all extensions are supported, and their support depends on the nature of the involved schemas.
 *
 * Possible extensions include:
 * - `Schema.String` with another `Schema.String` refinement or a string literal
 * - `Schema.Number` with another `Schema.Number` refinement or a number literal
 * - `Schema.Boolean` with another `Schema.Boolean` refinement or a boolean literal
 * - A struct with another struct where overlapping fields support extension
 * - A struct with in index signature
 * - A struct with a union of supported schemas
 * - A refinement of a struct with a supported schema
 * - A suspend of a struct with a supported schema
 *
 * @example
 * import * as Schema from "effect/Schema"
 *
 * const schema = Schema.Struct({
 *   a: Schema.String,
 *   b: Schema.String
 * })
 *
 * // const extended: Schema<
 * //   {
 * //     readonly a: string
 * //     readonly b: string
 * //   } & {
 * //     readonly c: string
 * //   } & {
 * //     readonly [x: string]: string
 * //   }
 * // >
 * const extended = Schema.asSchema(schema.pipe(
 *   Schema.extend(Schema.Struct({ c: Schema.String })), // <= you can add more fields
 *   Schema.extend(Schema.Record({ key: Schema.String, value: Schema.String })) // <= you can add index signatures
 * ))
 *
 * @category combinators
 * @since 3.10.0
 */
const extend = exports.extend = /*#__PURE__*/(0, _Function.dual)(2, (self, that) => make(extendAST(self.ast, that.ast, [])));
/**
 * @category combinators
 * @since 3.10.0
 */
const compose = exports.compose = /*#__PURE__*/(0, _Function.dual)(args => isSchema(args[1]), (from, to) => make(AST.compose(from.ast, to.ast)));
/**
 * @category constructors
 * @since 3.10.0
 */
const suspend = f => make(new AST.Suspend(() => f().ast));
/**
 * @since 3.10.0
 * @category symbol
 */
exports.suspend = suspend;
const RefineSchemaId = exports.RefineSchemaId = /*#__PURE__*/Symbol.for("effect/SchemaId/Refine");
const makeRefineClass = (from, filter, ast) => class RefineClass extends make(ast) {
  static annotations(annotations) {
    return makeRefineClass(this.from, this.filter, mergeSchemaAnnotations(this.ast, annotations));
  }
  static [RefineSchemaId] = from;
  static from = from;
  static filter = filter;
  static make = (a, options) => {
    return getDisableValidationMakeOption(options) ? a : ParseResult.validateSync(this)(a);
  };
};
const fromFilterPredicateReturnTypeItem = (item, ast, input) => {
  if (Predicate.isBoolean(item)) {
    return item ? option_.none() : option_.some(new ParseResult.Type(ast, input));
  }
  if (Predicate.isString(item)) {
    return option_.some(new ParseResult.Type(ast, input, item));
  }
  if (item !== undefined) {
    if ("_tag" in item) {
      return option_.some(item);
    }
    const issue = new ParseResult.Type(ast, input, item.message);
    return option_.some(array_.isNonEmptyReadonlyArray(item.path) ? new ParseResult.Pointer(item.path, input, issue) : issue);
  }
  return option_.none();
};
const toFilterParseIssue = (out, ast, input) => {
  if (util_.isSingle(out)) {
    return fromFilterPredicateReturnTypeItem(out, ast, input);
  }
  if (array_.isNonEmptyReadonlyArray(out)) {
    const issues = array_.filterMap(out, issue => fromFilterPredicateReturnTypeItem(issue, ast, input));
    if (array_.isNonEmptyReadonlyArray(issues)) {
      return option_.some(issues.length === 1 ? issues[0] : new ParseResult.Composite(ast, input, issues));
    }
  }
  return option_.none();
};
function filter(predicate, annotations) {
  return self => {
    function filter(input, options, ast) {
      return toFilterParseIssue(predicate(input, options, ast), ast, input);
    }
    const ast = new AST.Refinement(self.ast, filter, toASTAnnotations(annotations));
    return makeRefineClass(self, filter, ast);
  };
}
/**
 * @category transformations
 * @since 3.10.0
 */
const filterEffect = exports.filterEffect = /*#__PURE__*/(0, _Function.dual)(2, (self, f) => transformOrFail(self, typeSchema(self), {
  strict: true,
  decode: (a, options, ast) => ParseResult.flatMap(f(a, options, ast), filterReturnType => option_.match(toFilterParseIssue(filterReturnType, ast, a), {
    onNone: () => ParseResult.succeed(a),
    onSome: ParseResult.fail
  })),
  encode: ParseResult.succeed
}));
const makeTransformationClass = (from, to, ast) => class TransformationClass extends make(ast) {
  static annotations(annotations) {
    return makeTransformationClass(this.from, this.to, mergeSchemaAnnotations(this.ast, annotations));
  }
  static from = from;
  static to = to;
};
/**
 * Create a new `Schema` by transforming the input and output of an existing `Schema`
 * using the provided decoding functions.
 *
 * @category transformations
 * @since 3.10.0
 */
const transformOrFail = exports.transformOrFail = /*#__PURE__*/(0, _Function.dual)(args => isSchema(args[0]) && isSchema(args[1]), (from, to, options) => makeTransformationClass(from, to, new AST.Transformation(from.ast, to.ast, new AST.FinalTransformation(options.decode, options.encode))));
/**
 * Create a new `Schema` by transforming the input and output of an existing `Schema`
 * using the provided mapping functions.
 *
 * @category transformations
 * @since 3.10.0
 */
const transform = exports.transform = /*#__PURE__*/(0, _Function.dual)(args => isSchema(args[0]) && isSchema(args[1]), (from, to, options) => transformOrFail(from, to, {
  strict: true,
  decode: (fromA, _options, _ast, toA) => ParseResult.succeed(options.decode(fromA, toA)),
  encode: (toI, _options, _ast, toA) => ParseResult.succeed(options.encode(toI, toA))
}));
/**
 * Creates a new `Schema` which transforms literal values.
 *
 * @example
 * import * as S from "effect/Schema"
 *
 * const schema = S.transformLiteral(0, "a")
 *
 * assert.deepStrictEqual(S.decodeSync(schema)(0), "a")
 *
 * @category constructors
 * @since 3.10.0
 */
const transformLiteral = (from, to) => transform(Literal(from), Literal(to), {
  strict: true,
  decode: () => to,
  encode: () => from
});
exports.transformLiteral = transformLiteral;
function transformLiterals(...pairs) {
  return Union(...pairs.map(([from, to]) => transformLiteral(from, to)));
}
/**
 * Attaches a property signature with the specified key and value to the schema.
 * This API is useful when you want to add a property to your schema which doesn't describe the shape of the input,
 * but rather maps to another schema, for example when you want to add a discriminant to a simple union.
 *
 * @param self - The input schema.
 * @param key - The name of the property to add to the schema.
 * @param value - The value of the property to add to the schema.
 *
 * @example
 * import * as S from "effect/Schema"
 * import { pipe } from "effect/Function"
 *
 * const Circle = S.Struct({ radius: S.Number })
 * const Square = S.Struct({ sideLength: S.Number })
 * const Shape = S.Union(
 *   Circle.pipe(S.attachPropertySignature("kind", "circle")),
 *   Square.pipe(S.attachPropertySignature("kind", "square"))
 * )
 *
 * assert.deepStrictEqual(S.decodeSync(Shape)({ radius: 10 }), {
 *   kind: "circle",
 *   radius: 10
 * })
 *
 * @category combinators
 * @since 3.10.0
 */
const attachPropertySignature = exports.attachPropertySignature = /*#__PURE__*/(0, _Function.dual)(args => isSchema(args[0]), (schema, key, value, annotations) => {
  const ast = extend(typeSchema(schema), Struct({
    [key]: Predicate.isSymbol(value) ? UniqueSymbolFromSelf(value) : Literal(value)
  })).ast;
  return make(new AST.Transformation(schema.ast, annotations ? mergeSchemaAnnotations(ast, annotations) : ast, new AST.TypeLiteralTransformation([new AST.PropertySignatureTransformation(key, key, () => option_.some(value), () => option_.none())])));
});
/**
 * Merges a set of new annotations with existing ones, potentially overwriting
 * any duplicates.
 *
 * @category annotations
 * @since 3.10.0
 */
const annotations = exports.annotations = /*#__PURE__*/(0, _Function.dual)(2, (self, annotations) => self.annotations(annotations));
/**
 * @category renaming
 * @since 3.10.0
 */
const rename = exports.rename = /*#__PURE__*/(0, _Function.dual)(2, (self, mapping) => make(AST.rename(self.ast, mapping)));
/**
 * @category schema id
 * @since 3.10.0
 */
const TrimmedSchemaId = exports.TrimmedSchemaId = /*#__PURE__*/Symbol.for("effect/SchemaId/Trimmed");
/**
 * Verifies that a string contains no leading or trailing whitespaces.
 *
 * Note. This combinator does not make any transformations, it only validates.
 * If what you were looking for was a combinator to trim strings, then check out the `trim` combinator.
 *
 * @category string filters
 * @since 3.10.0
 */
const trimmed = annotations => self => self.pipe(filter(a => a === a.trim(), {
  schemaId: TrimmedSchemaId,
  description: "a string with no leading or trailing whitespace",
  jsonSchema: {
    pattern: "^\\S[\\s\\S]*\\S$|^\\S$|^$"
  },
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.trimmed = trimmed;
const MaxLengthSchemaId = exports.MaxLengthSchemaId = filters_.MaxLengthSchemaId;
/**
 * @category string filters
 * @since 3.10.0
 */
const maxLength = (maxLength, annotations) => self => self.pipe(filter(a => a.length <= maxLength, {
  schemaId: MaxLengthSchemaId,
  description: `a string at most ${maxLength} character(s) long`,
  jsonSchema: {
    maxLength
  },
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.maxLength = maxLength;
const MinLengthSchemaId = exports.MinLengthSchemaId = filters_.MinLengthSchemaId;
/**
 * @category string filters
 * @since 3.10.0
 */
const minLength = (minLength, annotations) => self => self.pipe(filter(a => a.length >= minLength, {
  schemaId: MinLengthSchemaId,
  description: `a string at least ${minLength} character(s) long`,
  jsonSchema: {
    minLength
  },
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.minLength = minLength;
const PatternSchemaId = exports.PatternSchemaId = /*#__PURE__*/Symbol.for("effect/SchemaId/Pattern");
/**
 * @category string filters
 * @since 3.10.0
 */
const pattern = (regex, annotations) => self => {
  const pattern = regex.source;
  return self.pipe(filter(a => {
    // The following line ensures that `lastIndex` is reset to `0` in case the user has specified the `g` flag
    regex.lastIndex = 0;
    return regex.test(a);
  }, {
    schemaId: PatternSchemaId,
    [PatternSchemaId]: {
      regex
    },
    description: `a string matching the pattern ${pattern}`,
    jsonSchema: {
      pattern
    },
    arbitrary: () => fc => fc.stringMatching(regex),
    ...annotations
  }));
};
/**
 * @category schema id
 * @since 3.10.0
 */
exports.pattern = pattern;
const StartsWithSchemaId = exports.StartsWithSchemaId = /*#__PURE__*/Symbol.for("effect/SchemaId/StartsWith");
/**
 * @category string filters
 * @since 3.10.0
 */
const startsWith = (startsWith, annotations) => self => self.pipe(filter(a => a.startsWith(startsWith), {
  schemaId: StartsWithSchemaId,
  [StartsWithSchemaId]: {
    startsWith
  },
  description: `a string starting with ${JSON.stringify(startsWith)}`,
  jsonSchema: {
    pattern: `^${startsWith}`
  },
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.startsWith = startsWith;
const EndsWithSchemaId = exports.EndsWithSchemaId = /*#__PURE__*/Symbol.for("effect/SchemaId/EndsWith");
/**
 * @category string filters
 * @since 3.10.0
 */
const endsWith = (endsWith, annotations) => self => self.pipe(filter(a => a.endsWith(endsWith), {
  schemaId: EndsWithSchemaId,
  [EndsWithSchemaId]: {
    endsWith
  },
  description: `a string ending with ${JSON.stringify(endsWith)}`,
  jsonSchema: {
    pattern: `^.*${endsWith}$`
  },
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.endsWith = endsWith;
const IncludesSchemaId = exports.IncludesSchemaId = /*#__PURE__*/Symbol.for("effect/SchemaId/Includes");
/**
 * @category string filters
 * @since 3.10.0
 */
const includes = (searchString, annotations) => self => self.pipe(filter(a => a.includes(searchString), {
  schemaId: IncludesSchemaId,
  [IncludesSchemaId]: {
    includes: searchString
  },
  description: `a string including ${JSON.stringify(searchString)}`,
  jsonSchema: {
    pattern: `.*${searchString}.*`
  },
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.includes = includes;
const LowercasedSchemaId = exports.LowercasedSchemaId = /*#__PURE__*/Symbol.for("effect/SchemaId/Lowercased");
/**
 * Verifies that a string is lowercased.
 *
 * @category string filters
 * @since 3.10.0
 */
const lowercased = annotations => self => self.pipe(filter(a => a === a.toLowerCase(), {
  schemaId: LowercasedSchemaId,
  description: "a lowercase string",
  ...annotations
}));
/**
 * @category string constructors
 * @since 3.10.0
 */
exports.lowercased = lowercased;
class Lowercased extends /*#__PURE__*/String$.pipe( /*#__PURE__*/lowercased({
  identifier: "Lowercased",
  title: "Lowercased"
})) {}
/**
 * @category schema id
 * @since 3.10.0
 */
exports.Lowercased = Lowercased;
const CapitalizedSchemaId = exports.CapitalizedSchemaId = /*#__PURE__*/Symbol.for("effect/SchemaId/Capitalized");
/**
 * Verifies that a string is capitalized.
 *
 * @category string filters
 * @since 3.10.0
 */
const capitalized = annotations => self => self.pipe(filter(a => a[0]?.toUpperCase() === a[0], {
  schemaId: CapitalizedSchemaId,
  description: "a capitalized string",
  ...annotations
}));
/**
 * @category string constructors
 * @since 3.10.0
 */
exports.capitalized = capitalized;
class Capitalized extends /*#__PURE__*/String$.pipe( /*#__PURE__*/capitalized({
  identifier: "Capitalized",
  title: "Capitalized"
})) {}
/**
 * @category schema id
 * @since 3.10.0
 */
exports.Capitalized = Capitalized;
const UncapitalizedSchemaId = exports.UncapitalizedSchemaId = /*#__PURE__*/Symbol.for("effect/SchemaId/Uncapitalized");
/**
 * Verifies that a string is uncapitalized.
 *
 * @category string filters
 * @since 3.10.0
 */
const uncapitalized = annotations => self => self.pipe(filter(a => a[0]?.toLowerCase() === a[0], {
  schemaId: UncapitalizedSchemaId,
  description: "a uncapitalized string",
  ...annotations
}));
/**
 * @category string constructors
 * @since 3.10.0
 */
exports.uncapitalized = uncapitalized;
class Uncapitalized extends /*#__PURE__*/String$.pipe( /*#__PURE__*/uncapitalized({
  identifier: "Uncapitalized",
  title: "Uncapitalized"
})) {}
/**
 * @category schema id
 * @since 3.10.0
 */
exports.Uncapitalized = Uncapitalized;
const UppercasedSchemaId = exports.UppercasedSchemaId = /*#__PURE__*/Symbol.for("effect/SchemaId/Uppercased");
/**
 * Verifies that a string is uppercased.
 *
 * @category string filters
 * @since 3.10.0
 */
const uppercased = annotations => self => self.pipe(filter(a => a === a.toUpperCase(), {
  schemaId: UppercasedSchemaId,
  description: "an uppercase string",
  ...annotations
}));
/**
 * @category string constructors
 * @since 3.10.0
 */
exports.uppercased = uppercased;
class Uppercased extends /*#__PURE__*/String$.pipe( /*#__PURE__*/uppercased({
  identifier: "Uppercased",
  title: "Uppercased"
})) {}
/**
 * @category schema id
 * @since 3.10.0
 */
exports.Uppercased = Uppercased;
const LengthSchemaId = exports.LengthSchemaId = filters_.LengthSchemaId;
/**
 * @category string filters
 * @since 3.10.0
 */
const length = (length, annotations) => self => {
  const minLength = Predicate.isObject(length) ? Math.max(0, Math.floor(length.min)) : Math.max(0, Math.floor(length));
  const maxLength = Predicate.isObject(length) ? Math.max(minLength, Math.floor(length.max)) : minLength;
  if (minLength !== maxLength) {
    return self.pipe(filter(a => a.length >= minLength && a.length <= maxLength, {
      schemaId: LengthSchemaId,
      description: `a string at least ${minLength} character(s) and at most ${maxLength} character(s) long`,
      jsonSchema: {
        minLength,
        maxLength
      },
      ...annotations
    }));
  }
  return self.pipe(filter(a => a.length === minLength, {
    schemaId: LengthSchemaId,
    description: minLength === 1 ? `a single character` : `a string ${minLength} character(s) long`,
    jsonSchema: {
      minLength,
      maxLength: minLength
    },
    ...annotations
  }));
};
/**
 * A schema representing a single character.
 *
 * @category string constructors
 * @since 3.10.0
 */
exports.length = length;
class Char extends /*#__PURE__*/String$.pipe( /*#__PURE__*/length(1, {
  identifier: "Char"
})) {}
/**
 * @category string filters
 * @since 3.10.0
 */
exports.Char = Char;
const nonEmptyString = annotations => minLength(1, {
  description: "a non empty string",
  ...annotations
});
/**
 * This schema converts a string to lowercase.
 *
 * @category string transformations
 * @since 3.10.0
 */
exports.nonEmptyString = nonEmptyString;
class Lowercase extends /*#__PURE__*/transform(String$.annotations({
  description: "a string that will be converted to lowercase"
}), Lowercased, {
  strict: true,
  decode: s => s.toLowerCase(),
  encode: _Function.identity
}).annotations({
  identifier: "Lowercase"
}) {}
/**
 * This schema converts a string to uppercase.
 *
 * @category string transformations
 * @since 3.10.0
 */
exports.Lowercase = Lowercase;
class Uppercase extends /*#__PURE__*/transform(String$.annotations({
  description: "a string that will be converted to uppercase"
}), Uppercased, {
  strict: true,
  decode: s => s.toUpperCase(),
  encode: _Function.identity
}).annotations({
  identifier: "Uppercase"
}) {}
/**
 * This schema converts a string to capitalized one.
 *
 * @category string transformations
 * @since 3.10.0
 */
exports.Uppercase = Uppercase;
class Capitalize extends /*#__PURE__*/transform(String$.annotations({
  description: "a string that will be converted to a capitalized format"
}), Capitalized, {
  strict: true,
  decode: s => string_.capitalize(s),
  encode: _Function.identity
}).annotations({
  identifier: "Capitalize"
}) {}
/**
 * This schema converts a string to uncapitalized one.
 *
 * @category string transformations
 * @since 3.10.0
 */
exports.Capitalize = Capitalize;
class Uncapitalize extends /*#__PURE__*/transform(String$.annotations({
  description: "a string that will be converted to an uncapitalized format"
}), Uncapitalized, {
  strict: true,
  decode: s => string_.uncapitalize(s),
  encode: _Function.identity
}).annotations({
  identifier: "Uncapitalize"
}) {}
/**
 * @category string constructors
 * @since 3.10.0
 */
exports.Uncapitalize = Uncapitalize;
class Trimmed extends /*#__PURE__*/String$.pipe( /*#__PURE__*/trimmed({
  identifier: "Trimmed",
  title: "Trimmed"
})) {}
/**
 * Useful for validating strings that must contain meaningful characters without
 * leading or trailing whitespace.
 *
 * @example
 * import { Schema } from "effect"
 *
 * console.log(Schema.decodeOption(Schema.NonEmptyTrimmedString)("")) // Option.none()
 * console.log(Schema.decodeOption(Schema.NonEmptyTrimmedString)(" a ")) // Option.none()
 * console.log(Schema.decodeOption(Schema.NonEmptyTrimmedString)("a")) // Option.some("a")
 *
 * @category string constructors
 * @since 3.10.0
 */
exports.Trimmed = Trimmed;
class NonEmptyTrimmedString extends /*#__PURE__*/Trimmed.pipe( /*#__PURE__*/nonEmptyString({
  identifier: "NonEmptyTrimmedString",
  title: "NonEmptyTrimmedString"
})) {}
/**
 * This schema allows removing whitespaces from the beginning and end of a string.
 *
 * @category string transformations
 * @since 3.10.0
 */
exports.NonEmptyTrimmedString = NonEmptyTrimmedString;
class Trim extends /*#__PURE__*/transform(String$.annotations({
  description: "a string that will be trimmed"
}), Trimmed, {
  strict: true,
  decode: s => s.trim(),
  encode: _Function.identity
}).annotations({
  identifier: "Trim"
}) {}
/**
 * Returns a schema that allows splitting a string into an array of strings.
 *
 * @category string transformations
 * @since 3.10.0
 */
exports.Trim = Trim;
const split = separator => transform(String$.annotations({
  description: "a string that will be split"
}), Array$(String$), {
  strict: true,
  decode: string_.split(separator),
  encode: array_.join(separator)
});
exports.split = split;
const JsonString = /*#__PURE__*/String$.annotations({
  [AST.IdentifierAnnotationId]: "JsonString",
  [AST.TitleAnnotationId]: "JsonString",
  [AST.DescriptionAnnotationId]: "a JSON string"
});
const getParseJsonTransformation = options => transformOrFail(JsonString, Unknown, {
  strict: true,
  decode: (s, _, ast) => ParseResult.try({
    try: () => JSON.parse(s, options?.reviver),
    catch: e => new ParseResult.Type(ast, s, e.message)
  }),
  encode: (u, _, ast) => ParseResult.try({
    try: () => JSON.stringify(u, options?.replacer, options?.space),
    catch: e => new ParseResult.Type(ast, u, e.message)
  })
}).annotations({
  schemaId: AST.ParseJsonSchemaId
});
/**
 * The `ParseJson` combinator provides a method to convert JSON strings into the `unknown` type using the underlying
 * functionality of `JSON.parse`. It also utilizes `JSON.stringify` for encoding.
 *
 * You can optionally provide a `ParseJsonOptions` to configure both `JSON.parse` and `JSON.stringify` executions.
 *
 * Optionally, you can pass a schema `Schema<A, I, R>` to obtain an `A` type instead of `unknown`.
 *
 * @example
 * import * as Schema from "effect/Schema"
 *
 * assert.deepStrictEqual(Schema.decodeUnknownSync(Schema.parseJson())(`{"a":"1"}`), { a: "1" })
 * assert.deepStrictEqual(Schema.decodeUnknownSync(Schema.parseJson(Schema.Struct({ a: Schema.NumberFromString })))(`{"a":"1"}`), { a: 1 })
 *
 * @category string transformations
 * @since 3.10.0
 */
const parseJson = (schemaOrOptions, o) => isSchema(schemaOrOptions) ? compose(parseJson(o), schemaOrOptions) : getParseJsonTransformation(schemaOrOptions);
/**
 * @category string constructors
 * @since 3.10.0
 */
exports.parseJson = parseJson;
class NonEmptyString extends /*#__PURE__*/String$.pipe( /*#__PURE__*/nonEmptyString({
  identifier: "NonEmptyString",
  title: "NonEmptyString"
})) {}
/**
 * @category schema id
 * @since 3.10.0
 */
exports.NonEmptyString = NonEmptyString;
const UUIDSchemaId = exports.UUIDSchemaId = /*#__PURE__*/Symbol.for("effect/SchemaId/UUID");
const uuidRegexp = /^[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}$/i;
/**
 * Represents a Universally Unique Identifier (UUID).
 *
 * This schema ensures that the provided string adheres to the standard UUID format.
 *
 * @category string constructors
 * @since 3.10.0
 */
class UUID extends /*#__PURE__*/String$.pipe( /*#__PURE__*/pattern(uuidRegexp, {
  schemaId: UUIDSchemaId,
  identifier: "UUID",
  title: "UUID",
  description: "a Universally Unique Identifier",
  arbitrary: () => fc => fc.uuid()
})) {}
/**
 * @category schema id
 * @since 3.10.0
 */
exports.UUID = UUID;
const ULIDSchemaId = exports.ULIDSchemaId = /*#__PURE__*/Symbol.for("effect/SchemaId/ULID");
const ulidRegexp = /^[0-7][0-9A-HJKMNP-TV-Z]{25}$/i;
/**
 * Represents a Universally Unique Lexicographically Sortable Identifier (ULID).
 *
 * ULIDs are designed to be compact, URL-safe, and ordered, making them suitable for use as identifiers.
 * This schema ensures that the provided string adheres to the standard ULID format.
 *
 * @category string constructors
 * @since 3.10.0
 */
class ULID extends /*#__PURE__*/String$.pipe( /*#__PURE__*/pattern(ulidRegexp, {
  schemaId: ULIDSchemaId,
  identifier: "ULID",
  title: "ULID",
  description: "a Universally Unique Lexicographically Sortable Identifier",
  arbitrary: () => fc => fc.ulid()
})) {}
/**
 * @category schema id
 * @since 3.10.0
 */
exports.ULID = ULID;
const FiniteSchemaId = exports.FiniteSchemaId = /*#__PURE__*/Symbol.for("effect/SchemaId/Finite");
/**
 * Ensures that the provided value is a finite number.
 *
 * This schema filters out non-finite numeric values, allowing only finite numbers to pass through.
 *
 * @category number filters
 * @since 3.10.0
 */
const finite = annotations => self => self.pipe(filter(a => Number.isFinite(a), {
  schemaId: FiniteSchemaId,
  description: "a finite number",
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.finite = finite;
const GreaterThanSchemaId = exports.GreaterThanSchemaId = filters_.GreaterThanSchemaId;
/**
 * This filter checks whether the provided number is greater than the specified minimum.
 *
 * @category number filters
 * @since 3.10.0
 */
const greaterThan = (min, annotations) => self => self.pipe(filter(a => a > min, {
  schemaId: GreaterThanSchemaId,
  description: min === 0 ? "a positive number" : `a number greater than ${min}`,
  jsonSchema: {
    exclusiveMinimum: min
  },
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.greaterThan = greaterThan;
const GreaterThanOrEqualToSchemaId = exports.GreaterThanOrEqualToSchemaId = filters_.GreaterThanOrEqualToSchemaId;
/**
 * This filter checks whether the provided number is greater than or equal to the specified minimum.
 *
 * @category number filters
 * @since 3.10.0
 */
const greaterThanOrEqualTo = (min, annotations) => self => self.pipe(filter(a => a >= min, {
  schemaId: GreaterThanOrEqualToSchemaId,
  description: min === 0 ? "a non-negative number" : `a number greater than or equal to ${min}`,
  jsonSchema: {
    minimum: min
  },
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.greaterThanOrEqualTo = greaterThanOrEqualTo;
const MultipleOfSchemaId = exports.MultipleOfSchemaId = /*#__PURE__*/Symbol.for("effect/SchemaId/MultipleOf");
/**
 * @category number filters
 * @since 3.10.0
 */
const multipleOf = (divisor, annotations) => self => self.pipe(filter(a => number_.remainder(a, divisor) === 0, {
  schemaId: MultipleOfSchemaId,
  description: `a number divisible by ${divisor}`,
  jsonSchema: {
    multipleOf: Math.abs(divisor)
  },
  // spec requires positive divisor
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.multipleOf = multipleOf;
const IntSchemaId = exports.IntSchemaId = filters_.IntSchemaId;
/**
 * @category number filters
 * @since 3.10.0
 */
const int = annotations => self => self.pipe(filter(a => Number.isSafeInteger(a), {
  schemaId: IntSchemaId,
  title: "integer",
  description: "an integer",
  jsonSchema: {
    type: "integer"
  },
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.int = int;
const LessThanSchemaId = exports.LessThanSchemaId = filters_.LessThanSchemaId;
/**
 * This filter checks whether the provided number is less than the specified maximum.
 *
 * @category number filters
 * @since 3.10.0
 */
const lessThan = (max, annotations) => self => self.pipe(filter(a => a < max, {
  schemaId: LessThanSchemaId,
  description: max === 0 ? "a negative number" : `a number less than ${max}`,
  jsonSchema: {
    exclusiveMaximum: max
  },
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.lessThan = lessThan;
const LessThanOrEqualToSchemaId = exports.LessThanOrEqualToSchemaId = filters_.LessThanOrEqualToSchemaId;
/**
 * This schema checks whether the provided number is less than or equal to the specified maximum.
 *
 * @category number filters
 * @since 3.10.0
 */
const lessThanOrEqualTo = (max, annotations) => self => self.pipe(filter(a => a <= max, {
  schemaId: LessThanOrEqualToSchemaId,
  description: max === 0 ? "a non-positive number" : `a number less than or equal to ${max}`,
  jsonSchema: {
    maximum: max
  },
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.lessThanOrEqualTo = lessThanOrEqualTo;
const BetweenSchemaId = exports.BetweenSchemaId = filters_.BetweenSchemaId;
/**
 * This filter checks whether the provided number falls within the specified minimum and maximum values.
 *
 * @category number filters
 * @since 3.10.0
 */
const between = (min, max, annotations) => self => self.pipe(filter(a => a >= min && a <= max, {
  schemaId: BetweenSchemaId,
  description: `a number between ${min} and ${max}`,
  jsonSchema: {
    maximum: max,
    minimum: min
  },
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.between = between;
const NonNaNSchemaId = exports.NonNaNSchemaId = /*#__PURE__*/Symbol.for("effect/SchemaId/NonNaN");
/**
 * @category number filters
 * @since 3.10.0
 */
const nonNaN = annotations => self => self.pipe(filter(a => !Number.isNaN(a), {
  schemaId: NonNaNSchemaId,
  description: "a number excluding NaN",
  ...annotations
}));
/**
 * @category number filters
 * @since 3.10.0
 */
exports.nonNaN = nonNaN;
const positive = annotations => greaterThan(0, annotations);
/**
 * @category number filters
 * @since 3.10.0
 */
exports.positive = positive;
const negative = annotations => lessThan(0, annotations);
/**
 * @category number filters
 * @since 3.10.0
 */
exports.negative = negative;
const nonPositive = annotations => lessThanOrEqualTo(0, annotations);
/**
 * @category number filters
 * @since 3.10.0
 */
exports.nonPositive = nonPositive;
const nonNegative = annotations => greaterThanOrEqualTo(0, annotations);
/**
 * Clamps a number between a minimum and a maximum value.
 *
 * @category number transformations
 * @since 3.10.0
 */
exports.nonNegative = nonNegative;
const clamp = (minimum, maximum) => self => transform(self, self.pipe(typeSchema, between(minimum, maximum)), {
  strict: false,
  decode: self => number_.clamp(self, {
    minimum,
    maximum
  }),
  encode: _Function.identity
});
/**
 * Transforms a `string` into a `number` by parsing the string using the `parse` function of the `effect/Number` module.
 *
 * It returns an error if the value can't be converted (for example when non-numeric characters are provided).
 *
 * The following special string values are supported: "NaN", "Infinity", "-Infinity".
 *
 * @category number transformations
 * @since 3.10.0
 */
exports.clamp = clamp;
const parseNumber = self => transformOrFail(self, Number$, {
  strict: false,
  decode: (s, _, ast) => ParseResult.fromOption(number_.parse(s), () => new ParseResult.Type(ast, s)),
  encode: n => ParseResult.succeed(String(n))
});
/**
 * This schema transforms a `string` into a `number` by parsing the string using the `parse` function of the `effect/Number` module.
 *
 * It returns an error if the value can't be converted (for example when non-numeric characters are provided).
 *
 * The following special string values are supported: "NaN", "Infinity", "-Infinity".
 *
 * @category number constructors
 * @since 3.10.0
 */
exports.parseNumber = parseNumber;
class NumberFromString extends /*#__PURE__*/parseNumber(String$.annotations({
  description: "a string that will be parsed into a number"
})).annotations({
  identifier: "NumberFromString"
}) {}
/**
 * @category number constructors
 * @since 3.10.0
 */
exports.NumberFromString = NumberFromString;
class Finite extends /*#__PURE__*/Number$.pipe( /*#__PURE__*/finite({
  identifier: "Finite",
  title: "Finite"
})) {}
/**
 * @category number constructors
 * @since 3.10.0
 */
exports.Finite = Finite;
class Int extends /*#__PURE__*/Number$.pipe( /*#__PURE__*/int({
  identifier: "Int",
  title: "Int"
})) {}
/**
 * @category number constructors
 * @since 3.10.0
 */
exports.Int = Int;
class NonNaN extends /*#__PURE__*/Number$.pipe( /*#__PURE__*/nonNaN({
  identifier: "NonNaN",
  title: "NonNaN"
})) {}
/**
 * @category number constructors
 * @since 3.10.0
 */
exports.NonNaN = NonNaN;
class Positive extends /*#__PURE__*/Number$.pipe( /*#__PURE__*/positive({
  identifier: "Positive",
  title: "Positive"
})) {}
/**
 * @category number constructors
 * @since 3.10.0
 */
exports.Positive = Positive;
class Negative extends /*#__PURE__*/Number$.pipe( /*#__PURE__*/negative({
  identifier: "Negative",
  title: "Negative"
})) {}
/**
 * @category number constructors
 * @since 3.10.0
 */
exports.Negative = Negative;
class NonPositive extends /*#__PURE__*/Number$.pipe( /*#__PURE__*/nonPositive({
  identifier: "NonPositive",
  title: "NonPositive"
})) {}
/**
 * @category number constructors
 * @since 3.10.0
 */
exports.NonPositive = NonPositive;
class NonNegative extends /*#__PURE__*/Number$.pipe( /*#__PURE__*/nonNegative({
  identifier: "NonNegative",
  title: "NonNegative"
})) {}
/**
 * @category schema id
 * @since 3.10.0
 */
exports.NonNegative = NonNegative;
const JsonNumberSchemaId = exports.JsonNumberSchemaId = /*#__PURE__*/Symbol.for("effect/SchemaId/JsonNumber");
/**
 * The `JsonNumber` is a schema for representing JSON numbers. It ensures that the provided value is a valid
 * number by filtering out `NaN` and `(+/-) Infinity`. This is useful when you want to validate and represent numbers in JSON
 * format.
 *
 * @example
 * import * as Schema from "effect/Schema"
 *
 * const is = Schema.is(S.JsonNumber)
 *
 * assert.deepStrictEqual(is(42), true)
 * assert.deepStrictEqual(is(Number.NaN), false)
 * assert.deepStrictEqual(is(Number.POSITIVE_INFINITY), false)
 * assert.deepStrictEqual(is(Number.NEGATIVE_INFINITY), false)
 *
 * @category number constructors
 * @since 3.10.0
 */
class JsonNumber extends /*#__PURE__*/Number$.pipe( /*#__PURE__*/filter(n => !Number.isNaN(n) && Number.isFinite(n), {
  schemaId: JsonNumberSchemaId,
  identifier: "JsonNumber",
  title: "JSON-compatible number",
  description: "a JSON-compatible number, excluding NaN, +Infinity, and -Infinity",
  jsonSchema: {
    type: "number"
  }
})) {}
/**
 * @category boolean transformations
 * @since 3.10.0
 */
exports.JsonNumber = JsonNumber;
class Not extends /*#__PURE__*/transform( /*#__PURE__*/Boolean$.annotations({
  description: "a boolean that will be negated"
}), Boolean$, {
  strict: true,
  decode: boolean_.not,
  encode: boolean_.not
}) {}
/** @ignore */
exports.Not = Not;
class Symbol$ extends /*#__PURE__*/transform(String$.annotations({
  description: "a string that will be converted to a symbol"
}), SymbolFromSelf, {
  strict: false,
  decode: s => Symbol.for(s),
  encode: sym => sym.description
}).annotations({
  identifier: "symbol"
}) {}
exports.Symbol = Symbol$;
/**
 * @category schema id
 * @since 3.10.0
 */
const GreaterThanBigIntSchemaId = exports.GreaterThanBigIntSchemaId = filters_.GreaterThanBigintSchemaId;
/**
 * @category bigint filters
 * @since 3.10.0
 */
const greaterThanBigInt = (min, annotations) => self => self.pipe(filter(a => a > min, {
  schemaId: GreaterThanBigIntSchemaId,
  [GreaterThanBigIntSchemaId]: {
    min
  },
  description: min === 0n ? "a positive bigint" : `a bigint greater than ${min}n`,
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.greaterThanBigInt = greaterThanBigInt;
const GreaterThanOrEqualToBigIntSchemaId = exports.GreaterThanOrEqualToBigIntSchemaId = filters_.GreaterThanOrEqualToBigIntSchemaId;
/**
 * @category bigint filters
 * @since 3.10.0
 */
const greaterThanOrEqualToBigInt = (min, annotations) => self => self.pipe(filter(a => a >= min, {
  schemaId: GreaterThanOrEqualToBigIntSchemaId,
  [GreaterThanOrEqualToBigIntSchemaId]: {
    min
  },
  description: min === 0n ? "a non-negative bigint" : `a bigint greater than or equal to ${min}n`,
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.greaterThanOrEqualToBigInt = greaterThanOrEqualToBigInt;
const LessThanBigIntSchemaId = exports.LessThanBigIntSchemaId = filters_.LessThanBigIntSchemaId;
/**
 * @category bigint filters
 * @since 3.10.0
 */
const lessThanBigInt = (max, annotations) => self => self.pipe(filter(a => a < max, {
  schemaId: LessThanBigIntSchemaId,
  [LessThanBigIntSchemaId]: {
    max
  },
  description: max === 0n ? "a negative bigint" : `a bigint less than ${max}n`,
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.lessThanBigInt = lessThanBigInt;
const LessThanOrEqualToBigIntSchemaId = exports.LessThanOrEqualToBigIntSchemaId = filters_.LessThanOrEqualToBigIntSchemaId;
/**
 * @category bigint filters
 * @since 3.10.0
 */
const lessThanOrEqualToBigInt = (max, annotations) => self => self.pipe(filter(a => a <= max, {
  schemaId: LessThanOrEqualToBigIntSchemaId,
  [LessThanOrEqualToBigIntSchemaId]: {
    max
  },
  description: max === 0n ? "a non-positive bigint" : `a bigint less than or equal to ${max}n`,
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.lessThanOrEqualToBigInt = lessThanOrEqualToBigInt;
const BetweenBigIntSchemaId = exports.BetweenBigIntSchemaId = filters_.BetweenBigintSchemaId;
/**
 * @category bigint filters
 * @since 3.10.0
 */
const betweenBigInt = (min, max, annotations) => self => self.pipe(filter(a => a >= min && a <= max, {
  schemaId: BetweenBigIntSchemaId,
  [BetweenBigIntSchemaId]: {
    max,
    min
  },
  description: `a bigint between ${min}n and ${max}n`,
  ...annotations
}));
/**
 * @category bigint filters
 * @since 3.10.0
 */
exports.betweenBigInt = betweenBigInt;
const positiveBigInt = annotations => greaterThanBigInt(0n, annotations);
/**
 * @category bigint filters
 * @since 3.10.0
 */
exports.positiveBigInt = positiveBigInt;
const negativeBigInt = annotations => lessThanBigInt(0n, annotations);
/**
 * @category bigint filters
 * @since 3.10.0
 */
exports.negativeBigInt = negativeBigInt;
const nonNegativeBigInt = annotations => greaterThanOrEqualToBigInt(0n, annotations);
/**
 * @category bigint filters
 * @since 3.10.0
 */
exports.nonNegativeBigInt = nonNegativeBigInt;
const nonPositiveBigInt = annotations => lessThanOrEqualToBigInt(0n, annotations);
/**
 * Clamps a bigint between a minimum and a maximum value.
 *
 * @category bigint transformations
 * @since 3.10.0
 */
exports.nonPositiveBigInt = nonPositiveBigInt;
const clampBigInt = (minimum, maximum) => self => transform(self, self.pipe(typeSchema, betweenBigInt(minimum, maximum)), {
  strict: false,
  decode: self => bigInt_.clamp(self, {
    minimum,
    maximum
  }),
  encode: _Function.identity
});
/** @ignore */
exports.clampBigInt = clampBigInt;
class BigInt$ extends /*#__PURE__*/transformOrFail(String$.annotations({
  description: "a string that will be parsed into a bigint"
}), BigIntFromSelf, {
  strict: true,
  decode: (s, _, ast) => ParseResult.fromOption(bigInt_.fromString(s), () => new ParseResult.Type(ast, s)),
  encode: n => ParseResult.succeed(String(n))
}).annotations({
  identifier: "bigint"
}) {}
exports.BigInt = BigInt$;
/**
 * @category bigint constructors
 * @since 3.10.0
 */
const PositiveBigIntFromSelf = exports.PositiveBigIntFromSelf = /*#__PURE__*/BigIntFromSelf.pipe( /*#__PURE__*/positiveBigInt({
  identifier: "PositiveBigintFromSelf",
  title: "PositiveBigintFromSelf"
}));
/**
 * @category bigint constructors
 * @since 3.10.0
 */
const PositiveBigInt = exports.PositiveBigInt = /*#__PURE__*/BigInt$.pipe( /*#__PURE__*/positiveBigInt({
  identifier: "PositiveBigint",
  title: "PositiveBigint"
}));
/**
 * @category bigint constructors
 * @since 3.10.0
 */
const NegativeBigIntFromSelf = exports.NegativeBigIntFromSelf = /*#__PURE__*/BigIntFromSelf.pipe( /*#__PURE__*/negativeBigInt({
  identifier: "NegativeBigintFromSelf",
  title: "NegativeBigintFromSelf"
}));
/**
 * @category bigint constructors
 * @since 3.10.0
 */
const NegativeBigInt = exports.NegativeBigInt = /*#__PURE__*/BigInt$.pipe( /*#__PURE__*/negativeBigInt({
  identifier: "NegativeBigint",
  title: "NegativeBigint"
}));
/**
 * @category bigint constructors
 * @since 3.10.0
 */
const NonPositiveBigIntFromSelf = exports.NonPositiveBigIntFromSelf = /*#__PURE__*/BigIntFromSelf.pipe( /*#__PURE__*/nonPositiveBigInt({
  identifier: "NonPositiveBigintFromSelf",
  title: "NonPositiveBigintFromSelf"
}));
/**
 * @category bigint constructors
 * @since 3.10.0
 */
const NonPositiveBigInt = exports.NonPositiveBigInt = /*#__PURE__*/BigInt$.pipe( /*#__PURE__*/nonPositiveBigInt({
  identifier: "NonPositiveBigint",
  title: "NonPositiveBigint"
}));
/**
 * @category bigint constructors
 * @since 3.10.0
 */
const NonNegativeBigIntFromSelf = exports.NonNegativeBigIntFromSelf = /*#__PURE__*/BigIntFromSelf.pipe( /*#__PURE__*/nonNegativeBigInt({
  identifier: "NonNegativeBigintFromSelf",
  title: "NonNegativeBigintFromSelf"
}));
/**
 * @category bigint constructors
 * @since 3.10.0
 */
const NonNegativeBigInt = exports.NonNegativeBigInt = /*#__PURE__*/BigInt$.pipe( /*#__PURE__*/nonNegativeBigInt({
  identifier: "NonNegativeBigint",
  title: "NonNegativeBigint"
}));
/**
 * This schema transforms a `number` into a `bigint` by parsing the number using the `BigInt` function.
 *
 * It returns an error if the value can't be safely encoded as a `number` due to being out of range.
 *
 * @category bigint transformations
 * @since 3.10.0
 */
class BigIntFromNumber extends /*#__PURE__*/transformOrFail(Number$.annotations({
  description: "a number that will be parsed into a bigint"
}), BigIntFromSelf, {
  strict: true,
  decode: (n, _, ast) => ParseResult.fromOption(bigInt_.fromNumber(n), () => new ParseResult.Type(ast, n)),
  encode: (b, _, ast) => ParseResult.fromOption(bigInt_.toNumber(b), () => new ParseResult.Type(ast, b))
}).annotations({
  identifier: "BigintFromNumber"
}) {}
exports.BigIntFromNumber = BigIntFromNumber;
const redactedArbitrary = value => fc => value(fc).map(redacted_.make);
const toComposite = (eff, onSuccess, ast, actual) => ParseResult.mapBoth(eff, {
  onFailure: e => new ParseResult.Composite(ast, actual, e),
  onSuccess
});
const redactedParse = decodeUnknown => (u, options, ast) => redacted_.isRedacted(u) ? toComposite(decodeUnknown(redacted_.value(u), options), redacted_.make, ast, u) : ParseResult.fail(new ParseResult.Type(ast, u));
/**
 * @category Redacted constructors
 * @since 3.10.0
 */
const RedactedFromSelf = value => declare([value], {
  decode: value => redactedParse(ParseResult.decodeUnknown(value)),
  encode: value => redactedParse(ParseResult.encodeUnknown(value))
}, {
  description: "Redacted(<redacted>)",
  pretty: () => () => "Redacted(<redacted>)",
  arbitrary: redactedArbitrary,
  equivalence: redacted_.getEquivalence
});
/**
 * A schema that transforms any type `A` into a `Redacted<A>`.
 *
 * @category Redacted transformations
 * @since 3.10.0
 */
exports.RedactedFromSelf = RedactedFromSelf;
const Redacted = value => {
  return transform(value, RedactedFromSelf(typeSchema(value)), {
    strict: true,
    decode: value => redacted_.make(value),
    encode: value => redacted_.value(value)
  });
};
/**
 * @category Duration constructors
 * @since 3.10.0
 */
exports.Redacted = Redacted;
class DurationFromSelf extends /*#__PURE__*/declare(duration_.isDuration, {
  identifier: "DurationFromSelf",
  pretty: () => String,
  arbitrary: () => fc => fc.oneof(fc.constant(duration_.infinity), fc.bigUint().map(_ => duration_.nanos(_)), fc.bigUint().map(_ => duration_.micros(_)), fc.maxSafeNat().map(_ => duration_.millis(_)), fc.maxSafeNat().map(_ => duration_.seconds(_)), fc.maxSafeNat().map(_ => duration_.minutes(_)), fc.maxSafeNat().map(_ => duration_.hours(_)), fc.maxSafeNat().map(_ => duration_.days(_)), fc.maxSafeNat().map(_ => duration_.weeks(_))),
  equivalence: () => duration_.Equivalence
}) {}
/**
 * A schema that transforms a `bigint` tuple into a `Duration`.
 * Treats the value as the number of nanoseconds.
 *
 * @category Duration transformations
 * @since 3.10.0
 */
exports.DurationFromSelf = DurationFromSelf;
class DurationFromNanos extends /*#__PURE__*/transformOrFail(BigIntFromSelf.annotations({
  description: "a bigint that will be parsed into a Duration"
}), DurationFromSelf, {
  strict: true,
  decode: nanos => ParseResult.succeed(duration_.nanos(nanos)),
  encode: (duration, _, ast) => option_.match(duration_.toNanos(duration), {
    onNone: () => ParseResult.fail(new ParseResult.Type(ast, duration)),
    onSome: val => ParseResult.succeed(val)
  })
}).annotations({
  identifier: "DurationFromNanos"
}) {}
/**
 * A schema that transforms a `number` tuple into a `Duration`.
 * Treats the value as the number of milliseconds.
 *
 * @category Duration transformations
 * @since 3.10.0
 */
exports.DurationFromNanos = DurationFromNanos;
class DurationFromMillis extends /*#__PURE__*/transform(Number$.annotations({
  description: "a number that will be parsed into a Duration"
}), DurationFromSelf, {
  strict: true,
  decode: ms => duration_.millis(ms),
  encode: n => duration_.toMillis(n)
}).annotations({
  identifier: "DurationFromMillis"
}) {}
exports.DurationFromMillis = DurationFromMillis;
const hrTime = /*#__PURE__*/Tuple( /*#__PURE__*/NonNegative.pipe( /*#__PURE__*/finite({
  [AST.TitleAnnotationId]: "seconds",
  [AST.DescriptionAnnotationId]: "seconds"
})), /*#__PURE__*/NonNegative.pipe( /*#__PURE__*/finite({
  [AST.TitleAnnotationId]: "nanos",
  [AST.DescriptionAnnotationId]: "nanos"
})));
/**
 * A schema that transforms a `[number, number]` tuple into a `Duration`.
 *
 * @category Duration transformations
 * @since 3.10.0
 */
class Duration extends /*#__PURE__*/transform(hrTime.annotations({
  description: "a tuple of seconds and nanos that will be parsed into a Duration"
}), DurationFromSelf, {
  strict: true,
  decode: ([seconds, nanos]) => duration_.nanos(BigInt(seconds) * BigInt(1e9) + BigInt(nanos)),
  encode: duration => duration_.toHrTime(duration)
}).annotations({
  identifier: "Duration"
}) {}
/**
 * Clamps a `Duration` between a minimum and a maximum value.
 *
 * @category Duration transformations
 * @since 3.10.0
 */
exports.Duration = Duration;
const clampDuration = (minimum, maximum) => self => transform(self, self.pipe(typeSchema, betweenDuration(minimum, maximum)), {
  strict: false,
  decode: self => duration_.clamp(self, {
    minimum,
    maximum
  }),
  encode: _Function.identity
});
/**
 * @category schema id
 * @since 3.10.0
 */
exports.clampDuration = clampDuration;
const LessThanDurationSchemaId = exports.LessThanDurationSchemaId = /*#__PURE__*/Symbol.for("effect/SchemaId/LessThanDuration");
/**
 * @category Duration filters
 * @since 3.10.0
 */
const lessThanDuration = (max, annotations) => self => self.pipe(filter(a => duration_.lessThan(a, max), {
  schemaId: LessThanDurationSchemaId,
  [LessThanDurationSchemaId]: {
    max
  },
  description: `a Duration less than ${duration_.decode(max)}`,
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.lessThanDuration = lessThanDuration;
const LessThanOrEqualToDurationSchemaId = exports.LessThanOrEqualToDurationSchemaId = /*#__PURE__*/Symbol.for("effect/schema/LessThanOrEqualToDuration");
/**
 * @category Duration filters
 * @since 3.10.0
 */
const lessThanOrEqualToDuration = (max, annotations) => self => self.pipe(filter(a => duration_.lessThanOrEqualTo(a, max), {
  schemaId: LessThanDurationSchemaId,
  [LessThanDurationSchemaId]: {
    max
  },
  description: `a Duration less than or equal to ${duration_.decode(max)}`,
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.lessThanOrEqualToDuration = lessThanOrEqualToDuration;
const GreaterThanDurationSchemaId = exports.GreaterThanDurationSchemaId = /*#__PURE__*/Symbol.for("effect/SchemaId/GreaterThanDuration");
/**
 * @category Duration filters
 * @since 3.10.0
 */
const greaterThanDuration = (min, annotations) => self => self.pipe(filter(a => duration_.greaterThan(a, min), {
  schemaId: GreaterThanDurationSchemaId,
  [GreaterThanDurationSchemaId]: {
    min
  },
  description: `a Duration greater than ${duration_.decode(min)}`,
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.greaterThanDuration = greaterThanDuration;
const GreaterThanOrEqualToDurationSchemaId = exports.GreaterThanOrEqualToDurationSchemaId = /*#__PURE__*/Symbol.for("effect/schema/GreaterThanOrEqualToDuration");
/**
 * @category Duration filters
 * @since 3.10.0
 */
const greaterThanOrEqualToDuration = (min, annotations) => self => self.pipe(filter(a => duration_.greaterThanOrEqualTo(a, min), {
  schemaId: GreaterThanOrEqualToDurationSchemaId,
  [GreaterThanOrEqualToDurationSchemaId]: {
    min
  },
  description: `a Duration greater than or equal to ${duration_.decode(min)}`,
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.greaterThanOrEqualToDuration = greaterThanOrEqualToDuration;
const BetweenDurationSchemaId = exports.BetweenDurationSchemaId = /*#__PURE__*/Symbol.for("effect/SchemaId/BetweenDuration");
/**
 * @category Duration filters
 * @since 3.10.0
 */
const betweenDuration = (minimum, maximum, annotations) => self => self.pipe(filter(a => duration_.between(a, {
  minimum,
  maximum
}), {
  schemaId: BetweenDurationSchemaId,
  [BetweenDurationSchemaId]: {
    maximum,
    minimum
  },
  description: `a Duration between ${duration_.decode(minimum)} and ${duration_.decode(maximum)}`,
  ...annotations
}));
/**
 * @category Uint8Array constructors
 * @since 3.10.0
 */
exports.betweenDuration = betweenDuration;
const Uint8ArrayFromSelf = exports.Uint8ArrayFromSelf = /*#__PURE__*/declare(Predicate.isUint8Array, {
  identifier: "Uint8ArrayFromSelf",
  pretty: () => u8arr => `new Uint8Array(${JSON.stringify(Array.from(u8arr))})`,
  arbitrary: () => fc => fc.uint8Array(),
  equivalence: () => array_.getEquivalence(Equal.equals)
});
const Uint8Array$ = exports.Uint8Array = /*#__PURE__*/transform(Array$(Number$.pipe(between(0, 255, {
  title: "8-bit unsigned integer",
  description: "a 8-bit unsigned integer"
}))).annotations({
  description: "an array of 8-bit unsigned integers that will be parsed into a Uint8Array"
}), Uint8ArrayFromSelf, {
  strict: true,
  decode: numbers => Uint8Array.from(numbers),
  encode: uint8Array => Array.from(uint8Array)
}).annotations({
  identifier: "Uint8Array"
});
const makeUint8ArrayTransformation = (id, decode, encode) => transformOrFail(String$.annotations({
  description: "a string that will be parsed into a Uint8Array"
}), Uint8ArrayFromSelf, {
  strict: true,
  decode: (s, _, ast) => either_.mapLeft(decode(s), decodeException => new ParseResult.Type(ast, s, decodeException.message)),
  encode: u => ParseResult.succeed(encode(u))
}).annotations({
  identifier: id
});
/**
 * Decodes a base64 (RFC4648) encoded string into a `Uint8Array`.
 *
 * @category Uint8Array transformations
 * @since 3.10.0
 */
const Uint8ArrayFromBase64 = exports.Uint8ArrayFromBase64 = /*#__PURE__*/makeUint8ArrayTransformation("Uint8ArrayFromBase64", Encoding.decodeBase64, Encoding.encodeBase64);
/**
 * Decodes a base64 (URL) encoded string into a `Uint8Array`.
 *
 * @category Uint8Array transformations
 * @since 3.10.0
 */
const Uint8ArrayFromBase64Url = exports.Uint8ArrayFromBase64Url = /*#__PURE__*/makeUint8ArrayTransformation("Uint8ArrayFromBase64Url", Encoding.decodeBase64Url, Encoding.encodeBase64Url);
/**
 * Decodes a hex encoded string into a `Uint8Array`.
 *
 * @category Uint8Array transformations
 * @since 3.10.0
 */
const Uint8ArrayFromHex = exports.Uint8ArrayFromHex = /*#__PURE__*/makeUint8ArrayTransformation("Uint8ArrayFromHex", Encoding.decodeHex, Encoding.encodeHex);
const makeEncodingTransformation = (id, decode, encode) => transformOrFail(String$.annotations({
  description: `A string that is interpreted as being ${id}-encoded and will be decoded into a UTF-8 string`
}), String$, {
  strict: true,
  decode: (s, _, ast) => either_.mapLeft(decode(s), decodeException => new ParseResult.Type(ast, s, decodeException.message)),
  encode: u => ParseResult.succeed(encode(u))
}).annotations({
  identifier: `StringFrom${id}`
});
/**
 * Decodes a base64 (RFC4648) encoded string into a UTF-8 string.
 *
 * @category string transformations
 * @since 3.10.0
 */
const StringFromBase64 = exports.StringFromBase64 = /*#__PURE__*/makeEncodingTransformation("Base64", Encoding.decodeBase64String, Encoding.encodeBase64);
/**
 * Decodes a base64 (URL) encoded string into a UTF-8 string.
 *
 * @category string transformations
 * @since 3.10.0
 */
const StringFromBase64Url = exports.StringFromBase64Url = /*#__PURE__*/makeEncodingTransformation("Base64Url", Encoding.decodeBase64UrlString, Encoding.encodeBase64Url);
/**
 * Decodes a hex encoded string into a UTF-8 string.
 *
 * @category string transformations
 * @since 3.10.0
 */
const StringFromHex = exports.StringFromHex = /*#__PURE__*/makeEncodingTransformation("Hex", Encoding.decodeHexString, Encoding.encodeHex);
/**
 * @category schema id
 * @since 3.10.0
 */
const MinItemsSchemaId = exports.MinItemsSchemaId = filters_.MinItemsSchemaId;
/**
 * @category ReadonlyArray filters
 * @since 3.10.0
 */
const minItems = (n, annotations) => self => {
  const minItems = Math.floor(n);
  if (minItems < 1) {
    throw new Error(errors_.getInvalidArgumentErrorMessage(`Expected an integer greater than or equal to 1, actual ${n}`));
  }
  return self.pipe(filter(a => a.length >= minItems, {
    schemaId: MinItemsSchemaId,
    description: `an array of at least ${minItems} items`,
    jsonSchema: {
      minItems
    },
    [AST.StableFilterAnnotationId]: true,
    ...annotations
  }));
};
/**
 * @category schema id
 * @since 3.10.0
 */
exports.minItems = minItems;
const MaxItemsSchemaId = exports.MaxItemsSchemaId = filters_.MaxItemsSchemaId;
/**
 * @category ReadonlyArray filters
 * @since 3.10.0
 */
const maxItems = (n, annotations) => self => self.pipe(filter(a => a.length <= n, {
  schemaId: MaxItemsSchemaId,
  description: `an array of at most ${n} items`,
  jsonSchema: {
    maxItems: n
  },
  [AST.StableFilterAnnotationId]: true,
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.maxItems = maxItems;
const ItemsCountSchemaId = exports.ItemsCountSchemaId = filters_.ItemsCountSchemaId;
/**
 * @category ReadonlyArray filters
 * @since 3.10.0
 */
const itemsCount = (n, annotations) => self => self.pipe(filter(a => a.length === n, {
  schemaId: ItemsCountSchemaId,
  description: `an array of exactly ${n} item(s)`,
  jsonSchema: {
    minItems: n,
    maxItems: n
  },
  [AST.StableFilterAnnotationId]: true,
  ...annotations
}));
/**
 * @category ReadonlyArray transformations
 * @since 3.10.0
 */
exports.itemsCount = itemsCount;
const getNumberIndexedAccess = self => make(AST.getNumberIndexedAccess(self.ast));
/**
 * Get the first element of a `ReadonlyArray`, or `None` if the array is empty.
 *
 * @category ReadonlyArray transformations
 * @since 3.10.0
 */
exports.getNumberIndexedAccess = getNumberIndexedAccess;
const head = self => transform(self, OptionFromSelf(getNumberIndexedAccess(typeSchema(self))), {
  strict: true,
  decode: array_.head,
  encode: option_.match({
    onNone: () => [],
    onSome: array_.of
  })
});
/**
 * Retrieves the first element of a `ReadonlyArray`.
 *
 * If the array is empty, it returns the `fallback` argument if provided; otherwise, it fails.
 *
 * @category ReadonlyArray transformations
 * @since 3.10.0
 */
exports.head = head;
const headOrElse = exports.headOrElse = /*#__PURE__*/(0, _Function.dual)(args => isSchema(args[0]), (self, fallback) => transformOrFail(self, getNumberIndexedAccess(typeSchema(self)), {
  strict: true,
  decode: (as, _, ast) => as.length > 0 ? ParseResult.succeed(as[0]) : fallback ? ParseResult.succeed(fallback()) : ParseResult.fail(new ParseResult.Type(ast, as)),
  encode: a => ParseResult.succeed(array_.of(a))
}));
/**
 * @category schema id
 * @since 3.10.0
 */
const ValidDateSchemaId = exports.ValidDateSchemaId = /*#__PURE__*/Symbol.for("effect/SchemaId/ValidDate");
/**
 * Defines a filter that specifically rejects invalid dates, such as `new
 * Date("Invalid Date")`. This filter ensures that only properly formatted and
 * valid date objects are accepted, enhancing data integrity by preventing
 * erroneous date values from being processed.
 *
 * @category Date filters
 * @since 3.10.0
 */
const validDate = annotations => self => self.pipe(filter(a => !Number.isNaN(a.getTime()), {
  schemaId: ValidDateSchemaId,
  description: "a valid Date",
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.validDate = validDate;
const LessThanDateSchemaId = exports.LessThanDateSchemaId = /*#__PURE__*/Symbol.for("effect/SchemaId/LessThanDate");
/**
 * @category Date filters
 * @since 3.10.0
 */
const lessThanDate = (max, annotations) => self => self.pipe(filter(a => a < max, {
  schemaId: LessThanDateSchemaId,
  [LessThanDateSchemaId]: {
    max
  },
  description: `a date before ${util_.formatDate(max)}`,
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.lessThanDate = lessThanDate;
const LessThanOrEqualToDateSchemaId = exports.LessThanOrEqualToDateSchemaId = /*#__PURE__*/Symbol.for("effect/schema/LessThanOrEqualToDate");
/**
 * @category Date filters
 * @since 3.10.0
 */
const lessThanOrEqualToDate = (max, annotations) => self => self.pipe(filter(a => a <= max, {
  schemaId: LessThanDateSchemaId,
  [LessThanDateSchemaId]: {
    max
  },
  description: `a date before or equal to ${util_.formatDate(max)}`,
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.lessThanOrEqualToDate = lessThanOrEqualToDate;
const GreaterThanDateSchemaId = exports.GreaterThanDateSchemaId = /*#__PURE__*/Symbol.for("effect/SchemaId/GreaterThanDate");
/**
 * @category Date filters
 * @since 3.10.0
 */
const greaterThanDate = (min, annotations) => self => self.pipe(filter(a => a > min, {
  schemaId: GreaterThanDateSchemaId,
  [GreaterThanDateSchemaId]: {
    min
  },
  description: `a date after ${util_.formatDate(min)}`,
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.greaterThanDate = greaterThanDate;
const GreaterThanOrEqualToDateSchemaId = exports.GreaterThanOrEqualToDateSchemaId = /*#__PURE__*/Symbol.for("effect/schema/GreaterThanOrEqualToDate");
/**
 * @category Date filters
 * @since 3.10.0
 */
const greaterThanOrEqualToDate = (min, annotations) => self => self.pipe(filter(a => a >= min, {
  schemaId: GreaterThanOrEqualToDateSchemaId,
  [GreaterThanOrEqualToDateSchemaId]: {
    min
  },
  description: `a date after or equal to ${util_.formatDate(min)}`,
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.greaterThanOrEqualToDate = greaterThanOrEqualToDate;
const BetweenDateSchemaId = exports.BetweenDateSchemaId = /*#__PURE__*/Symbol.for("effect/SchemaId/BetweenDate");
/**
 * @category Date filters
 * @since 3.10.0
 */
const betweenDate = (minimum, maximum, annotations) => self => self.pipe(filter(a => a <= maximum && a >= minimum, {
  schemaId: BetweenDateSchemaId,
  [BetweenDateSchemaId]: {
    maximum,
    minimum
  },
  description: `a date between ${util_.formatDate(minimum)} and ${util_.formatDate(maximum)}`,
  ...annotations
}));
/**
 * Describes a schema that accommodates potentially invalid `Date` instances,
 * such as `new Date("Invalid Date")`, without rejection.
 *
 * @category Date constructors
 * @since 3.10.0
 */
exports.betweenDate = betweenDate;
class DateFromSelf extends /*#__PURE__*/declare(Predicate.isDate, {
  identifier: "DateFromSelf",
  description: "a potentially invalid Date instance",
  pretty: () => date => `new Date(${JSON.stringify(date)})`,
  arbitrary: () => fc => fc.date({
    noInvalidDate: false
  }),
  equivalence: () => Equivalence.Date
}) {}
/**
 * Defines a schema that ensures only valid dates are accepted. This schema
 * rejects values like `new Date("Invalid Date")`, which, despite being a `Date`
 * instance, represents an invalid date. Such stringent validation ensures that
 * all date objects processed through this schema are properly formed and
 * represent real dates.
 *
 * @category Date constructors
 * @since 3.10.0
 */
exports.DateFromSelf = DateFromSelf;
class ValidDateFromSelf extends /*#__PURE__*/DateFromSelf.pipe( /*#__PURE__*/validDate({
  identifier: "ValidDateFromSelf",
  description: "a valid Date instance"
})) {}
/**
 * Defines a schema that attempts to convert a `string` to a `Date` object using
 * the `new Date` constructor. This conversion is lenient, meaning it does not
 * reject strings that do not form valid dates (e.g., using `new Date("Invalid
 * Date")` results in a `Date` object, despite being invalid).
 *
 * @category Date transformations
 * @since 3.10.0
 */
exports.ValidDateFromSelf = ValidDateFromSelf;
class DateFromString extends /*#__PURE__*/transform(String$.annotations({
  description: "a string that will be parsed into a Date"
}), DateFromSelf, {
  strict: true,
  decode: s => new Date(s),
  encode: d => util_.formatDate(d)
}).annotations({
  identifier: "DateFromString"
}) {}
/** @ignore */
exports.DateFromString = DateFromString;
class Date$ extends /*#__PURE__*/DateFromString.pipe( /*#__PURE__*/validDate({
  identifier: "Date"
})) {}
exports.Date = Date$;
/**
 * Defines a schema that converts a `number` into a `Date` object using the `new
 * Date` constructor. This schema does not validate the numerical input,
 * allowing potentially invalid values such as `NaN`, `Infinity`, and
 * `-Infinity` to be converted into `Date` objects. During the encoding process,
 * any invalid `Date` object will be encoded to `NaN`.
 *
 * @category Date transformations
 * @since 3.10.0
 */
class DateFromNumber extends /*#__PURE__*/transform(Number$.annotations({
  description: "a number that will be parsed into a Date"
}), DateFromSelf, {
  strict: true,
  decode: n => new Date(n),
  encode: d => d.getTime()
}).annotations({
  identifier: "DateFromNumber"
}) {}
/**
 * Describes a schema that represents a `DateTime.Utc` instance.
 *
 * @category DateTime.Utc constructors
 * @since 3.10.0
 */
exports.DateFromNumber = DateFromNumber;
class DateTimeUtcFromSelf extends /*#__PURE__*/declare(u => dateTime.isDateTime(u) && dateTime.isUtc(u), {
  identifier: "DateTimeUtcFromSelf",
  description: "a DateTime.Utc instance",
  pretty: () => dateTime => dateTime.toString(),
  arbitrary: () => fc => fc.date().map(date => dateTime.unsafeFromDate(date)),
  equivalence: () => dateTime.Equivalence
}) {}
exports.DateTimeUtcFromSelf = DateTimeUtcFromSelf;
const decodeDateTime = (input, _, ast) => ParseResult.try({
  try: () => dateTime.unsafeMake(input),
  catch: () => new ParseResult.Type(ast, input)
});
/**
 * Defines a schema that attempts to convert a `number` to a `DateTime.Utc` instance using the `DateTime.unsafeMake` constructor.
 *
 * @category DateTime.Utc transformations
 * @since 3.10.0
 */
class DateTimeUtcFromNumber extends /*#__PURE__*/transformOrFail(Number$.annotations({
  description: "a number that will be parsed into a DateTime.Utc"
}), DateTimeUtcFromSelf, {
  strict: true,
  decode: decodeDateTime,
  encode: dt => ParseResult.succeed(dateTime.toEpochMillis(dt))
}).annotations({
  identifier: "DateTimeUtcFromNumber"
}) {}
/**
 * Defines a schema that attempts to convert a `string` to a `DateTime.Utc` instance using the `DateTime.unsafeMake` constructor.
 *
 * @category DateTime.Utc transformations
 * @since 3.10.0
 */
exports.DateTimeUtcFromNumber = DateTimeUtcFromNumber;
class DateTimeUtc extends /*#__PURE__*/transformOrFail(String$.annotations({
  description: "a string that will be parsed into a DateTime.Utc"
}), DateTimeUtcFromSelf, {
  strict: true,
  decode: decodeDateTime,
  encode: dt => ParseResult.succeed(dateTime.formatIso(dt))
}).annotations({
  identifier: "DateTimeUtc"
}) {}
exports.DateTimeUtc = DateTimeUtc;
const timeZoneOffsetArbitrary = () => fc => fc.integer({
  min: -12 * 60 * 60 * 1000,
  max: 12 * 60 * 60 * 1000
}).map(dateTime.zoneMakeOffset);
/**
 * Describes a schema that represents a `TimeZone.Offset` instance.
 *
 * @category TimeZone constructors
 * @since 3.10.0
 */
class TimeZoneOffsetFromSelf extends /*#__PURE__*/declare(dateTime.isTimeZoneOffset, {
  identifier: "TimeZoneOffsetFromSelf",
  description: "a TimeZone.Offset instance",
  pretty: () => zone => zone.toString(),
  arbitrary: timeZoneOffsetArbitrary
}) {}
/**
 * Defines a schema that converts a `number` to a `TimeZone.Offset` instance using the `DateTime.zoneMakeOffset` constructor.
 *
 * @category TimeZone transformations
 * @since 3.10.0
 */
exports.TimeZoneOffsetFromSelf = TimeZoneOffsetFromSelf;
class TimeZoneOffset extends /*#__PURE__*/transform(Number$.annotations({
  description: "a number that will be parsed into a TimeZone.Offset"
}), TimeZoneOffsetFromSelf, {
  strict: true,
  decode: dateTime.zoneMakeOffset,
  encode: tz => tz.offset
}).annotations({
  identifier: "TimeZoneOffset"
}) {}
exports.TimeZoneOffset = TimeZoneOffset;
const timeZoneNamedArbitrary = () => fc => fc.constantFrom(...Intl.supportedValuesOf("timeZone")).map(dateTime.zoneUnsafeMakeNamed);
/**
 * Describes a schema that represents a `TimeZone.Named` instance.
 *
 * @category TimeZone constructors
 * @since 3.10.0
 */
class TimeZoneNamedFromSelf extends /*#__PURE__*/declare(dateTime.isTimeZoneNamed, {
  identifier: "TimeZoneNamedFromSelf",
  description: "a TimeZone.Named instance",
  pretty: () => zone => zone.toString(),
  arbitrary: timeZoneNamedArbitrary
}) {}
/**
 * Defines a schema that attempts to convert a `string` to a `TimeZone.Named` instance using the `DateTime.zoneUnsafeMakeNamed` constructor.
 *
 * @category TimeZone transformations
 * @since 3.10.0
 */
exports.TimeZoneNamedFromSelf = TimeZoneNamedFromSelf;
class TimeZoneNamed extends /*#__PURE__*/transformOrFail(String$.annotations({
  description: "a string that will be parsed into a TimeZone.Named"
}), TimeZoneNamedFromSelf, {
  strict: true,
  decode: (s, _, ast) => ParseResult.try({
    try: () => dateTime.zoneUnsafeMakeNamed(s),
    catch: () => new ParseResult.Type(ast, s)
  }),
  encode: tz => ParseResult.succeed(tz.id)
}).annotations({
  identifier: "TimeZoneNamed"
}) {}
/**
 * @category TimeZone constructors
 * @since 3.10.0
 */
exports.TimeZoneNamed = TimeZoneNamed;
const TimeZoneFromSelf = exports.TimeZoneFromSelf = /*#__PURE__*/Union(TimeZoneOffsetFromSelf, TimeZoneNamedFromSelf);
/**
 * Defines a schema that attempts to convert a `string` to a `TimeZone` using the `DateTime.zoneFromString` constructor.
 *
 * @category TimeZone transformations
 * @since 3.10.0
 */
class TimeZone extends /*#__PURE__*/transformOrFail(String$.annotations({
  description: "a string that will be parsed into a TimeZone"
}), TimeZoneFromSelf, {
  strict: true,
  decode: (s, _, ast) => option_.match(dateTime.zoneFromString(s), {
    onNone: () => ParseResult.fail(new ParseResult.Type(ast, s)),
    onSome: ParseResult.succeed
  }),
  encode: tz => ParseResult.succeed(dateTime.zoneToString(tz))
}).annotations({
  identifier: "TimeZone"
}) {}
exports.TimeZone = TimeZone;
const timeZoneArbitrary = fc => fc.oneof(timeZoneOffsetArbitrary()(fc), timeZoneNamedArbitrary()(fc));
/**
 * Describes a schema that represents a `DateTime.Zoned` instance.
 *
 * @category DateTime.Zoned constructors
 * @since 3.10.0
 */
class DateTimeZonedFromSelf extends /*#__PURE__*/declare(u => dateTime.isDateTime(u) && dateTime.isZoned(u), {
  identifier: "DateTimeZonedFromSelf",
  description: "a DateTime.Zoned instance",
  pretty: () => dateTime => dateTime.toString(),
  arbitrary: () => fc => fc.date().chain(date => timeZoneArbitrary(fc).map(timeZone => dateTime.unsafeMakeZoned(date, {
    timeZone
  }))),
  equivalence: () => dateTime.Equivalence
}) {}
/**
 * Defines a schema that attempts to convert a `string` to a `DateTime.Zoned` instance.
 *
 * @category DateTime.Zoned transformations
 * @since 3.10.0
 */
exports.DateTimeZonedFromSelf = DateTimeZonedFromSelf;
class DateTimeZoned extends /*#__PURE__*/transformOrFail(String$.annotations({
  description: "a string that will be parsed into a DateTime.Zoned"
}), DateTimeZonedFromSelf, {
  strict: true,
  decode: (s, _, ast) => option_.match(dateTime.makeZonedFromString(s), {
    onNone: () => ParseResult.fail(new ParseResult.Type(ast, s)),
    onSome: ParseResult.succeed
  }),
  encode: dt => ParseResult.succeed(dateTime.formatIsoZoned(dt))
}).annotations({
  identifier: "DateTimeZoned"
}) {}
exports.DateTimeZoned = DateTimeZoned;
const OptionNoneEncoded = /*#__PURE__*/Struct({
  _tag: Literal("None")
}).annotations({
  description: "NoneEncoded"
});
const optionSomeEncoded = value => Struct({
  _tag: Literal("Some"),
  value
}).annotations({
  description: `SomeEncoded<${format(value)}>`
});
const optionEncoded = value => Union(OptionNoneEncoded, optionSomeEncoded(value)).annotations({
  description: `OptionEncoded<${format(value)}>`
});
const optionDecode = input => input._tag === "None" ? option_.none() : option_.some(input.value);
const optionArbitrary = (value, ctx) => fc => fc.oneof(ctx, fc.record({
  _tag: fc.constant("None")
}), fc.record({
  _tag: fc.constant("Some"),
  value: value(fc)
})).map(optionDecode);
const optionPretty = value => option_.match({
  onNone: () => "none()",
  onSome: a => `some(${value(a)})`
});
const optionParse = decodeUnknown => (u, options, ast) => option_.isOption(u) ? option_.isNone(u) ? ParseResult.succeed(option_.none()) : toComposite(decodeUnknown(u.value, options), option_.some, ast, u) : ParseResult.fail(new ParseResult.Type(ast, u));
/**
 * @category Option transformations
 * @since 3.10.0
 */
const OptionFromSelf = value => {
  return declare([value], {
    decode: value => optionParse(ParseResult.decodeUnknown(value)),
    encode: value => optionParse(ParseResult.encodeUnknown(value))
  }, {
    description: `Option<${format(value)}>`,
    pretty: optionPretty,
    arbitrary: optionArbitrary,
    equivalence: option_.getEquivalence
  });
};
exports.OptionFromSelf = OptionFromSelf;
const makeNoneEncoded = {
  _tag: "None"
};
const makeSomeEncoded = value => ({
  _tag: "Some",
  value
});
/**
 * @category Option transformations
 * @since 3.10.0
 */
const Option = value => {
  const value_ = asSchema(value);
  return transform(optionEncoded(value_), OptionFromSelf(typeSchema(value_)), {
    strict: true,
    decode: optionDecode,
    encode: option_.match({
      onNone: () => makeNoneEncoded,
      onSome: makeSomeEncoded
    })
  });
};
/**
 * @category Option transformations
 * @since 3.10.0
 */
exports.Option = Option;
const OptionFromNullOr = value => {
  const value_ = asSchema(value);
  return transform(NullOr(value_), OptionFromSelf(typeSchema(value_)), {
    strict: true,
    decode: option_.fromNullable,
    encode: option_.getOrNull
  });
};
/**
 * @category Option transformations
 * @since 3.10.0
 */
exports.OptionFromNullOr = OptionFromNullOr;
const OptionFromNullishOr = (value, onNoneEncoding) => {
  const value_ = asSchema(value);
  return transform(NullishOr(value_), OptionFromSelf(typeSchema(value_)), {
    strict: true,
    decode: option_.fromNullable,
    encode: onNoneEncoding === null ? option_.getOrNull : option_.getOrUndefined
  });
};
/**
 * @category Option transformations
 * @since 3.10.0
 */
exports.OptionFromNullishOr = OptionFromNullishOr;
const OptionFromUndefinedOr = value => {
  const value_ = asSchema(value);
  return transform(UndefinedOr(value_), OptionFromSelf(typeSchema(value_)), {
    strict: true,
    decode: option_.fromNullable,
    encode: option_.getOrUndefined
  });
};
/**
 * Transforms strings into an Option type, effectively filtering out empty or
 * whitespace-only strings by trimming them and checking their length. Returns
 * `none` for invalid inputs and `some` for valid non-empty strings.
 *
 * @example
 * import { Schema } from "effect"
 *
 * console.log(Schema.decodeSync(Schema.OptionFromNonEmptyTrimmedString)("")) // Option.none()
 * console.log(Schema.decodeSync(Schema.OptionFromNonEmptyTrimmedString)(" a ")) // Option.some("a")
 * console.log(Schema.decodeSync(Schema.OptionFromNonEmptyTrimmedString)("a")) // Option.some("a")
 *
 * @category Option transformations
 * @since 3.10.0
 */
exports.OptionFromUndefinedOr = OptionFromUndefinedOr;
const OptionFromNonEmptyTrimmedString = exports.OptionFromNonEmptyTrimmedString = /*#__PURE__*/transform(String$, /*#__PURE__*/OptionFromSelf(NonEmptyTrimmedString), {
  strict: true,
  decode: s => {
    const out = s.trim();
    return out.length === 0 ? option_.none() : option_.some(out);
  },
  encode: /*#__PURE__*/option_.getOrElse(() => "")
});
const rightEncoded = right => Struct({
  _tag: Literal("Right"),
  right
}).annotations({
  description: `RightEncoded<${format(right)}>`
});
const leftEncoded = left => Struct({
  _tag: Literal("Left"),
  left
}).annotations({
  description: `LeftEncoded<${format(left)}>`
});
const eitherEncoded = (right, left) => Union(rightEncoded(right), leftEncoded(left)).annotations({
  description: `EitherEncoded<${format(left)}, ${format(right)}>`
});
const eitherDecode = input => input._tag === "Left" ? either_.left(input.left) : either_.right(input.right);
const eitherArbitrary = (right, left) => fc => fc.oneof(fc.record({
  _tag: fc.constant("Left"),
  left: left(fc)
}), fc.record({
  _tag: fc.constant("Right"),
  right: right(fc)
})).map(eitherDecode);
const eitherPretty = (right, left) => either_.match({
  onLeft: e => `left(${left(e)})`,
  onRight: a => `right(${right(a)})`
});
const eitherParse = (parseRight, decodeUnknownLeft) => (u, options, ast) => either_.isEither(u) ? either_.match(u, {
  onLeft: left => toComposite(decodeUnknownLeft(left, options), either_.left, ast, u),
  onRight: right => toComposite(parseRight(right, options), either_.right, ast, u)
}) : ParseResult.fail(new ParseResult.Type(ast, u));
/**
 * @category Either transformations
 * @since 3.10.0
 */
const EitherFromSelf = ({
  left,
  right
}) => {
  return declare([right, left], {
    decode: (right, left) => eitherParse(ParseResult.decodeUnknown(right), ParseResult.decodeUnknown(left)),
    encode: (right, left) => eitherParse(ParseResult.encodeUnknown(right), ParseResult.encodeUnknown(left))
  }, {
    description: `Either<${format(right)}, ${format(left)}>`,
    pretty: eitherPretty,
    arbitrary: eitherArbitrary,
    equivalence: (right, left) => either_.getEquivalence({
      left,
      right
    })
  });
};
exports.EitherFromSelf = EitherFromSelf;
const makeLeftEncoded = left => ({
  _tag: "Left",
  left
});
const makeRightEncoded = right => ({
  _tag: "Right",
  right
});
/**
 * @category Either transformations
 * @since 3.10.0
 */
const Either = ({
  left,
  right
}) => {
  const right_ = asSchema(right);
  const left_ = asSchema(left);
  return transform(eitherEncoded(right_, left_), EitherFromSelf({
    left: typeSchema(left_),
    right: typeSchema(right_)
  }), {
    strict: true,
    decode: eitherDecode,
    encode: either_.match({
      onLeft: makeLeftEncoded,
      onRight: makeRightEncoded
    })
  });
};
/**
 * @example
 * import * as Schema from "effect/Schema"
 *
 * // Schema<string | number, Either<string, number>>
 * Schema.EitherFromUnion({ left: Schema.String, right: Schema.Number })
 *
 * @category Either transformations
 * @since 3.10.0
 */
exports.Either = Either;
const EitherFromUnion = ({
  left,
  right
}) => {
  const right_ = asSchema(right);
  const left_ = asSchema(left);
  const toright = typeSchema(right_);
  const toleft = typeSchema(left_);
  const fromRight = transform(right_, rightEncoded(toright), {
    strict: true,
    decode: makeRightEncoded,
    encode: r => r.right
  });
  const fromLeft = transform(left_, leftEncoded(toleft), {
    strict: true,
    decode: makeLeftEncoded,
    encode: l => l.left
  });
  return transform(Union(fromRight, fromLeft), EitherFromSelf({
    left: toleft,
    right: toright
  }), {
    strict: true,
    decode: from => from._tag === "Left" ? either_.left(from.left) : either_.right(from.right),
    encode: either_.match({
      onLeft: makeLeftEncoded,
      onRight: makeRightEncoded
    })
  });
};
exports.EitherFromUnion = EitherFromUnion;
const mapArbitrary = (key, value, ctx) => {
  return fc => {
    const items = fc.array(fc.tuple(key(fc), value(fc)));
    return (ctx.depthIdentifier !== undefined ? fc.oneof(ctx, fc.constant([]), items) : items).map(as => new Map(as));
  };
};
const readonlyMapPretty = (key, value) => map => `new Map([${Array.from(map.entries()).map(([k, v]) => `[${key(k)}, ${value(v)}]`).join(", ")}])`;
const readonlyMapEquivalence = (key, value) => {
  const arrayEquivalence = array_.getEquivalence(Equivalence.make(([ka, va], [kb, vb]) => key(ka, kb) && value(va, vb)));
  return Equivalence.make((a, b) => arrayEquivalence(Array.from(a.entries()), Array.from(b.entries())));
};
const readonlyMapParse = decodeUnknown => (u, options, ast) => Predicate.isMap(u) ? toComposite(decodeUnknown(Array.from(u.entries()), options), as => new Map(as), ast, u) : ParseResult.fail(new ParseResult.Type(ast, u));
const mapFromSelf_ = (key, value, description) => declare([key, value], {
  decode: (Key, Value) => readonlyMapParse(ParseResult.decodeUnknown(Array$(Tuple(Key, Value)))),
  encode: (Key, Value) => readonlyMapParse(ParseResult.encodeUnknown(Array$(Tuple(Key, Value))))
}, {
  description,
  pretty: readonlyMapPretty,
  arbitrary: mapArbitrary,
  equivalence: readonlyMapEquivalence
});
/**
 * @category ReadonlyMap
 * @since 3.10.0
 */
const ReadonlyMapFromSelf = ({
  key,
  value
}) => mapFromSelf_(key, value, `ReadonlyMap<${format(key)}, ${format(value)}>`);
/**
 * @category Map
 * @since 3.10.0
 */
exports.ReadonlyMapFromSelf = ReadonlyMapFromSelf;
const MapFromSelf = ({
  key,
  value
}) => mapFromSelf_(key, value, `Map<${format(key)}, ${format(value)}>`);
/**
 * @category ReadonlyMap transformations
 * @since 3.10.0
 */
exports.MapFromSelf = MapFromSelf;
const ReadonlyMap = ({
  key,
  value
}) => {
  const key_ = asSchema(key);
  const value_ = asSchema(value);
  return transform(Array$(Tuple(key_, value_)), ReadonlyMapFromSelf({
    key: typeSchema(key_),
    value: typeSchema(value_)
  }), {
    strict: true,
    decode: as => new Map(as),
    encode: map => Array.from(map.entries())
  });
};
exports.ReadonlyMap = ReadonlyMap;
const map = ({
  key,
  value
}) => {
  const key_ = asSchema(key);
  const value_ = asSchema(value);
  return transform(Array$(Tuple(key_, value_)), MapFromSelf({
    key: typeSchema(key_),
    value: typeSchema(value_)
  }), {
    strict: true,
    decode: as => new Map(as),
    encode: map => Array.from(map.entries())
  });
};
exports.Map = map;
/**
 * @category ReadonlyMap transformations
 * @since 3.10.0
 */
const ReadonlyMapFromRecord = ({
  key,
  value
}) => transform(Record({
  key: encodedBoundSchema(key),
  value
}).annotations({
  description: "a record that will be parsed into a ReadonlyMap"
}), ReadonlyMapFromSelf({
  key,
  value: typeSchema(value)
}), {
  strict: true,
  decode: record => new Map(Object.entries(record)),
  encode: record_.fromEntries
});
/**
 * @category Map transformations
 * @since 3.10.0
 */
exports.ReadonlyMapFromRecord = ReadonlyMapFromRecord;
const MapFromRecord = ({
  key,
  value
}) => transform(Record({
  key: encodedBoundSchema(key),
  value
}).annotations({
  description: "a record that will be parsed into a Map"
}), MapFromSelf({
  key,
  value: typeSchema(value)
}), {
  strict: true,
  decode: record => new Map(Object.entries(record)),
  encode: record_.fromEntries
});
exports.MapFromRecord = MapFromRecord;
const setArbitrary = (item, ctx) => fc => {
  const items = fc.array(item(fc));
  return (ctx.depthIdentifier !== undefined ? fc.oneof(ctx, fc.constant([]), items) : items).map(as => new Set(as));
};
const readonlySetPretty = item => set => `new Set([${Array.from(set.values()).map(a => item(a)).join(", ")}])`;
const readonlySetEquivalence = item => {
  const arrayEquivalence = array_.getEquivalence(item);
  return Equivalence.make((a, b) => arrayEquivalence(Array.from(a.values()), Array.from(b.values())));
};
const readonlySetParse = decodeUnknown => (u, options, ast) => Predicate.isSet(u) ? toComposite(decodeUnknown(Array.from(u.values()), options), as => new Set(as), ast, u) : ParseResult.fail(new ParseResult.Type(ast, u));
const setFromSelf_ = (value, description) => declare([value], {
  decode: item => readonlySetParse(ParseResult.decodeUnknown(Array$(item))),
  encode: item => readonlySetParse(ParseResult.encodeUnknown(Array$(item)))
}, {
  description,
  pretty: readonlySetPretty,
  arbitrary: setArbitrary,
  equivalence: readonlySetEquivalence
});
/**
 * @category ReadonlySet
 * @since 3.10.0
 */
const ReadonlySetFromSelf = value => setFromSelf_(value, `ReadonlySet<${format(value)}>`);
/**
 * @category Set
 * @since 3.10.0
 */
exports.ReadonlySetFromSelf = ReadonlySetFromSelf;
const SetFromSelf = value => setFromSelf_(value, `Set<${format(value)}>`);
/**
 * @category ReadonlySet transformations
 * @since 3.10.0
 */
exports.SetFromSelf = SetFromSelf;
const ReadonlySet = value => {
  const value_ = asSchema(value);
  return transform(Array$(value_), ReadonlySetFromSelf(typeSchema(value_)), {
    strict: true,
    decode: as => new Set(as),
    encode: set => Array.from(set)
  });
};
exports.ReadonlySet = ReadonlySet;
const set = value => {
  const value_ = asSchema(value);
  return transform(Array$(value_), SetFromSelf(typeSchema(value_)), {
    strict: true,
    decode: as => new Set(as),
    encode: set => Array.from(set)
  });
};
exports.Set = set;
const bigDecimalPretty = () => val => `BigDecimal(${bigDecimal_.format(bigDecimal_.normalize(val))})`;
const bigDecimalArbitrary = () => fc => fc.tuple(fc.bigInt(), fc.integer()).map(([value, scale]) => bigDecimal_.make(value, scale));
/**
 * @category BigDecimal constructors
 * @since 3.10.0
 */
class BigDecimalFromSelf extends /*#__PURE__*/declare(bigDecimal_.isBigDecimal, {
  identifier: "BigDecimalFromSelf",
  pretty: bigDecimalPretty,
  arbitrary: bigDecimalArbitrary,
  equivalence: () => bigDecimal_.Equivalence
}) {}
/**
 * @category BigDecimal transformations
 * @since 3.10.0
 */
exports.BigDecimalFromSelf = BigDecimalFromSelf;
class BigDecimal extends /*#__PURE__*/transformOrFail(String$.annotations({
  description: "a string that will be parsed into a BigDecimal"
}), BigDecimalFromSelf, {
  strict: true,
  decode: (num, _, ast) => bigDecimal_.fromString(num).pipe(option_.match({
    onNone: () => ParseResult.fail(new ParseResult.Type(ast, num)),
    onSome: val => ParseResult.succeed(bigDecimal_.normalize(val))
  })),
  encode: val => ParseResult.succeed(bigDecimal_.format(bigDecimal_.normalize(val)))
}).annotations({
  identifier: "BigDecimal"
}) {}
/**
 * A schema that transforms a `number` into a `BigDecimal`.
 * When encoding, this Schema will produce incorrect results if the BigDecimal exceeds the 64-bit range of a number.
 *
 * @category BigDecimal transformations
 * @since 3.10.0
 */
exports.BigDecimal = BigDecimal;
class BigDecimalFromNumber extends /*#__PURE__*/transformOrFail(Number$.annotations({
  description: "a number that will be parsed into a BigDecimal"
}), BigDecimalFromSelf, {
  strict: true,
  decode: num => ParseResult.succeed(bigDecimal_.fromNumber(num)),
  encode: val => ParseResult.succeed(bigDecimal_.unsafeToNumber(val))
}).annotations({
  identifier: "BigDecimalFromNumber"
}) {}
/**
 * @category schema id
 * @since 3.10.0
 */
exports.BigDecimalFromNumber = BigDecimalFromNumber;
const GreaterThanBigDecimalSchemaId = exports.GreaterThanBigDecimalSchemaId = /*#__PURE__*/Symbol.for("effect/SchemaId/GreaterThanBigDecimal");
/**
 * @category BigDecimal filters
 * @since 3.10.0
 */
const greaterThanBigDecimal = (min, annotations) => self => self.pipe(filter(a => bigDecimal_.greaterThan(a, min), {
  schemaId: GreaterThanBigDecimalSchemaId,
  [GreaterThanBigDecimalSchemaId]: {
    min
  },
  description: `a BigDecimal greater than ${bigDecimal_.format(min)}`,
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.greaterThanBigDecimal = greaterThanBigDecimal;
const GreaterThanOrEqualToBigDecimalSchemaId = exports.GreaterThanOrEqualToBigDecimalSchemaId = /*#__PURE__*/Symbol.for("effect/schema/GreaterThanOrEqualToBigDecimal");
/**
 * @category BigDecimal filters
 * @since 3.10.0
 */
const greaterThanOrEqualToBigDecimal = (min, annotations) => self => self.pipe(filter(a => bigDecimal_.greaterThanOrEqualTo(a, min), {
  schemaId: GreaterThanOrEqualToBigDecimalSchemaId,
  [GreaterThanOrEqualToBigDecimalSchemaId]: {
    min
  },
  description: `a BigDecimal greater than or equal to ${bigDecimal_.format(min)}`,
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.greaterThanOrEqualToBigDecimal = greaterThanOrEqualToBigDecimal;
const LessThanBigDecimalSchemaId = exports.LessThanBigDecimalSchemaId = /*#__PURE__*/Symbol.for("effect/SchemaId/LessThanBigDecimal");
/**
 * @category BigDecimal filters
 * @since 3.10.0
 */
const lessThanBigDecimal = (max, annotations) => self => self.pipe(filter(a => bigDecimal_.lessThan(a, max), {
  schemaId: LessThanBigDecimalSchemaId,
  [LessThanBigDecimalSchemaId]: {
    max
  },
  description: `a BigDecimal less than ${bigDecimal_.format(max)}`,
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.lessThanBigDecimal = lessThanBigDecimal;
const LessThanOrEqualToBigDecimalSchemaId = exports.LessThanOrEqualToBigDecimalSchemaId = /*#__PURE__*/Symbol.for("effect/schema/LessThanOrEqualToBigDecimal");
/**
 * @category BigDecimal filters
 * @since 3.10.0
 */
const lessThanOrEqualToBigDecimal = (max, annotations) => self => self.pipe(filter(a => bigDecimal_.lessThanOrEqualTo(a, max), {
  schemaId: LessThanOrEqualToBigDecimalSchemaId,
  [LessThanOrEqualToBigDecimalSchemaId]: {
    max
  },
  description: `a BigDecimal less than or equal to ${bigDecimal_.format(max)}`,
  ...annotations
}));
/**
 * @category schema id
 * @since 3.10.0
 */
exports.lessThanOrEqualToBigDecimal = lessThanOrEqualToBigDecimal;
const PositiveBigDecimalSchemaId = exports.PositiveBigDecimalSchemaId = /*#__PURE__*/Symbol.for("effect/schema/PositiveBigDecimal");
/**
 * @category BigDecimal filters
 * @since 3.10.0
 */
const positiveBigDecimal = annotations => self => self.pipe(filter(a => bigDecimal_.isPositive(a), {
  schemaId: PositiveBigDecimalSchemaId,
  description: `a positive BigDecimal`,
  ...annotations
}));
/**
 * @category BigDecimal constructors
 * @since 3.10.0
 */
exports.positiveBigDecimal = positiveBigDecimal;
const PositiveBigDecimalFromSelf = exports.PositiveBigDecimalFromSelf = /*#__PURE__*/BigDecimalFromSelf.pipe( /*#__PURE__*/positiveBigDecimal({
  identifier: "PositiveBigDecimalFromSelf",
  title: "PositiveBigDecimalFromSelf"
}));
/**
 * @category schema id
 * @since 3.10.0
 */
const NonNegativeBigDecimalSchemaId = exports.NonNegativeBigDecimalSchemaId = /*#__PURE__*/Symbol.for("effect/schema/NonNegativeBigDecimal");
/**
 * @category BigDecimal filters
 * @since 3.10.0
 */
const nonNegativeBigDecimal = annotations => self => self.pipe(filter(a => a.value >= 0n, {
  schemaId: NonNegativeBigDecimalSchemaId,
  description: `a non-negative BigDecimal`,
  ...annotations
}));
/**
 * @category BigDecimal constructors
 * @since 3.10.0
 */
exports.nonNegativeBigDecimal = nonNegativeBigDecimal;
const NonNegativeBigDecimalFromSelf = exports.NonNegativeBigDecimalFromSelf = /*#__PURE__*/BigDecimalFromSelf.pipe( /*#__PURE__*/nonNegativeBigDecimal({
  identifier: "NonNegativeBigDecimalFromSelf",
  title: "NonNegativeBigDecimalFromSelf"
}));
/**
 * @category schema id
 * @since 3.10.0
 */
const NegativeBigDecimalSchemaId = exports.NegativeBigDecimalSchemaId = /*#__PURE__*/Symbol.for("effect/schema/NegativeBigDecimal");
/**
 * @category BigDecimal filters
 * @since 3.10.0
 */
const negativeBigDecimal = annotations => self => self.pipe(filter(a => bigDecimal_.isNegative(a), {
  schemaId: NegativeBigDecimalSchemaId,
  description: `a negative BigDecimal`,
  ...annotations
}));
/**
 * @category BigDecimal constructors
 * @since 3.10.0
 */
exports.negativeBigDecimal = negativeBigDecimal;
const NegativeBigDecimalFromSelf = exports.NegativeBigDecimalFromSelf = /*#__PURE__*/BigDecimalFromSelf.pipe( /*#__PURE__*/negativeBigDecimal({
  identifier: "NegativeBigDecimalFromSelf",
  title: "NegativeBigDecimalFromSelf"
}));
/**
 * @category schema id
 * @since 3.10.0
 */
const NonPositiveBigDecimalSchemaId = exports.NonPositiveBigDecimalSchemaId = /*#__PURE__*/Symbol.for("effect/schema/NonPositiveBigDecimal");
/**
 * @category BigDecimal filters
 * @since 3.10.0
 */
const nonPositiveBigDecimal = annotations => self => self.pipe(filter(a => a.value <= 0n, {
  schemaId: NonPositiveBigDecimalSchemaId,
  description: `a non-positive BigDecimal`,
  ...annotations
}));
/**
 * @category BigDecimal constructors
 * @since 3.10.0
 */
exports.nonPositiveBigDecimal = nonPositiveBigDecimal;
const NonPositiveBigDecimalFromSelf = exports.NonPositiveBigDecimalFromSelf = /*#__PURE__*/BigDecimalFromSelf.pipe( /*#__PURE__*/nonPositiveBigDecimal({
  identifier: "NonPositiveBigDecimalFromSelf",
  title: "NonPositiveBigDecimalFromSelf"
}));
/**
 * @category schema id
 * @since 3.10.0
 */
const BetweenBigDecimalSchemaId = exports.BetweenBigDecimalSchemaId = /*#__PURE__*/Symbol.for("effect/SchemaId/BetweenBigDecimal");
/**
 * @category BigDecimal filters
 * @since 3.10.0
 */
const betweenBigDecimal = (minimum, maximum, annotations) => self => self.pipe(filter(a => bigDecimal_.between(a, {
  minimum,
  maximum
}), {
  schemaId: BetweenBigDecimalSchemaId,
  [BetweenBigDecimalSchemaId]: {
    maximum,
    minimum
  },
  description: `a BigDecimal between ${bigDecimal_.format(minimum)} and ${bigDecimal_.format(maximum)}`,
  ...annotations
}));
/**
 * Clamps a `BigDecimal` between a minimum and a maximum value.
 *
 * @category BigDecimal transformations
 * @since 3.10.0
 */
exports.betweenBigDecimal = betweenBigDecimal;
const clampBigDecimal = (minimum, maximum) => self => transform(self, self.pipe(typeSchema, betweenBigDecimal(minimum, maximum)), {
  strict: false,
  decode: self => bigDecimal_.clamp(self, {
    minimum,
    maximum
  }),
  encode: _Function.identity
});
exports.clampBigDecimal = clampBigDecimal;
const chunkArbitrary = (item, ctx) => fc => {
  const items = fc.array(item(fc));
  return (ctx.depthIdentifier !== undefined ? fc.oneof(ctx, fc.constant([]), items) : items).map(chunk_.fromIterable);
};
const chunkPretty = item => c => `Chunk(${chunk_.toReadonlyArray(c).map(item).join(", ")})`;
const chunkParse = decodeUnknown => (u, options, ast) => chunk_.isChunk(u) ? chunk_.isEmpty(u) ? ParseResult.succeed(chunk_.empty()) : toComposite(decodeUnknown(chunk_.toReadonlyArray(u), options), chunk_.fromIterable, ast, u) : ParseResult.fail(new ParseResult.Type(ast, u));
/**
 * @category Chunk
 * @since 3.10.0
 */
const ChunkFromSelf = value => {
  return declare([value], {
    decode: item => chunkParse(ParseResult.decodeUnknown(Array$(item))),
    encode: item => chunkParse(ParseResult.encodeUnknown(Array$(item)))
  }, {
    description: `Chunk<${format(value)}>`,
    pretty: chunkPretty,
    arbitrary: chunkArbitrary,
    equivalence: chunk_.getEquivalence
  });
};
/**
 * @category Chunk transformations
 * @since 3.10.0
 */
exports.ChunkFromSelf = ChunkFromSelf;
const Chunk = value => {
  const value_ = asSchema(value);
  return transform(Array$(value_), ChunkFromSelf(typeSchema(value_)), {
    strict: true,
    decode: as => as.length === 0 ? chunk_.empty() : chunk_.fromIterable(as),
    encode: chunk_.toReadonlyArray
  });
};
exports.Chunk = Chunk;
const nonEmptyChunkArbitrary = item => fc => fastCheck_.array(item(fc), {
  minLength: 1
}).map(as => chunk_.unsafeFromNonEmptyArray(as));
const nonEmptyChunkPretty = item => c => `NonEmptyChunk(${chunk_.toReadonlyArray(c).map(item).join(", ")})`;
const nonEmptyChunkParse = decodeUnknown => (u, options, ast) => chunk_.isChunk(u) && chunk_.isNonEmpty(u) ? toComposite(decodeUnknown(chunk_.toReadonlyArray(u), options), chunk_.unsafeFromNonEmptyArray, ast, u) : ParseResult.fail(new ParseResult.Type(ast, u));
/**
 * @category Chunk
 * @since 3.10.0
 */
const NonEmptyChunkFromSelf = value => {
  return declare([value], {
    decode: item => nonEmptyChunkParse(ParseResult.decodeUnknown(NonEmptyArray(item))),
    encode: item => nonEmptyChunkParse(ParseResult.encodeUnknown(NonEmptyArray(item)))
  }, {
    description: `NonEmptyChunk<${format(value)}>`,
    pretty: nonEmptyChunkPretty,
    arbitrary: nonEmptyChunkArbitrary,
    equivalence: chunk_.getEquivalence
  });
};
/**
 * @category Chunk transformations
 * @since 3.10.0
 */
exports.NonEmptyChunkFromSelf = NonEmptyChunkFromSelf;
const NonEmptyChunk = value => {
  const value_ = asSchema(value);
  return transform(NonEmptyArray(value_), NonEmptyChunkFromSelf(typeSchema(value_)), {
    strict: true,
    decode: chunk_.unsafeFromNonEmptyArray,
    encode: chunk_.toReadonlyArray
  });
};
exports.NonEmptyChunk = NonEmptyChunk;
const toData = a => Array.isArray(a) ? data_.array(a) : data_.struct(a);
const dataArbitrary = item => fc => item(fc).map(toData);
const dataPretty = item => d => `Data(${item(d)})`;
const dataParse = decodeUnknown => (u, options, ast) => Equal.isEqual(u) ? toComposite(decodeUnknown(u, options), toData, ast, u) : ParseResult.fail(new ParseResult.Type(ast, u));
/**
 * @category Data transformations
 * @since 3.10.0
 */
const DataFromSelf = item => declare([item], {
  decode: item => dataParse(ParseResult.decodeUnknown(item)),
  encode: item => dataParse(ParseResult.encodeUnknown(item))
}, {
  description: `Data<${format(item)}>`,
  pretty: dataPretty,
  arbitrary: dataArbitrary
});
/**
 * @category Data transformations
 * @since 3.10.0
 */
exports.DataFromSelf = DataFromSelf;
const Data = item => transform(item, DataFromSelf(typeSchema(item)), {
  strict: false,
  decode: toData,
  encode: a => Array.isArray(a) ? Array.from(a) : Object.assign({}, a)
});
exports.Data = Data;
const isField = u => isSchema(u) || isPropertySignature(u);
const isFields = fields => util_.ownKeys(fields).every(key => isField(fields[key]));
const getFields = hasFields => "fields" in hasFields ? hasFields.fields : getFields(hasFields[RefineSchemaId]);
const getSchemaFromFieldsOr = fieldsOr => isFields(fieldsOr) ? Struct(fieldsOr) : isSchema(fieldsOr) ? fieldsOr : Struct(getFields(fieldsOr));
const getFieldsFromFieldsOr = fieldsOr => isFields(fieldsOr) ? fieldsOr : getFields(fieldsOr);
/**
 * @category classes
 * @since 3.10.0
 */
const Class = identifier => (fieldsOr, annotations) => makeClass({
  kind: "Class",
  identifier,
  schema: getSchemaFromFieldsOr(fieldsOr),
  fields: getFieldsFromFieldsOr(fieldsOr),
  Base: data_.Class,
  annotations
});
/** @internal */
exports.Class = Class;
const getClassTag = tag => withConstructorDefault(propertySignature(Literal(tag)), () => tag);
/**
 * @category classes
 * @since 3.10.0
 */
exports.getClassTag = getClassTag;
const TaggedClass = identifier => (tag, fieldsOr, annotations) => {
  const fields = getFieldsFromFieldsOr(fieldsOr);
  const schema = getSchemaFromFieldsOr(fieldsOr);
  const newFields = {
    _tag: getClassTag(tag)
  };
  const taggedFields = extendFields(newFields, fields);
  return class TaggedClass extends makeClass({
    kind: "TaggedClass",
    identifier: identifier ?? tag,
    schema: extend(schema, Struct(newFields)),
    fields: taggedFields,
    Base: data_.Class,
    annotations
  }) {
    static _tag = tag;
  };
};
/**
 * @category classes
 * @since 3.10.0
 */
exports.TaggedClass = TaggedClass;
const TaggedError = identifier => (tag, fieldsOr, annotations) => {
  class Base extends data_.Error {}
  ;
  Base.prototype.name = tag;
  const fields = getFieldsFromFieldsOr(fieldsOr);
  const schema = getSchemaFromFieldsOr(fieldsOr);
  const newFields = {
    _tag: getClassTag(tag)
  };
  const taggedFields = extendFields(newFields, fields);
  return class TaggedErrorClass extends makeClass({
    kind: "TaggedError",
    identifier: identifier ?? tag,
    schema: extend(schema, Struct(newFields)),
    fields: taggedFields,
    Base,
    annotations,
    disableToString: true
  }) {
    static _tag = tag;
    get message() {
      return `{ ${util_.ownKeys(fields).map(p => `${util_.formatPropertyKey(p)}: ${util_.formatUnknown(this[p])}`).join(", ")} }`;
    }
  };
};
exports.TaggedError = TaggedError;
const extendFields = (a, b) => {
  const out = {
    ...a
  };
  for (const key of util_.ownKeys(b)) {
    if (key in a) {
      throw new Error(errors_.getASTDuplicatePropertySignatureErrorMessage(key));
    }
    out[key] = b[key];
  }
  return out;
};
// does not overwrite existing title annotation
const orElseTitleAnnotation = (schema, title) => {
  const annotation = AST.getTitleAnnotation(schema.ast);
  if (option_.isNone(annotation)) {
    return schema.annotations({
      title
    });
  }
  return schema;
};
const getDisableValidationMakeOption = options => Predicate.isBoolean(options) ? options : options?.disableValidation ?? false;
const makeClass = ({
  Base,
  annotations,
  disableToString,
  fields,
  identifier,
  kind,
  schema
}) => {
  const classSymbol = Symbol.for(`effect/Schema/${kind}/${identifier}`);
  const validateSchema = orElseTitleAnnotation(schema, `${identifier} (Constructor)`);
  const encodedSide = orElseTitleAnnotation(schema, `${identifier} (Encoded side)`);
  const typeSide = orElseTitleAnnotation(typeSchema(schema), `${identifier} (Type side)`);
  const fallbackInstanceOf = u => Predicate.hasProperty(u, classSymbol) && ParseResult.is(typeSide)(u);
  const klass = class extends Base {
    constructor(props = {}, options = false) {
      props = {
        ...props
      };
      if (kind !== "Class") {
        delete props["_tag"];
      }
      props = lazilyMergeDefaults(fields, props);
      if (!getDisableValidationMakeOption(options)) {
        props = ParseResult.validateSync(validateSchema)(props);
      }
      super(props, true);
    }
    // ----------------
    // Schema interface
    // ----------------
    static [TypeId] = variance;
    static get ast() {
      const declaration = declare([typeSide], {
        decode: () => (input, _, ast) => input instanceof this || fallbackInstanceOf(input) ? ParseResult.succeed(input) : ParseResult.fail(new ParseResult.Type(ast, input)),
        encode: () => (input, options) => input instanceof this ? ParseResult.succeed(input) : ParseResult.map(ParseResult.encodeUnknown(typeSide)(input, options), props => new this(props, true))
      }, {
        identifier,
        title: identifier,
        description: `an instance of ${identifier}`,
        pretty: pretty => self => `${identifier}(${pretty(self)})`,
        // @ts-expect-error
        arbitrary: arb => fc => arb(fc).map(props => new this(props)),
        equivalence: _Function.identity,
        [AST.SurrogateAnnotationId]: typeSide.ast,
        ...annotations
      });
      const transformation = transform(encodedSide, declaration, {
        strict: true,
        decode: input => new this(input, true),
        encode: _Function.identity
      }).annotations({
        [AST.SurrogateAnnotationId]: schema.ast
      });
      return transformation.ast;
    }
    static pipe() {
      return (0, _Pipeable.pipeArguments)(this, arguments);
    }
    static annotations(annotations) {
      return make(this.ast).annotations(annotations);
    }
    static toString() {
      return `(${String(encodedSide)} <-> ${identifier})`;
    }
    // ----------------
    // Class interface
    // ----------------
    static make(...args) {
      return new this(...args);
    }
    static fields = {
      ...fields
    };
    static identifier = identifier;
    static extend(identifier) {
      return (newFieldsOr, annotations) => {
        const newFields = getFieldsFromFieldsOr(newFieldsOr);
        const newSchema = getSchemaFromFieldsOr(newFieldsOr);
        const extendedFields = extendFields(fields, newFields);
        return makeClass({
          kind,
          identifier,
          schema: extend(schema, newSchema),
          fields: extendedFields,
          Base: this,
          annotations
        });
      };
    }
    static transformOrFail(identifier) {
      return (newFields, options, annotations) => {
        const transformedFields = extendFields(fields, newFields);
        return makeClass({
          kind,
          identifier,
          schema: transformOrFail(schema, typeSchema(Struct(transformedFields)), options),
          fields: transformedFields,
          Base: this,
          annotations
        });
      };
    }
    static transformOrFailFrom(identifier) {
      return (newFields, options, annotations) => {
        const transformedFields = extendFields(fields, newFields);
        return makeClass({
          kind,
          identifier,
          schema: transformOrFail(encodedSchema(schema), Struct(transformedFields), options),
          fields: transformedFields,
          Base: this,
          annotations
        });
      };
    }
    // ----------------
    // other
    // ----------------
    get [classSymbol]() {
      return classSymbol;
    }
  };
  if (disableToString !== true) {
    Object.defineProperty(klass.prototype, "toString", {
      value() {
        return `${identifier}({ ${util_.ownKeys(fields).map(p => `${util_.formatPropertyKey(p)}: ${util_.formatUnknown(this[p])}`).join(", ")} })`;
      },
      configurable: true
    });
  }
  return klass;
};
const FiberIdNoneEncoded = /*#__PURE__*/Struct({
  _tag: Literal("None")
}).annotations({
  identifier: "FiberIdNoneEncoded"
});
const FiberIdRuntimeEncoded = /*#__PURE__*/Struct({
  _tag: Literal("Runtime"),
  id: Int.annotations({
    title: "id",
    description: "id"
  }),
  startTimeMillis: Int.annotations({
    title: "startTimeMillis",
    description: "startTimeMillis"
  })
}).annotations({
  identifier: "FiberIdRuntimeEncoded"
});
const FiberIdCompositeEncoded = /*#__PURE__*/Struct({
  _tag: Literal("Composite"),
  left: suspend(() => FiberIdEncoded),
  right: suspend(() => FiberIdEncoded)
}).annotations({
  identifier: "FiberIdCompositeEncoded"
});
const FiberIdEncoded = /*#__PURE__*/Union(FiberIdNoneEncoded, FiberIdRuntimeEncoded, FiberIdCompositeEncoded).annotations({
  identifier: "FiberIdEncoded"
});
const fiberIdArbitrary = fc => fc.letrec(tie => ({
  None: fc.record({
    _tag: fc.constant("None")
  }),
  Runtime: fc.record({
    _tag: fc.constant("Runtime"),
    id: fc.integer(),
    startTimeMillis: fc.integer()
  }),
  Composite: fc.record({
    _tag: fc.constant("Composite"),
    left: tie("FiberId"),
    right: tie("FiberId")
  }),
  FiberId: fc.oneof(tie("None"), tie("Runtime"), tie("Composite"))
})).FiberId.map(fiberIdDecode);
const fiberIdPretty = fiberId => {
  switch (fiberId._tag) {
    case "None":
      return "FiberId.none";
    case "Runtime":
      return `FiberId.runtime(${fiberId.id}, ${fiberId.startTimeMillis})`;
    case "Composite":
      return `FiberId.composite(${fiberIdPretty(fiberId.right)}, ${fiberIdPretty(fiberId.left)})`;
  }
};
/**
 * @category FiberId constructors
 * @since 3.10.0
 */
class FiberIdFromSelf extends /*#__PURE__*/declare(fiberId_.isFiberId, {
  identifier: "FiberIdFromSelf",
  pretty: () => fiberIdPretty,
  arbitrary: () => fiberIdArbitrary
}) {}
exports.FiberIdFromSelf = FiberIdFromSelf;
const fiberIdDecode = input => {
  switch (input._tag) {
    case "None":
      return fiberId_.none;
    case "Runtime":
      return fiberId_.runtime(input.id, input.startTimeMillis);
    case "Composite":
      return fiberId_.composite(fiberIdDecode(input.left), fiberIdDecode(input.right));
  }
};
const fiberIdEncode = input => {
  switch (input._tag) {
    case "None":
      return {
        _tag: "None"
      };
    case "Runtime":
      return {
        _tag: "Runtime",
        id: input.id,
        startTimeMillis: input.startTimeMillis
      };
    case "Composite":
      return {
        _tag: "Composite",
        left: fiberIdEncode(input.left),
        right: fiberIdEncode(input.right)
      };
  }
};
/**
 * @category FiberId transformations
 * @since 3.10.0
 */
class FiberId extends /*#__PURE__*/transform(FiberIdEncoded, FiberIdFromSelf, {
  strict: true,
  decode: fiberIdDecode,
  encode: fiberIdEncode
}).annotations({
  identifier: "FiberId"
}) {}
exports.FiberId = FiberId;
const causeDieEncoded = defect => Struct({
  _tag: Literal("Die"),
  defect
});
const CauseEmptyEncoded = /*#__PURE__*/Struct({
  _tag: /*#__PURE__*/Literal("Empty")
});
const causeFailEncoded = error => Struct({
  _tag: Literal("Fail"),
  error
});
const CauseInterruptEncoded = /*#__PURE__*/Struct({
  _tag: /*#__PURE__*/Literal("Interrupt"),
  fiberId: FiberIdEncoded
});
const causeParallelEncoded = causeEncoded => Struct({
  _tag: Literal("Parallel"),
  left: causeEncoded,
  right: causeEncoded
});
const causeSequentialEncoded = causeEncoded => Struct({
  _tag: Literal("Sequential"),
  left: causeEncoded,
  right: causeEncoded
});
const causeEncoded = (error, defect) => {
  const recur = suspend(() => out);
  const out = Union(CauseEmptyEncoded, causeFailEncoded(error), causeDieEncoded(defect), CauseInterruptEncoded, causeSequentialEncoded(recur), causeParallelEncoded(recur)).annotations({
    title: `CauseEncoded<${format(error)}>`
  });
  return out;
};
const causeArbitrary = (error, defect) => fc => fc.letrec(tie => ({
  Empty: fc.record({
    _tag: fc.constant("Empty")
  }),
  Fail: fc.record({
    _tag: fc.constant("Fail"),
    error: error(fc)
  }),
  Die: fc.record({
    _tag: fc.constant("Die"),
    defect: defect(fc)
  }),
  Interrupt: fc.record({
    _tag: fc.constant("Interrupt"),
    fiberId: fiberIdArbitrary(fc)
  }),
  Sequential: fc.record({
    _tag: fc.constant("Sequential"),
    left: tie("Cause"),
    right: tie("Cause")
  }),
  Parallel: fc.record({
    _tag: fc.constant("Parallel"),
    left: tie("Cause"),
    right: tie("Cause")
  }),
  Cause: fc.oneof(tie("Empty"), tie("Fail"), tie("Die"), tie("Interrupt"), tie("Sequential"), tie("Parallel"))
})).Cause.map(causeDecode);
const causePretty = error => cause => {
  const f = cause => {
    switch (cause._tag) {
      case "Empty":
        return "Cause.empty";
      case "Fail":
        return `Cause.fail(${error(cause.error)})`;
      case "Die":
        return `Cause.die(${cause_.pretty(cause)})`;
      case "Interrupt":
        return `Cause.interrupt(${fiberIdPretty(cause.fiberId)})`;
      case "Sequential":
        return `Cause.sequential(${f(cause.left)}, ${f(cause.right)})`;
      case "Parallel":
        return `Cause.parallel(${f(cause.left)}, ${f(cause.right)})`;
    }
  };
  return f(cause);
};
const causeParse = decodeUnknown => (u, options, ast) => cause_.isCause(u) ? toComposite(decodeUnknown(causeEncode(u), options), causeDecode, ast, u) : ParseResult.fail(new ParseResult.Type(ast, u));
/**
 * @category Cause transformations
 * @since 3.10.0
 */
const CauseFromSelf = ({
  defect,
  error
}) => {
  return declare([error, defect], {
    decode: (error, defect) => causeParse(ParseResult.decodeUnknown(causeEncoded(error, defect))),
    encode: (error, defect) => causeParse(ParseResult.encodeUnknown(causeEncoded(error, defect)))
  }, {
    title: `Cause<${error.ast}>`,
    pretty: causePretty,
    arbitrary: causeArbitrary
  });
};
exports.CauseFromSelf = CauseFromSelf;
function causeDecode(cause) {
  switch (cause._tag) {
    case "Empty":
      return cause_.empty;
    case "Fail":
      return cause_.fail(cause.error);
    case "Die":
      return cause_.die(cause.defect);
    case "Interrupt":
      return cause_.interrupt(fiberIdDecode(cause.fiberId));
    case "Sequential":
      return cause_.sequential(causeDecode(cause.left), causeDecode(cause.right));
    case "Parallel":
      return cause_.parallel(causeDecode(cause.left), causeDecode(cause.right));
  }
}
function causeEncode(cause) {
  switch (cause._tag) {
    case "Empty":
      return {
        _tag: "Empty"
      };
    case "Fail":
      return {
        _tag: "Fail",
        error: cause.error
      };
    case "Die":
      return {
        _tag: "Die",
        defect: cause.defect
      };
    case "Interrupt":
      return {
        _tag: "Interrupt",
        fiberId: cause.fiberId
      };
    case "Sequential":
      return {
        _tag: "Sequential",
        left: causeEncode(cause.left),
        right: causeEncode(cause.right)
      };
    case "Parallel":
      return {
        _tag: "Parallel",
        left: causeEncode(cause.left),
        right: causeEncode(cause.right)
      };
  }
}
/**
 * @category Cause transformations
 * @since 3.10.0
 */
const Cause = ({
  defect,
  error
}) => {
  const error_ = asSchema(error);
  const defect_ = asSchema(defect);
  return transform(causeEncoded(error_, defect_), CauseFromSelf({
    error: typeSchema(error_),
    defect: Unknown
  }), {
    strict: false,
    decode: causeDecode,
    encode: causeEncode
  });
};
/**
 * Defines a schema for handling JavaScript errors (`Error` instances) and other types of defects.
 * It decodes objects into Error instances if they match the expected structure (i.e., have a `message` and optionally a `name` and `stack`),
 * or converts other values to their string representations.
 *
 * When encoding, it converts `Error` instances back into plain objects containing only the error's name and message,
 * or other values into their string forms.
 *
 * This is useful for serializing and deserializing errors across network boundaries where error objects do not natively serialize.
 *
 * @category defect
 * @since 3.10.0
 */
exports.Cause = Cause;
const Defect = exports.Defect = /*#__PURE__*/transform(Unknown, Unknown, {
  strict: true,
  decode: u => {
    if (Predicate.isObject(u) && "message" in u && typeof u.message === "string") {
      const err = new Error(u.message, {
        cause: u
      });
      if ("name" in u && typeof u.name === "string") {
        err.name = u.name;
      }
      err.stack = "stack" in u && typeof u.stack === "string" ? u.stack : "";
      return err;
    }
    return String(u);
  },
  encode: defect => {
    if (defect instanceof Error) {
      return {
        name: defect.name,
        message: defect.message
        // no stack because of security reasons
      };
    }
    return String(defect);
  }
}).annotations({
  identifier: "Defect"
});
const exitFailureEncoded = (error, defect) => Struct({
  _tag: Literal("Failure"),
  cause: causeEncoded(error, defect)
});
const exitSuccessEncoded = value => Struct({
  _tag: Literal("Success"),
  value
});
const exitEncoded = (value, error, defect) => Union(exitFailureEncoded(error, defect), exitSuccessEncoded(value)).annotations({
  title: `ExitEncoded<${format(value)}, ${format(error)}, ${format(defect)}>`
});
const exitDecode = input => {
  switch (input._tag) {
    case "Failure":
      return exit_.failCause(causeDecode(input.cause));
    case "Success":
      return exit_.succeed(input.value);
  }
};
const exitArbitrary = (value, error, defect) => fc => fc.oneof(fc.record({
  _tag: fc.constant("Failure"),
  cause: causeArbitrary(error, defect)(fc)
}), fc.record({
  _tag: fc.constant("Success"),
  value: value(fc)
})).map(exitDecode);
const exitPretty = (value, error) => exit => exit._tag === "Failure" ? `Exit.failCause(${causePretty(error)(exit.cause)})` : `Exit.succeed(${value(exit.value)})`;
const exitParse = (decodeUnknownValue, decodeUnknownCause) => (u, options, ast) => exit_.isExit(u) ? exit_.match(u, {
  onFailure: cause => toComposite(decodeUnknownCause(cause, options), exit_.failCause, ast, u),
  onSuccess: value => toComposite(decodeUnknownValue(value, options), exit_.succeed, ast, u)
}) : ParseResult.fail(new ParseResult.Type(ast, u));
/**
 * @category Exit transformations
 * @since 3.10.0
 */
const ExitFromSelf = ({
  defect,
  failure,
  success
}) => declare([success, failure, defect], {
  decode: (success, failure, defect) => exitParse(ParseResult.decodeUnknown(success), ParseResult.decodeUnknown(CauseFromSelf({
    error: failure,
    defect
  }))),
  encode: (success, failure, defect) => exitParse(ParseResult.encodeUnknown(success), ParseResult.encodeUnknown(CauseFromSelf({
    error: failure,
    defect
  })))
}, {
  title: `Exit<${success.ast}, ${failure.ast}>`,
  pretty: exitPretty,
  arbitrary: exitArbitrary
});
/**
 * @category Exit transformations
 * @since 3.10.0
 */
exports.ExitFromSelf = ExitFromSelf;
const Exit = ({
  defect,
  failure,
  success
}) => {
  const success_ = asSchema(success);
  const failure_ = asSchema(failure);
  const defect_ = asSchema(defect);
  return transform(exitEncoded(success_, failure_, defect_), ExitFromSelf({
    failure: typeSchema(failure_),
    success: typeSchema(success_),
    defect: Unknown
  }), {
    strict: false,
    decode: exitDecode,
    encode: exit => exit._tag === "Failure" ? {
      _tag: "Failure",
      cause: exit.cause
    } : {
      _tag: "Success",
      value: exit.value
    }
  });
};
exports.Exit = Exit;
const hashSetArbitrary = (item, ctx) => fc => {
  const items = fc.array(item(fc));
  return (ctx.depthIdentifier !== undefined ? fc.oneof(ctx, fc.constant([]), items) : items).map(hashSet_.fromIterable);
};
const hashSetPretty = item => set => `HashSet(${Array.from(set).map(a => item(a)).join(", ")})`;
const hashSetEquivalence = item => {
  const arrayEquivalence = array_.getEquivalence(item);
  return Equivalence.make((a, b) => arrayEquivalence(Array.from(a), Array.from(b)));
};
const hashSetParse = decodeUnknown => (u, options, ast) => hashSet_.isHashSet(u) ? toComposite(decodeUnknown(Array.from(u), options), hashSet_.fromIterable, ast, u) : ParseResult.fail(new ParseResult.Type(ast, u));
/**
 * @category HashSet transformations
 * @since 3.10.0
 */
const HashSetFromSelf = value => {
  return declare([value], {
    decode: item => hashSetParse(ParseResult.decodeUnknown(Array$(item))),
    encode: item => hashSetParse(ParseResult.encodeUnknown(Array$(item)))
  }, {
    description: `HashSet<${format(value)}>`,
    pretty: hashSetPretty,
    arbitrary: hashSetArbitrary,
    equivalence: hashSetEquivalence
  });
};
/**
 * @category HashSet transformations
 * @since 3.10.0
 */
exports.HashSetFromSelf = HashSetFromSelf;
const HashSet = value => {
  const value_ = asSchema(value);
  return transform(Array$(value_), HashSetFromSelf(typeSchema(value_)), {
    strict: true,
    decode: as => hashSet_.fromIterable(as),
    encode: set => Array.from(set)
  });
};
exports.HashSet = HashSet;
const hashMapArbitrary = (key, value, ctx) => fc => {
  const items = fc.array(fc.tuple(key(fc), value(fc)));
  return (ctx.depthIdentifier !== undefined ? fc.oneof(ctx, fc.constant([]), items) : items).map(hashMap_.fromIterable);
};
const hashMapPretty = (key, value) => map => `HashMap([${Array.from(map).map(([k, v]) => `[${key(k)}, ${value(v)}]`).join(", ")}])`;
const hashMapEquivalence = (key, value) => {
  const arrayEquivalence = array_.getEquivalence(Equivalence.make(([ka, va], [kb, vb]) => key(ka, kb) && value(va, vb)));
  return Equivalence.make((a, b) => arrayEquivalence(Array.from(a), Array.from(b)));
};
const hashMapParse = decodeUnknown => (u, options, ast) => hashMap_.isHashMap(u) ? toComposite(decodeUnknown(Array.from(u), options), hashMap_.fromIterable, ast, u) : ParseResult.fail(new ParseResult.Type(ast, u));
/**
 * @category HashMap transformations
 * @since 3.10.0
 */
const HashMapFromSelf = ({
  key,
  value
}) => {
  return declare([key, value], {
    decode: (key, value) => hashMapParse(ParseResult.decodeUnknown(Array$(Tuple(key, value)))),
    encode: (key, value) => hashMapParse(ParseResult.encodeUnknown(Array$(Tuple(key, value))))
  }, {
    description: `HashMap<${format(key)}, ${format(value)}>`,
    pretty: hashMapPretty,
    arbitrary: hashMapArbitrary,
    equivalence: hashMapEquivalence
  });
};
/**
 * @category HashMap transformations
 * @since 3.10.0
 */
exports.HashMapFromSelf = HashMapFromSelf;
const HashMap = ({
  key,
  value
}) => {
  const key_ = asSchema(key);
  const value_ = asSchema(value);
  return transform(Array$(Tuple(key_, value_)), HashMapFromSelf({
    key: typeSchema(key_),
    value: typeSchema(value_)
  }), {
    strict: true,
    decode: as => hashMap_.fromIterable(as),
    encode: map => Array.from(map)
  });
};
exports.HashMap = HashMap;
const listArbitrary = (item, ctx) => fc => {
  const items = fc.array(item(fc));
  return (ctx.depthIdentifier !== undefined ? fc.oneof(ctx, fc.constant([]), items) : items).map(list_.fromIterable);
};
const listPretty = item => set => `List(${Array.from(set).map(a => item(a)).join(", ")})`;
const listEquivalence = item => {
  const arrayEquivalence = array_.getEquivalence(item);
  return Equivalence.make((a, b) => arrayEquivalence(Array.from(a), Array.from(b)));
};
const listParse = decodeUnknown => (u, options, ast) => list_.isList(u) ? toComposite(decodeUnknown(Array.from(u), options), list_.fromIterable, ast, u) : ParseResult.fail(new ParseResult.Type(ast, u));
/**
 * @category List transformations
 * @since 3.10.0
 */
const ListFromSelf = value => {
  return declare([value], {
    decode: item => listParse(ParseResult.decodeUnknown(Array$(item))),
    encode: item => listParse(ParseResult.encodeUnknown(Array$(item)))
  }, {
    description: `List<${format(value)}>`,
    pretty: listPretty,
    arbitrary: listArbitrary,
    equivalence: listEquivalence
  });
};
/**
 * @category List transformations
 * @since 3.10.0
 */
exports.ListFromSelf = ListFromSelf;
const List = value => {
  const value_ = asSchema(value);
  return transform(Array$(value_), ListFromSelf(typeSchema(value_)), {
    strict: true,
    decode: as => list_.fromIterable(as),
    encode: set => Array.from(set)
  });
};
exports.List = List;
const sortedSetArbitrary = (item, ord, ctx) => fc => {
  const items = fc.array(item(fc));
  return (ctx.depthIdentifier !== undefined ? fc.oneof(ctx, fc.constant([]), items) : items).map(as => sortedSet_.fromIterable(as, ord));
};
const sortedSetPretty = item => set => `new SortedSet([${Array.from(sortedSet_.values(set)).map(a => item(a)).join(", ")}])`;
const sortedSetParse = (decodeUnknown, ord) => (u, options, ast) => sortedSet_.isSortedSet(u) ? toComposite(decodeUnknown(Array.from(sortedSet_.values(u)), options), as => sortedSet_.fromIterable(as, ord), ast, u) : ParseResult.fail(new ParseResult.Type(ast, u));
/**
 * @category SortedSet transformations
 * @since 3.10.0
 */
const SortedSetFromSelf = (value, ordA, ordI) => {
  return declare([value], {
    decode: item => sortedSetParse(ParseResult.decodeUnknown(Array$(item)), ordA),
    encode: item => sortedSetParse(ParseResult.encodeUnknown(Array$(item)), ordI)
  }, {
    description: `SortedSet<${format(value)}>`,
    pretty: sortedSetPretty,
    arbitrary: (arb, ctx) => sortedSetArbitrary(arb, ordA, ctx),
    equivalence: () => sortedSet_.getEquivalence()
  });
};
/**
 * @category SortedSet transformations
 * @since 3.10.0
 */
exports.SortedSetFromSelf = SortedSetFromSelf;
const SortedSet = (value, ordA) => {
  const value_ = asSchema(value);
  const to = typeSchema(value_);
  return transform(Array$(value_), SortedSetFromSelf(to, ordA, ordA), {
    strict: true,
    decode: as => sortedSet_.fromIterable(as, ordA),
    encode: set => Array.from(sortedSet_.values(set))
  });
};
/**
 * Converts an arbitrary value to a `boolean` by testing whether it is truthy.
 * Uses `!!val` to coerce the value to a `boolean`.
 *
 * @see https://developer.mozilla.org/docs/Glossary/Truthy
 * @category boolean constructors
 * @since 3.10.0
 */
exports.SortedSet = SortedSet;
class BooleanFromUnknown extends /*#__PURE__*/transform(Unknown, Boolean$, {
  strict: true,
  decode: Predicate.isTruthy,
  encode: _Function.identity
}).annotations({
  identifier: "BooleanFromUnknown"
}) {}
/**
 * @category Config validations
 * @since 3.10.0
 */
exports.BooleanFromUnknown = BooleanFromUnknown;
const Config = (name, schema) => {
  const decodeEither_ = decodeEither(schema);
  return config_.string(name).pipe(config_.mapOrFail(a => decodeEither_(a).pipe(either_.mapLeft(error => configError_.InvalidData([], ParseResult.TreeFormatter.formatErrorSync(error))))));
};
// ---------------------------------------------
// Serializable
// ---------------------------------------------
/**
 * @since 3.10.0
 * @category symbol
 */
exports.Config = Config;
const symbolSerializable = exports.symbolSerializable = /*#__PURE__*/Symbol.for("effect/Schema/Serializable/symbol");
/**
 * @since 3.10.0
 */
const asSerializable = serializable => serializable;
/**
 * @since 3.10.0
 * @category accessor
 */
exports.asSerializable = asSerializable;
const serializableSchema = self => self[symbolSerializable];
/**
 * @since 3.10.0
 * @category encoding
 */
exports.serializableSchema = serializableSchema;
const serialize = self => encodeUnknown(self[symbolSerializable])(self);
/**
 * @since 3.10.0
 * @category decoding
 */
exports.serialize = serialize;
const deserialize = exports.deserialize = /*#__PURE__*/(0, _Function.dual)(2, (self, value) => decodeUnknown(self[symbolSerializable])(value));
/**
 * @since 3.10.0
 * @category symbol
 */
const symbolWithResult = exports.symbolWithResult = /*#__PURE__*/Symbol.for("effect/Schema/Serializable/symbolResult");
/**
 * @since 3.10.0
 */
const asWithResult = withExit => withExit;
/**
 * @since 3.10.0
 * @category accessor
 */
exports.asWithResult = asWithResult;
const failureSchema = self => self[symbolWithResult].failure;
/**
 * @since 3.10.0
 * @category accessor
 */
exports.failureSchema = failureSchema;
const successSchema = self => self[symbolWithResult].success;
exports.successSchema = successSchema;
const exitSchemaCache = /*#__PURE__*/(0, _GlobalValue.globalValue)("effect/Schema/Serializable/exitSchemaCache", () => new WeakMap());
/**
 * @since 3.10.0
 * @category accessor
 */
const exitSchema = self => {
  const proto = Object.getPrototypeOf(self);
  if (!(symbolWithResult in proto)) {
    return Exit({
      failure: failureSchema(self),
      success: successSchema(self),
      defect: Defect
    });
  }
  let schema = exitSchemaCache.get(proto);
  if (schema === undefined) {
    schema = Exit({
      failure: failureSchema(self),
      success: successSchema(self),
      defect: Defect
    });
    exitSchemaCache.set(proto, schema);
  }
  return schema;
};
/**
 * @since 3.10.0
 * @category encoding
 */
exports.exitSchema = exitSchema;
const serializeFailure = exports.serializeFailure = /*#__PURE__*/(0, _Function.dual)(2, (self, value) => encode(self[symbolWithResult].failure)(value));
/**
 * @since 3.10.0
 * @category decoding
 */
const deserializeFailure = exports.deserializeFailure = /*#__PURE__*/(0, _Function.dual)(2, (self, value) => decodeUnknown(self[symbolWithResult].failure)(value));
/**
 * @since 3.10.0
 * @category encoding
 */
const serializeSuccess = exports.serializeSuccess = /*#__PURE__*/(0, _Function.dual)(2, (self, value) => encode(self[symbolWithResult].success)(value));
/**
 * @since 3.10.0
 * @category decoding
 */
const deserializeSuccess = exports.deserializeSuccess = /*#__PURE__*/(0, _Function.dual)(2, (self, value) => decodeUnknown(self[symbolWithResult].success)(value));
/**
 * @since 3.10.0
 * @category encoding
 */
const serializeExit = exports.serializeExit = /*#__PURE__*/(0, _Function.dual)(2, (self, value) => encode(exitSchema(self))(value));
/**
 * @since 3.10.0
 * @category decoding
 */
const deserializeExit = exports.deserializeExit = /*#__PURE__*/(0, _Function.dual)(2, (self, value) => decodeUnknown(exitSchema(self))(value));
/**
 * @since 3.10.0
 */
const asSerializableWithResult = procedure => procedure;
/**
 * @category classes
 * @since 3.10.0
 */
exports.asSerializableWithResult = asSerializableWithResult;
const TaggedRequest = identifier => (tag, options, annotations) => {
  const taggedFields = extendFields({
    _tag: getClassTag(tag)
  }, options.payload);
  return class TaggedRequestClass extends makeClass({
    kind: "TaggedRequest",
    identifier: identifier ?? tag,
    schema: Struct(taggedFields),
    fields: taggedFields,
    Base: Request.Class,
    annotations
  }) {
    static _tag = tag;
    static success = options.success;
    static failure = options.failure;
    get [symbolSerializable]() {
      return this.constructor;
    }
    get [symbolWithResult]() {
      return {
        failure: options.failure,
        success: options.success
      };
    }
  };
};
// -------------------------------------------------------------------------------------------------
// Equivalence compiler
// -------------------------------------------------------------------------------------------------
/**
 * Given a schema `Schema<A, I, R>`, returns an `Equivalence` instance for `A`.
 *
 * @category Equivalence
 * @since 3.10.0
 */
exports.TaggedRequest = TaggedRequest;
const equivalence = schema => go(schema.ast, []);
exports.equivalence = equivalence;
const getEquivalenceAnnotation = /*#__PURE__*/AST.getAnnotation(AST.EquivalenceAnnotationId);
const go = (ast, path) => {
  const hook = getEquivalenceAnnotation(ast);
  if (option_.isSome(hook)) {
    switch (ast._tag) {
      case "Declaration":
        return hook.value(...ast.typeParameters.map(tp => go(tp, path)));
      case "Refinement":
        return hook.value(go(ast.from, path));
      default:
        return hook.value();
    }
  }
  switch (ast._tag) {
    case "NeverKeyword":
      throw new Error(errors_.getEquivalenceUnsupportedErrorMessage(ast, path));
    case "Transformation":
      return go(ast.to, path);
    case "Declaration":
    case "Literal":
    case "StringKeyword":
    case "TemplateLiteral":
    case "UniqueSymbol":
    case "SymbolKeyword":
    case "UnknownKeyword":
    case "AnyKeyword":
    case "NumberKeyword":
    case "BooleanKeyword":
    case "BigIntKeyword":
    case "UndefinedKeyword":
    case "VoidKeyword":
    case "Enums":
    case "ObjectKeyword":
      return Equal.equals;
    case "Refinement":
      return go(ast.from, path);
    case "Suspend":
      {
        const get = util_.memoizeThunk(() => go(ast.f(), path));
        return (a, b) => get()(a, b);
      }
    case "TupleType":
      {
        const elements = ast.elements.map((element, i) => go(element.type, path.concat(i)));
        const rest = ast.rest.map(annotatedAST => go(annotatedAST.type, path));
        return Equivalence.make((a, b) => {
          const len = a.length;
          if (len !== b.length) {
            return false;
          }
          // ---------------------------------------------
          // handle elements
          // ---------------------------------------------
          let i = 0;
          for (; i < Math.min(len, ast.elements.length); i++) {
            if (!elements[i](a[i], b[i])) {
              return false;
            }
          }
          // ---------------------------------------------
          // handle rest element
          // ---------------------------------------------
          if (array_.isNonEmptyReadonlyArray(rest)) {
            const [head, ...tail] = rest;
            for (; i < len - tail.length; i++) {
              if (!head(a[i], b[i])) {
                return false;
              }
            }
            // ---------------------------------------------
            // handle post rest elements
            // ---------------------------------------------
            for (let j = 0; j < tail.length; j++) {
              i += j;
              if (!tail[j](a[i], b[i])) {
                return false;
              }
            }
          }
          return true;
        });
      }
    case "TypeLiteral":
      {
        if (ast.propertySignatures.length === 0 && ast.indexSignatures.length === 0) {
          return Equal.equals;
        }
        const propertySignatures = ast.propertySignatures.map(ps => go(ps.type, path.concat(ps.name)));
        const indexSignatures = ast.indexSignatures.map(is => go(is.type, path));
        return Equivalence.make((a, b) => {
          const aStringKeys = Object.keys(a);
          const aSymbolKeys = Object.getOwnPropertySymbols(a);
          // ---------------------------------------------
          // handle property signatures
          // ---------------------------------------------
          for (let i = 0; i < propertySignatures.length; i++) {
            const ps = ast.propertySignatures[i];
            const name = ps.name;
            const aHas = Object.prototype.hasOwnProperty.call(a, name);
            const bHas = Object.prototype.hasOwnProperty.call(b, name);
            if (ps.isOptional) {
              if (aHas !== bHas) {
                return false;
              }
            }
            if (aHas && bHas && !propertySignatures[i](a[name], b[name])) {
              return false;
            }
          }
          // ---------------------------------------------
          // handle index signatures
          // ---------------------------------------------
          let bSymbolKeys;
          let bStringKeys;
          for (let i = 0; i < indexSignatures.length; i++) {
            const is = ast.indexSignatures[i];
            const base = AST.getParameterBase(is.parameter);
            const isSymbol = AST.isSymbolKeyword(base);
            if (isSymbol) {
              bSymbolKeys = bSymbolKeys || Object.getOwnPropertySymbols(b);
              if (aSymbolKeys.length !== bSymbolKeys.length) {
                return false;
              }
            } else {
              bStringKeys = bStringKeys || Object.keys(b);
              if (aStringKeys.length !== bStringKeys.length) {
                return false;
              }
            }
            const aKeys = isSymbol ? aSymbolKeys : aStringKeys;
            for (let j = 0; j < aKeys.length; j++) {
              const key = aKeys[j];
              if (!Object.prototype.hasOwnProperty.call(b, key) || !indexSignatures[i](a[key], b[key])) {
                return false;
              }
            }
          }
          return true;
        });
      }
    case "Union":
      {
        const searchTree = ParseResult.getSearchTree(ast.types, true);
        const ownKeys = util_.ownKeys(searchTree.keys);
        const len = ownKeys.length;
        return Equivalence.make((a, b) => {
          let candidates = [];
          if (len > 0 && Predicate.isRecordOrArray(a)) {
            for (let i = 0; i < len; i++) {
              const name = ownKeys[i];
              const buckets = searchTree.keys[name].buckets;
              if (Object.prototype.hasOwnProperty.call(a, name)) {
                const literal = String(a[name]);
                if (Object.prototype.hasOwnProperty.call(buckets, literal)) {
                  candidates = candidates.concat(buckets[literal]);
                }
              }
            }
          }
          if (searchTree.otherwise.length > 0) {
            candidates = candidates.concat(searchTree.otherwise);
          }
          const tuples = candidates.map(ast => [go(ast, path), ParseResult.is({
            ast
          })]);
          for (let i = 0; i < tuples.length; i++) {
            const [equivalence, is] = tuples[i];
            if (is(a) && is(b)) {
              if (equivalence(a, b)) {
                return true;
              }
            }
          }
          return false;
        });
      }
  }
};
//# sourceMappingURL=Schema.js.map